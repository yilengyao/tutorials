{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87c0e903-842f-43fd-95e3-d10d50aacf6a",
   "metadata": {},
   "source": [
    "# Build AI PC\n",
    "\n",
    "Read this article for instruction to build your own AI PC [Run LLMs Natively in your Java Application\n",
    "](https://www.linkedin.com/pulse/run-llms-natively-your-java-application-yi-leng-yao-brpnc/?trackingId=gwi8eydkQselga2eSd8N7Q%3D%3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368b5c2b-6b66-45b0-b7dc-79c8550c65f9",
   "metadata": {},
   "source": [
    "# SSH into Ubuntu Server\n",
    "On the Ubuntu terminal and install openssh\n",
    "```\n",
    "apt update\n",
    "sudo apt install openssh-server\n",
    "```\n",
    "\n",
    "To validate ssh is running\n",
    "```\n",
    "sudo systemctl status ssh\n",
    "```\n",
    "\n",
    "Tell firewall to allow ssh\n",
    "```\n",
    "sudo ufw allow ssh\n",
    "```\n",
    "\n",
    "Get local network IP address of Ubuntu machine\n",
    "```\n",
    "ip a\n",
    "```\n",
    "\n",
    "No on your Mac type in the command to ssh into the machine.\n",
    "```\n",
    "ssh <username>@<ubuntu local network ip address>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58804a5-9082-4bc4-aa4d-205b14d16364",
   "metadata": {},
   "source": [
    "# TailScale Setup\n",
    "TailScale is a peer-to-peer vpn that allows your computers to communicate over the internet.\n",
    "\n",
    "Download and install Tailscale on mac from https://tailscale.com/download/.\n",
    "\n",
    "SSH into Ubuntu and run\n",
    "```\n",
    "curl -fsSL https://tailscale.com/install.sh | sh\n",
    "```\n",
    "\n",
    "After setting up TailScale you can get the IP addresses of your devices in https://login.tailscale.com/admin/machines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ab931f-3677-47fa-b752-f778b1cfadf7",
   "metadata": {},
   "source": [
    "# Ollama Setup\n",
    "Created systemd override for persistent configuration\n",
    "/etc/systemd/system/ollama.service.d/override.conf:\n",
    "```\n",
    "[Service]\n",
    "Environment=\"OLLAMA_HOST=0.0.0.0:11434\"\n",
    "```\n",
    "\n",
    "Created Ollama config file\n",
    "HOME/.ollama/config.json:\n",
    "```\n",
    "{\n",
    "  \"host\": \"0.0.0.0:11434\",\n",
    "  \"origins\": [\"*\"]\n",
    "}\n",
    "```\n",
    "This configured Ollama to:\n",
    "\n",
    "Listen on all network interfaces (0.0.0.0)\n",
    "Accept connections from any origin\n",
    "Persist settings across restarts\n",
    "\n",
    "## Allowing Access through our firewall\n",
    "Now using ufw to allow traffic to the ports 8080 and 11434 in our firewall. Run the following in Ubuntu.\n",
    "```\n",
    "sudo ufw allow in on tailscale0 to any port 8080\n",
    "sudo ufw allow in on tailscale0 to any port 11434\n",
    "```\n",
    "\n",
    "## Start Ollama Server and Pull LLM Model\n",
    "Starting Ollama Server\n",
    "```\n",
    "sudo systemctl start ollama\n",
    "\n",
    "#or\n",
    "sudo OLLAMA_HOST=\"0.0.0.0:11434\" ollama serve\n",
    "```\n",
    "\n",
    "Pulling the QWEN 32b model\n",
    "```\n",
    "ollama pull qwen:32b\n",
    "```\n",
    "\n",
    "## Accessing Ollama on your mac\n",
    "you can access Ollama on your mac through \n",
    "```\n",
    "localhost 11434\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6979e66a-2d9a-4cbb-a786-71c8093ad1ee",
   "metadata": {},
   "source": [
    "# Jupyter Integration\n",
    "Install the `Pretzel plugin`.\n",
    "\n",
    "Go to `settings` -> `Pretzel AI Settings`\n",
    "\n",
    "Set the base url to\n",
    "```\n",
    "http://localhost:11434\n",
    "```\n",
    "\n",
    "And model and copilot model to\n",
    "```\n",
    "qwen:32b\n",
    "```\n",
    "\n",
    "<img src=\"JupyterIntegration.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5cd5d4-f1de-4e3d-a906-5ea65cc520f9",
   "metadata": {},
   "source": [
    "# VS Code Setup\n",
    "\n",
    "## SSH\n",
    "Install Open Remote - SSH plugin\n",
    "\n",
    "## Code Generation\n",
    "Install the Continue - Codestral, Claude, and more plugin\n",
    "\n",
    "Then add you local model to the `.continue/config.json` file\n",
    "```\n",
    " \"models\": [\n",
    "    {\n",
    "      \"title\": \"Qwen\",\n",
    "      \"provider\": \"ollama\",\n",
    "      \"model\": \"qwen:32b\"\n",
    "    },\n",
    "```\n",
    "\n",
    "<img src=\"vs-code-continuedev-config.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a67c5e-e957-4ce8-bd01-dbaa845ecce1",
   "metadata": {},
   "source": [
    "# NeoVim Development\n",
    "Add the [remote-nvim](https://github.com/amitds1997/remote-nvim.nvim) plugin.\n",
    "\n",
    "Create a file named `remote-nvin.lua` in your `~/.config/nvim/lua/plugins` directory and add the following code.\n",
    "```\n",
    "return {\n",
    "  {\n",
    "    \"amitds1997/remote-nvim.nvim\",\n",
    "  version = \"*\", -- Pin to GitHub releases\n",
    "  dependencies = {\n",
    "      \"nvim-lua/plenary.nvim\", -- For standard functions\n",
    "      \"MunifTanjim/nui.nvim\", -- To build the plugin UI\n",
    "      \"nvim-telescope/telescope.nvim\", -- For picking b/w different remote methods\n",
    "  },\n",
    "  config = true,\n",
    "  },\n",
    "}\n",
    "```\n",
    "\n",
    "Start up your neovim editor\n",
    "```\n",
    "nvim\n",
    "```\n",
    "\n",
    "And enter in the command to ssh into your remote server.\n",
    "```\n",
    ":RemoteStart\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a13c67-9888-475d-8e29-01a27ba61e2a",
   "metadata": {},
   "source": [
    "# Java Development\n",
    "Add the following configuration to your `application.properties` file\n",
    "```\n",
    "# In application.properties\n",
    "server.address=0.0.0.0\n",
    "server.port=8080\n",
    "server.tomcat.protocol-header=x-forwarded-proto\n",
    "server.tomcat.remote-ip-header=x-forwarded-for\n",
    "server.tomcat.use-relative-redirects=true\n",
    "```\n",
    "\n",
    "And when you spin up your Spring Boot server on Ubuntu, you can access the endpoint through `htto://localhost:8080`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
