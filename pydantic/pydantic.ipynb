{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "from pydantic_ai.providers.openai import OpenAIProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ollama_model = OpenAIModel(\n",
    "    model_name='qwen2.5-coder:14b', provider=OpenAIProvider(base_url='http://localhost:11434/v1')\n",
    ")\n",
    "\n",
    "roulette_agent = Agent(  \n",
    "    ollama_model,\n",
    "    deps_type=int,\n",
    "    result_type=bool,\n",
    "    system_prompt=(\n",
    "        'Use the `roulette_wheel` function to see if the '\n",
    "        'customer has won based on the number they provide.'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROULETTE_NUMBERS = 37\n",
    "import random\n",
    "\n",
    "@roulette_agent.tool\n",
    "def roulette_wheel(ctx: RunContext[int], number: int) -> bool:\n",
    "    # generate random numbers between 0 and 36\n",
    "    winning_numbers = [random.randint(0, ROULETTE_NUMBERS) for _ in range(19)]\n",
    "\n",
    "    # if 0 < number < ROULETTE_NUMBERS:\n",
    "    #     raise ValueError(f'Number must be between 0 and {ROULETTE_NUMBERS}')\n",
    "    print(f'Winning numbers: {winning_numbers}')\n",
    "    print(f'User number: {number}')\n",
    "    print(f'deps: {ctx.deps}')\n",
    "    return number in winning_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winning numbers: [1, 34, 17, 32, 1, 1, 6, 22, 11, 36, 24, 1, 36, 6, 34, 0, 20, 5, 31]\n",
      "User number: 15\n",
      "deps: 15\n"
     ]
    }
   ],
   "source": [
    "result = roulette_agent.run_sync(\"is fifteen a winning number\", deps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentRunResult(data=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "from pydantic_ai.providers.openai import OpenAIProvider\n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ModelRequestNode(request=ModelRequest(parts=[UserPromptPart(content='What is '\n",
      "                                                                     'the '\n",
      "                                                                     'capital '\n",
      "                                                                     'of '\n",
      "                                                                     'France?',\n",
      "                                                             timestamp=datetime.datetime(2025, 3, 7, 19, 25, 13, 25883, tzinfo=datetime.timezone.utc),\n",
      "                                                             part_kind='user-prompt')],\n",
      "                                       kind='request')),\n",
      " CallToolsNode(model_response=ModelResponse(parts=[TextPart(content='The '\n",
      "                                                                    'capital '\n",
      "                                                                    'of France '\n",
      "                                                                    'is Paris.',\n",
      "                                                            part_kind='text')],\n",
      "                                            model_name='qwen2.5-coder:14b',\n",
      "                                            timestamp=datetime.datetime(2025, 3, 7, 19, 25, 13, tzinfo=datetime.timezone.utc),\n",
      "                                            kind='response')),\n",
      " End(data=FinalResult(data='The capital of France is Paris.',\n",
      "                      tool_name=None,\n",
      "                      tool_call_id=None))]\n",
      "'The capital of France is Paris.'\n"
     ]
    }
   ],
   "source": [
    "from pydantic_ai import Agent\n",
    "\n",
    "ollama_model = OpenAIModel(\n",
    "    model_name='qwen2.5-coder:14b', provider=OpenAIProvider(base_url='http://localhost:11434/v1')\n",
    ")\n",
    "agent = Agent(ollama_model)\n",
    "\n",
    "\n",
    "nodes = []\n",
    "\n",
    "# Begin an AgentRun, which is an async-iterable over the nodes of the agent's graph\n",
    "async with agent.iter('What is the capital of France?') as agent_run:\n",
    "    async for node in agent_run:\n",
    "        # Each node represents a step in the agent's execution\n",
    "        nodes.append(node)\n",
    "pp.pprint(nodes)\n",
    "\"\"\"\n",
    "    [\n",
    "        ModelRequestNode(\n",
    "            request=ModelRequest(\n",
    "                parts=[\n",
    "                    UserPromptPart(\n",
    "                        content='What is the capital of France?',\n",
    "                        timestamp=datetime.datetime(...),\n",
    "                        part_kind='user-prompt',\n",
    "                    )\n",
    "                ],\n",
    "                kind='request',\n",
    "            )\n",
    "        ),\n",
    "        CallToolsNode(\n",
    "            model_response=ModelResponse(\n",
    "                parts=[TextPart(content='Paris', part_kind='text')],\n",
    "                model_name='gpt-4o',\n",
    "                timestamp=datetime.datetime(...),\n",
    "                kind='response',\n",
    "            )\n",
    "        ),\n",
    "        End(data=FinalResult(data='Paris', tool_name=None, tool_call_id=None)),\n",
    "    ]\n",
    "\"\"\"\n",
    "\n",
    "pp.pprint(agent_run.result.data)\n",
    "#> Paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "from pydantic_ai.providers.openai import OpenAIProvider\n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Sure, here's a light-hearted joke for you:\\n\"\n",
      " '\\n'\n",
      " 'Why did the tomato turn red?\\n'\n",
      " '\\n'\n",
      " 'Because it saw the salad dressing! \\n'\n",
      " '\\n'\n",
      " \"I hope you found that amusing! If you'd like to hear more jokes or have any \"\n",
      " 'other questions, feel free to ask.')\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "import httpx\n",
    "\n",
    "from pydantic_ai import Agent\n",
    "ollama_model = OpenAIModel(\n",
    "    model_name='qwen2.5-coder:14b', provider=OpenAIProvider(base_url='http://localhost:11434/v1')\n",
    ")\n",
    "agent = Agent(ollama_model)\n",
    "\n",
    "@dataclass\n",
    "class MyDeps:  \n",
    "    api_key: str\n",
    "    http_client: httpx.AsyncClient\n",
    "\n",
    "\n",
    "\n",
    "async with httpx.AsyncClient() as client:\n",
    "    deps = MyDeps('foobar', client)\n",
    "    result = await agent.run(\n",
    "        'Tell me a joke.',\n",
    "        deps=deps,  \n",
    "    )\n",
    "    pp.pprint(result.data)\n",
    "    #> Did you hear about the toothpaste scandal? They called it Colgate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Why couldn't the bicycle stand up by itself? Because it was two-tired!\"\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class MyDeps:\n",
    "    api_key: str\n",
    "    http_client: httpx.AsyncClient\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    ollama_model,\n",
    "    deps_type=MyDeps,\n",
    ")\n",
    "\n",
    "\n",
    "@agent.system_prompt  \n",
    "async def get_system_prompt(ctx: RunContext[MyDeps]) -> str:  \n",
    "    response = await ctx.deps.http_client.get(  \n",
    "        'https://example.com',\n",
    "        headers={'Authorization': f'Bearer {ctx.deps.api_key}'},  \n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    return f'Prompt: {response.text}'\n",
    "\n",
    "\n",
    "async with httpx.AsyncClient() as client:\n",
    "    deps = MyDeps('foobar', client)\n",
    "    result = await agent.run('Tell me a joke.', deps=deps)\n",
    "    pp.pprint(result.data)\n",
    "        #> Did you hear about the toothpaste scandal? They called it Colgate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "from pydantic_ai.providers.openai import OpenAIProvider\n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Alright, let me tackle this query about the top five highest-grossing animated films of 2025. The user is asking for a list that's specific to 2025, which means I need to ensure the data provided pertains accurately to that year.\n",
      "\n",
      "First, looking at the tool responses from DuckDuckGo, several sources are cited. Wikipedia mentions \"Ne Zha 2\" surpassing other films and becoming the highest-grossing animated film as of early 2025. Another entry on JustJared lists \"Ne Zha 2\" with a gross of $1.72 billion as of February 20, 2025. This suggests it's at the top.\n",
      "\n",
      "Next, there are mentions of other films like \"Inside Out 2\" being noted in one source as the highest even though Ne Zha 2 overtook it. The Wikipedia entry about box office number ones in the U.S. lists \"Captain America: Brave New World\" as high-grossing domestically for Disney, but since that's a live-action film (part of Captain America franchise), unless it's an animated/live action hybrid, it might not count towards the pure animated list. I need to check if that's considered animated here.\n",
      "\n",
      "The Dexerto article talks about 2024 having success with various sequels like Moana 2 and Despicable Me 4, but the user is asking for 2025, so those might be older entries unless they have continued 2025 earnings. The Statista entry notes \"Inside Out 2\" as #1 as of January 2025, suggesting it's the previous top before Ne Zha 2.\n",
      "\n",
      "Looking at another source from What's After the Movie, their page for 2025 is listed but incomplete in the provided summary (like no titles after rank 1). The IMDB list and the-numbers.com site also refer to 2025 data. \n",
      "\n",
      "I need to compile these sources carefully. Possible contenders beyond Ne Zha 2 might include Inside Out 2, Moana 2, Despicable Me 4, Kung Fu Panda 4 (they were big in 2024 but maybe still grossing into 2025). However, the IMDB list's detail isn't given here. Wikipedia mentions \"Ne Zha 2\" surpassing Inside Out 2 as of early 2025, so perhaps a shift happened.\n",
      "\n",
      "Also, checking for any animated Captain America film? The entry on Captain America: Brave New World is listed under highest-grossing in the US domestic charts but it's possible that isn't an animated movie. Looking at details, Ne Zha is from China, which makes sense as breaking Disney's streak (mentioned in Wikipedia). Disney films like Inside Out 2 are part of their 2024 portfolio but still ongoing into 2025.\n",
      "\n",
      "Putting this together, the top five would likely be:\n",
      "\n",
      "1. Ne Zha 2 – leading with over $1.7B by early 2025\n",
      "2. Inside Out 2 – previously held top spot\n",
      "3. Moana 2 (maybe?)\n",
      "4. Despicable Me 4\n",
      "5. Kung Fu Panda 4? \n",
      "\n",
      "Or perhaps other films like \"Turning Red\" sequels or others, but given the data supplied, those four would fit alongside Ne Zha and Inside Out. Need to note that some might have overlapping years or continued earnings from previous years.\n",
      "\n",
      "I should also consider if any of these entries could be international co-productions or animated/live-action blends affecting their status. Since the query specifies animated films, I can safely list Moana 2, Despicable Me, etc., as they are animated. \n",
      "\n",
      "Potential issue: The Statista data says Inside Out is top until Jan 2025, then Ne Zha overtakes it in February (from JustJared). So ranking order may have changed. Also, other entries like \"Spider-Man: Across the Spider-Verse\" were huge in late 2023 and might still be earning in 2025? But that's probably way past its release date by then.\n",
      "\n",
      "Based on tool responses provided, the top five are:\n",
      "\n",
      "1. Ne Zha 2\n",
      "2. Inside Out 2 (if it held onto second place)\n",
      "Then others like Moana 2 or other mentioned films from 2024 sequels which may have carried over revenue into early 2025. \n",
      "\n",
      "Alternatively, perhaps \"Turning Red\" 2? The user's sources don't name more beyond these.\n",
      "\n",
      "I'll structure the answer listing Ne Zha as #1, then follow with Inside Out 2, and a couple of others based on mentions in the tool data. Need to mention that some films might have been released in late previous year but continued into this one, affecting earnings.\n",
      "</think>\n",
      "\n",
      "Here’s a list of the **top five highest-grossing animated films of 2025**, based on the search results provided (note that these reflect projections or early-year data as of January/February 2025):\n",
      "\n",
      "---\n",
      "\n",
      "### **1. *Ne Zha 2***  \n",
      "- **Gross**: Over **$1.72 billion** worldwide (as of February 20, 2025; via JustJared).  \n",
      "- **Notable**: Surpassed *Inside Out 2* to become the **highest-grossing animated film ever** in early 2025 (Wikipedia/JustJared sources).  \n",
      "\n",
      "---\n",
      "\n",
      "### **2. *Inside Out 2***  \n",
      "- **Gross**: ~$1.7 billion worldwide by January 2025 (*Statista* and Wikipedia mentions pre-January performance).  \n",
      "- **Status**: Previously held the top spot until overtaken by *Ne Zha 2*.  \n",
      "\n",
      "---\n",
      "\n",
      "### **3. *Moana 2***  \n",
      "- **Gross**: While exact figures for 2025 aren’t detailed in tool results, its strong 2024 release (mentioned in Dexerto) likely carried strong earnings into early 2025 due to continued global popularity and streaming performance.  \n",
      "\n",
      "---\n",
      "\n",
      "### **4. *Despicable Me 4***  \n",
      "- **Gross**: Likely high-ranking based on the franchise’s track record and mention alongside Moana/Inside Out as a 2023–2024 hit in Dexerto’s coverage of late 2024 earnings.  \n",
      "\n",
      "---\n",
      "\n",
      "### **5. *Kung Fu Panda 4***  \n",
      "- **Gross**: Similar to above, positioned among top-grossing sequels from previous years with carryover box office revenue (referenced in Dexerto’s article).  \n",
      "\n",
      "---\n",
      "\n",
      "### Key Notes:  \n",
      "- These rankings depend on when films were released (late 2023–2024 vs. early 2025) and ongoing earnings. For example:  \n",
      "  - *Ne Zha 2* is highlighted as a **breakout hit of early 2025**, propelled by its Chinese market dominance.  \n",
      "  - Disney’s franchises (*Inside Out*, *Moana*) rely on widespread international appeal and sequel momentum.  \n",
      "\n",
      "- Non-animated films like *Captain America: Brave New World* (noted in U.S. domestic charts) are excluded here, as they aren’t animated titles.  \n",
      "\n",
      "For precise 2025 rankings by year-end 2025, updates would be needed to account for full-year performance and new releases later in the year.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nI looked into several sources on animated box‐office performance in 2025, and while detailed\\nrankings can shift as more money is tallied, multiple independent reports have already\\nhighlighted a couple of record‐breaking shows. For example:\\n\\n• Ne Zha 2 – News outlets (Variety, Wikipedia\\'s \"List of animated feature films of 2025\", and others)\\n    have reported that this Chinese title not only became the highest‑grossing animated film of 2025\\n    but also broke records as the highest‑grossing non‑English animated film ever. One article noted\\n    its run exceeded US$1.7 billion.\\n• Inside Out 2 – According to data shared on Statista and in industry news, this Pixar sequel has been\\n    on pace to set new records (with some sources even noting it as the highest‑grossing animated film\\n    ever, as of January 2025).\\n\\nBeyond those two, some entertainment trade sites (for example, a Just Jared article titled\\n\"Top 10 Highest-Earning Animated Films at the Box Office Revealed\") have begun listing a broader\\ntop‑10. Although full consolidated figures can sometimes differ by source and are updated daily during\\na box‑office run, many of the industry trackers have begun to single out five films as the biggest\\nearners so far in 2025.\\n\\nUnfortunately, although multiple articles discuss the \"top animated films\" of 2025, there isn\\'t yet a\\nsingle, universally accepted list with final numbers that names the complete top five. (Box‑office\\nrankings, especially mid‑year, can be fluid as films continue to add to their totals.)\\n\\nBased on what several sources note so far, the two undisputed leaders are:\\n1. Ne Zha 2\\n2. Inside Out 2\\n\\nThe remaining top spots (3–5) are reported by some outlets in their \"Top‑10 Animated Films\"\\nlists for 2025 but the titles and order can vary depending on the source and the exact cut‑off\\ndate of the data. For the most up‑to‑date and detailed ranking (including the 3rd, 4th, and 5th\\nhighest‑grossing films), I recommend checking resources like:\\n• Wikipedia\\'s \"List of animated feature films of 2025\" page\\n• Box‑office tracking sites (such as Box Office Mojo or The Numbers)\\n• Trade articles like the one on Just Jared\\n\\nTo summarize with what is clear from the current reporting:\\n1. Ne Zha 2\\n2. Inside Out 2\\n3–5. Other animated films (yet to be definitively finalized across all reporting outlets)\\n\\nIf you\\'re looking for a final, consensus list of the top five, it may be best to wait until\\nthe 2025 year‑end box‑office tallies are in or to consult a regularly updated entertainment industry source.\\n\\nWould you like help finding a current source or additional details on where to look for the complete updated list?\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic_ai.common_tools.duckduckgo import duckduckgo_search_tool\n",
    "from pydantic_ai import Agent\n",
    "ollama_model = OpenAIModel(\n",
    "    model_name='qwq:32b', provider=OpenAIProvider(base_url='http://localhost:11434/v1')\n",
    ")\n",
    "agent = Agent(ollama_model)\n",
    "agent = Agent(\n",
    "    ollama_model,\n",
    "    tools=[duckduckgo_search_tool()],\n",
    "    system_prompt='Search DuckDuckGo for the given query and return the results.',\n",
    ")\n",
    "\n",
    "result = agent.run_sync(\n",
    "    'Can you list the top five highest-grossing animated films of 2025?'\n",
    ")\n",
    "print(result.data)\n",
    "\"\"\"\n",
    "I looked into several sources on animated box‐office performance in 2025, and while detailed\n",
    "rankings can shift as more money is tallied, multiple independent reports have already\n",
    "highlighted a couple of record‐breaking shows. For example:\n",
    "\n",
    "• Ne Zha 2 – News outlets (Variety, Wikipedia's \"List of animated feature films of 2025\", and others)\n",
    "    have reported that this Chinese title not only became the highest‑grossing animated film of 2025\n",
    "    but also broke records as the highest‑grossing non‑English animated film ever. One article noted\n",
    "    its run exceeded US$1.7 billion.\n",
    "• Inside Out 2 – According to data shared on Statista and in industry news, this Pixar sequel has been\n",
    "    on pace to set new records (with some sources even noting it as the highest‑grossing animated film\n",
    "    ever, as of January 2025).\n",
    "\n",
    "Beyond those two, some entertainment trade sites (for example, a Just Jared article titled\n",
    "\"Top 10 Highest-Earning Animated Films at the Box Office Revealed\") have begun listing a broader\n",
    "top‑10. Although full consolidated figures can sometimes differ by source and are updated daily during\n",
    "a box‑office run, many of the industry trackers have begun to single out five films as the biggest\n",
    "earners so far in 2025.\n",
    "\n",
    "Unfortunately, although multiple articles discuss the \"top animated films\" of 2025, there isn't yet a\n",
    "single, universally accepted list with final numbers that names the complete top five. (Box‑office\n",
    "rankings, especially mid‑year, can be fluid as films continue to add to their totals.)\n",
    "\n",
    "Based on what several sources note so far, the two undisputed leaders are:\n",
    "1. Ne Zha 2\n",
    "2. Inside Out 2\n",
    "\n",
    "The remaining top spots (3–5) are reported by some outlets in their \"Top‑10 Animated Films\"\n",
    "lists for 2025 but the titles and order can vary depending on the source and the exact cut‑off\n",
    "date of the data. For the most up‑to‑date and detailed ranking (including the 3rd, 4th, and 5th\n",
    "highest‑grossing films), I recommend checking resources like:\n",
    "• Wikipedia's \"List of animated feature films of 2025\" page\n",
    "• Box‑office tracking sites (such as Box Office Mojo or The Numbers)\n",
    "• Trade articles like the one on Just Jared\n",
    "\n",
    "To summarize with what is clear from the current reporting:\n",
    "1. Ne Zha 2\n",
    "2. Inside Out 2\n",
    "3–5. Other animated films (yet to be definitively finalized across all reporting outlets)\n",
    "\n",
    "If you're looking for a final, consensus list of the top five, it may be best to wait until\n",
    "the 2025 year‑end box‑office tallies are in or to consult a regularly updated entertainment industry source.\n",
    "\n",
    "Would you like help finding a current source or additional details on where to look for the complete updated list?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/MCP/fastmcp/.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 8ms\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/MCP/fastmcp/.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 8ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! uv pip install 'pydantic-ai-slim[tavily]'\n",
    "! uv pip install 'pydantic-ai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnexpectedModelBehavior",
     "evalue": "Tool exceeded max retries count of 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MCP/fastmcp/.venv/lib/python3.12/site-packages/pydantic_ai/tools.py:273\u001b[39m, in \u001b[36mTool.run\u001b[39m\u001b[34m(self, message, run_context)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message.args, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m273\u001b[39m     args_dict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for __call__\ntime_range\n  Input should be 'day', 'week', 'month', 'year', 'd', 'w', 'm' or 'y' [type=literal_error, input_value='7d', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.10/v/literal_error",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mUnexpectedModelBehavior\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      6\u001b[39m api_key=os.environ[\u001b[33m'\u001b[39m\u001b[33mTAVILY_API_KEY\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     10\u001b[39m agent = Agent(\n\u001b[32m     11\u001b[39m     ollama_model,\n\u001b[32m     12\u001b[39m     tools=[tavily_search_tool(api_key)],\n\u001b[32m     13\u001b[39m     system_prompt=\u001b[33m'\u001b[39m\u001b[33mSearch Tavily for the given query and return the results.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     14\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m result = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_sync\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTell me the top news in the GenAI world, give me links.\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(result.data)\n\u001b[32m     18\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[33;03mHere are some of the top recent news articles related to GenAI:\u001b[39;00m\n\u001b[32m     20\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m \u001b[33;03mFeel free to click on the links to dive deeper into each story!\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MCP/fastmcp/.venv/lib/python3.12/site-packages/pydantic_ai/agent.py:558\u001b[39m, in \u001b[36mAgent.run_sync\u001b[39m\u001b[34m(self, user_prompt, result_type, message_history, model, deps, model_settings, usage_limits, usage, infer_name)\u001b[39m\n\u001b[32m    556\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m infer_name \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    557\u001b[39m     \u001b[38;5;28mself\u001b[39m._infer_name(inspect.currentframe())\n\u001b[32m--> \u001b[39m\u001b[32m558\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_event_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresult_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresult_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage_history\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_history\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m        \u001b[49m\u001b[43musage_limits\u001b[49m\u001b[43m=\u001b[49m\u001b[43musage_limits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m        \u001b[49m\u001b[43musage\u001b[49m\u001b[43m=\u001b[49m\u001b[43musage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m        \u001b[49m\u001b[43minfer_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MCP/fastmcp/.venv/lib/python3.12/site-packages/nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/asyncio/futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/asyncio/tasks.py:314\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    311\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    313\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    316\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MCP/fastmcp/.venv/lib/python3.12/site-packages/pydantic_ai/agent.py:316\u001b[39m, in \u001b[36mAgent.run\u001b[39m\u001b[34m(self, user_prompt, result_type, message_history, model, deps, model_settings, usage_limits, usage, infer_name)\u001b[39m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28mself\u001b[39m._infer_name(inspect.currentframe())\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter(\n\u001b[32m    307\u001b[39m     user_prompt=user_prompt,\n\u001b[32m    308\u001b[39m     result_type=result_type,\n\u001b[32m   (...)\u001b[39m\u001b[32m    314\u001b[39m     usage=usage,\n\u001b[32m    315\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agent_run:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m agent_run:\n\u001b[32m    317\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (final_result := agent_run.result) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mThe graph run did not finish properly\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MCP/fastmcp/.venv/lib/python3.12/site-packages/pydantic_ai/agent.py:1352\u001b[39m, in \u001b[36mAgentRun.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1348\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__anext__\u001b[39m(\n\u001b[32m   1349\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1350\u001b[39m ) -> _agent_graph.AgentNode[AgentDepsT, ResultDataT] | End[FinalResult[ResultDataT]]:\n\u001b[32m   1351\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Advance to the next node automatically based on the last returned node.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1352\u001b[39m     next_node = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._graph_run.\u001b[34m__anext__\u001b[39m()\n\u001b[32m   1353\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _agent_graph.is_agent_node(next_node):\n\u001b[32m   1354\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m next_node\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MCP/fastmcp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py:734\u001b[39m, in \u001b[36mGraphRun.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    732\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._next_node, End):\n\u001b[32m    733\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.next(\u001b[38;5;28mself\u001b[39m._next_node)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MCP/fastmcp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py:723\u001b[39m, in \u001b[36mGraphRun.next\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m    720\u001b[39m state = \u001b[38;5;28mself\u001b[39m.state\n\u001b[32m    721\u001b[39m deps = \u001b[38;5;28mself\u001b[39m.deps\n\u001b[32m--> \u001b[39m\u001b[32m723\u001b[39m \u001b[38;5;28mself\u001b[39m._next_node = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.graph.next(node, history, state=state, deps=deps, infer_name=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    725\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._next_node\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MCP/fastmcp/.venv/lib/python3.12/site-packages/pydantic_graph/graph.py:305\u001b[39m, in \u001b[36mGraph.next\u001b[39m\u001b[34m(self, node, history, state, deps, infer_name)\u001b[39m\n\u001b[32m    303\u001b[39m     start_ts = _utils.now_utc()\n\u001b[32m    304\u001b[39m     start = perf_counter()\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m     next_node = \u001b[38;5;28;01mawait\u001b[39;00m node.run(ctx)\n\u001b[32m    306\u001b[39m     duration = perf_counter() - start\n\u001b[32m    308\u001b[39m history.append(\n\u001b[32m    309\u001b[39m     NodeStep(state=state, node=node, start_ts=start_ts, duration=duration, snapshot_state=\u001b[38;5;28mself\u001b[39m.snapshot_state)\n\u001b[32m    310\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MCP/fastmcp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py:365\u001b[39m, in \u001b[36mCallToolsNode.run\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\n\u001b[32m    363\u001b[39m     \u001b[38;5;28mself\u001b[39m, ctx: GraphRunContext[GraphAgentState, GraphAgentDeps[DepsT, NodeRunEndT]]\n\u001b[32m    364\u001b[39m ) -> Union[ModelRequestNode[DepsT, NodeRunEndT], End[result.FinalResult[NodeRunEndT]]]:  \u001b[38;5;66;03m# noqa UP007\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream(ctx):\n\u001b[32m    366\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    368\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m (next_node := \u001b[38;5;28mself\u001b[39m._next_node) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mthe stream should set `self._next_node` before it ends\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/contextlib.py:217\u001b[39m, in \u001b[36m_AsyncGeneratorContextManager.__aexit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m anext(\u001b[38;5;28mself\u001b[39m.gen)\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m:\n\u001b[32m    219\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MCP/fastmcp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py:380\u001b[39m, in \u001b[36mCallToolsNode.stream\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m stream\n\u001b[32m    379\u001b[39m \u001b[38;5;66;03m# Run the stream to completion if it was not finished:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m380\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _event \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[32m    381\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MCP/fastmcp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py:417\u001b[39m, in \u001b[36mCallToolsNode._run_stream\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    413\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m exceptions.UnexpectedModelBehavior(\u001b[33m'\u001b[39m\u001b[33mReceived empty model response\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    415\u001b[39m     \u001b[38;5;28mself\u001b[39m._events_iterator = _run_stream()\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._events_iterator:\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MCP/fastmcp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py:407\u001b[39m, in \u001b[36mCallToolsNode._run_stream.<locals>._run_stream\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    402\u001b[39m \u001b[38;5;66;03m# At the moment, we prioritize at least executing tool calls if they are present.\u001b[39;00m\n\u001b[32m    403\u001b[39m \u001b[38;5;66;03m# In the future, we'd consider making this configurable at the agent or run level.\u001b[39;00m\n\u001b[32m    404\u001b[39m \u001b[38;5;66;03m# This accounts for cases like anthropic returns that might contain a text response\u001b[39;00m\n\u001b[32m    405\u001b[39m \u001b[38;5;66;03m# and a tool call response, where the text response just indicates the tool call will happen.\u001b[39;00m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tool_calls:\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._handle_tool_calls(ctx, tool_calls):\n\u001b[32m    408\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m texts:\n\u001b[32m    410\u001b[39m     \u001b[38;5;66;03m# No events are emitted during the handling of text responses, so we don't need to yield anything\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MCP/fastmcp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py:446\u001b[39m, in \u001b[36mCallToolsNode._handle_tool_calls\u001b[39m\u001b[34m(self, ctx, tool_calls)\u001b[39m\n\u001b[32m    444\u001b[39m \u001b[38;5;66;03m# Then build the other request parts based on end strategy\u001b[39;00m\n\u001b[32m    445\u001b[39m tool_responses: \u001b[38;5;28mlist\u001b[39m[_messages.ModelRequestPart] = \u001b[38;5;28mself\u001b[39m._tool_responses\n\u001b[32m--> \u001b[39m\u001b[32m446\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m process_function_tools(\n\u001b[32m    447\u001b[39m     tool_calls,\n\u001b[32m    448\u001b[39m     final_result \u001b[38;5;129;01mand\u001b[39;00m final_result.tool_name,\n\u001b[32m    449\u001b[39m     final_result \u001b[38;5;129;01mand\u001b[39;00m final_result.tool_call_id,\n\u001b[32m    450\u001b[39m     ctx,\n\u001b[32m    451\u001b[39m     tool_responses,\n\u001b[32m    452\u001b[39m ):\n\u001b[32m    453\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m final_result:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MCP/fastmcp/.venv/lib/python3.12/site-packages/pydantic_ai/_agent_graph.py:631\u001b[39m, in \u001b[36mprocess_function_tools\u001b[39m\u001b[34m(tool_calls, result_tool_name, result_tool_call_id, ctx, output_parts)\u001b[39m\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m done:\n\u001b[32m    630\u001b[39m     index = tasks.index(task)\n\u001b[32m--> \u001b[39m\u001b[32m631\u001b[39m     result = \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    632\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m _messages.FunctionToolResultEvent(result, tool_call_id=call_index_to_event_id[index])\n\u001b[32m    633\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, (_messages.ToolReturnPart, _messages.RetryPromptPart)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/asyncio/futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/asyncio/tasks.py:314\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    311\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    313\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    316\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MCP/fastmcp/.venv/lib/python3.12/site-packages/pydantic_ai/tools.py:277\u001b[39m, in \u001b[36mTool.run\u001b[39m\u001b[34m(self, message, run_context)\u001b[39m\n\u001b[32m    275\u001b[39m         args_dict = \u001b[38;5;28mself\u001b[39m._validator.validate_python(message.args)\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_on_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m args, kwargs = \u001b[38;5;28mself\u001b[39m._call_args(args_dict, message, run_context)\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MCP/fastmcp/.venv/lib/python3.12/site-packages/pydantic_ai/tools.py:325\u001b[39m, in \u001b[36mTool._on_error\u001b[39m\u001b[34m(self, exc, call_message)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;28mself\u001b[39m.current_retry += \u001b[32m1\u001b[39m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.max_retries \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.current_retry > \u001b[38;5;28mself\u001b[39m.max_retries:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedModelBehavior(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mTool exceeded max retries count of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.max_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    327\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, ValidationError):\n",
      "\u001b[31mUnexpectedModelBehavior\u001b[39m: Tool exceeded max retries count of 1"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from pydantic_ai.agent import Agent\n",
    "from pydantic_ai.common_tools.tavily import tavily_search_tool\n",
    "\n",
    "api_key=os.environ['TAVILY_API_KEY']\n",
    "\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    ollama_model,\n",
    "    tools=[tavily_search_tool(api_key)],\n",
    "    system_prompt='Search Tavily for the given query and return the results.',\n",
    ")\n",
    "\n",
    "result = agent.run_sync('Tell me the top news in the GenAI world, give me links.')\n",
    "print(result.data)\n",
    "\"\"\"\n",
    "Here are some of the top recent news articles related to GenAI:\n",
    "\n",
    "1. How CLEAR users can improve risk analysis with GenAI – Thomson Reuters\n",
    "   Read more: https://legal.thomsonreuters.com/blog/how-clear-users-can-improve-risk-analysis-with-genai/\n",
    "   (This article discusses how CLEAR's new GenAI-powered tool streamlines risk analysis by quickly summarizing key information from various public data sources.)\n",
    "\n",
    "2. TELUS Digital Survey Reveals Enterprise Employees Are Entering Sensitive Data Into AI Assistants More Than You Think – FT.com\n",
    "   Read more: https://markets.ft.com/data/announce/detail?dockey=600-202502260645BIZWIRE_USPRX____20250226_BW490609-1\n",
    "   (This news piece highlights findings from a TELUS Digital survey showing that many enterprise employees use public GenAI tools and sometimes even enter sensitive data.)\n",
    "\n",
    "3. The Essential Guide to Generative AI – Virtualization Review\n",
    "   Read more: https://virtualizationreview.com/Whitepapers/2025/02/SNOWFLAKE-The-Essential-Guide-to-Generative-AI.aspx\n",
    "   (This guide provides insights into how GenAI is revolutionizing enterprise strategies and productivity, with input from industry leaders.)\n",
    "\n",
    "Feel free to click on the links to dive deeper into each story!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Usage(requests=2, request_tokens=1655, response_tokens=1901, total_tokens=3556, details=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<think>\\n'\n",
      " 'Alright, let me tackle this query about the top five highest-grossing '\n",
      " \"animated films of 2025. The user is asking for a list that's specific to \"\n",
      " '2025, which means I need to ensure the data provided pertains accurately to '\n",
      " 'that year.\\n'\n",
      " '\\n'\n",
      " 'First, looking at the tool responses from DuckDuckGo, several sources are '\n",
      " 'cited. Wikipedia mentions \"Ne Zha 2\" surpassing other films and becoming the '\n",
      " 'highest-grossing animated film as of early 2025. Another entry on JustJared '\n",
      " 'lists \"Ne Zha 2\" with a gross of $1.72 billion as of February 20, 2025. This '\n",
      " \"suggests it's at the top.\\n\"\n",
      " '\\n'\n",
      " 'Next, there are mentions of other films like \"Inside Out 2\" being noted in '\n",
      " 'one source as the highest even though Ne Zha 2 overtook it. The Wikipedia '\n",
      " 'entry about box office number ones in the U.S. lists \"Captain America: Brave '\n",
      " 'New World\" as high-grossing domestically for Disney, but since that\\'s a '\n",
      " \"live-action film (part of Captain America franchise), unless it's an \"\n",
      " 'animated/live action hybrid, it might not count towards the pure animated '\n",
      " \"list. I need to check if that's considered animated here.\\n\"\n",
      " '\\n'\n",
      " 'The Dexerto article talks about 2024 having success with various sequels '\n",
      " 'like Moana 2 and Despicable Me 4, but the user is asking for 2025, so those '\n",
      " 'might be older entries unless they have continued 2025 earnings. The '\n",
      " 'Statista entry notes \"Inside Out 2\" as #1 as of January 2025, suggesting '\n",
      " \"it's the previous top before Ne Zha 2.\\n\"\n",
      " '\\n'\n",
      " \"Looking at another source from What's After the Movie, their page for 2025 \"\n",
      " 'is listed but incomplete in the provided summary (like no titles after rank '\n",
      " '1). The IMDB list and the-numbers.com site also refer to 2025 data. \\n'\n",
      " '\\n'\n",
      " 'I need to compile these sources carefully. Possible contenders beyond Ne Zha '\n",
      " '2 might include Inside Out 2, Moana 2, Despicable Me 4, Kung Fu Panda 4 '\n",
      " '(they were big in 2024 but maybe still grossing into 2025). However, the '\n",
      " 'IMDB list\\'s detail isn\\'t given here. Wikipedia mentions \"Ne Zha 2\" '\n",
      " 'surpassing Inside Out 2 as of early 2025, so perhaps a shift happened.\\n'\n",
      " '\\n'\n",
      " 'Also, checking for any animated Captain America film? The entry on Captain '\n",
      " 'America: Brave New World is listed under highest-grossing in the US domestic '\n",
      " \"charts but it's possible that isn't an animated movie. Looking at details, \"\n",
      " \"Ne Zha is from China, which makes sense as breaking Disney's streak \"\n",
      " '(mentioned in Wikipedia). Disney films like Inside Out 2 are part of their '\n",
      " '2024 portfolio but still ongoing into 2025.\\n'\n",
      " '\\n'\n",
      " 'Putting this together, the top five would likely be:\\n'\n",
      " '\\n'\n",
      " '1. Ne Zha 2 – leading with over $1.7B by early 2025\\n'\n",
      " '2. Inside Out 2 – previously held top spot\\n'\n",
      " '3. Moana 2 (maybe?)\\n'\n",
      " '4. Despicable Me 4\\n'\n",
      " '5. Kung Fu Panda 4? \\n'\n",
      " '\\n'\n",
      " 'Or perhaps other films like \"Turning Red\" sequels or others, but given the '\n",
      " 'data supplied, those four would fit alongside Ne Zha and Inside Out. Need to '\n",
      " 'note that some might have overlapping years or continued earnings from '\n",
      " 'previous years.\\n'\n",
      " '\\n'\n",
      " 'I should also consider if any of these entries could be international '\n",
      " 'co-productions or animated/live-action blends affecting their status. Since '\n",
      " 'the query specifies animated films, I can safely list Moana 2, Despicable '\n",
      " 'Me, etc., as they are animated. \\n'\n",
      " '\\n'\n",
      " 'Potential issue: The Statista data says Inside Out is top until Jan 2025, '\n",
      " 'then Ne Zha overtakes it in February (from JustJared). So ranking order may '\n",
      " 'have changed. Also, other entries like \"Spider-Man: Across the Spider-Verse\" '\n",
      " \"were huge in late 2023 and might still be earning in 2025? But that's \"\n",
      " 'probably way past its release date by then.\\n'\n",
      " '\\n'\n",
      " 'Based on tool responses provided, the top five are:\\n'\n",
      " '\\n'\n",
      " '1. Ne Zha 2\\n'\n",
      " '2. Inside Out 2 (if it held onto second place)\\n'\n",
      " 'Then others like Moana 2 or other mentioned films from 2024 sequels which '\n",
      " 'may have carried over revenue into early 2025. \\n'\n",
      " '\\n'\n",
      " 'Alternatively, perhaps \"Turning Red\" 2? The user\\'s sources don\\'t name more '\n",
      " 'beyond these.\\n'\n",
      " '\\n'\n",
      " \"I'll structure the answer listing Ne Zha as #1, then follow with Inside Out \"\n",
      " '2, and a couple of others based on mentions in the tool data. Need to '\n",
      " 'mention that some films might have been released in late previous year but '\n",
      " 'continued into this one, affecting earnings.\\n'\n",
      " '</think>\\n'\n",
      " '\\n'\n",
      " 'Here’s a list of the **top five highest-grossing animated films of 2025**, '\n",
      " 'based on the search results provided (note that these reflect projections or '\n",
      " 'early-year data as of January/February 2025):\\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### **1. *Ne Zha 2***  \\n'\n",
      " '- **Gross**: Over **$1.72 billion** worldwide (as of February 20, 2025; via '\n",
      " 'JustJared).  \\n'\n",
      " '- **Notable**: Surpassed *Inside Out 2* to become the **highest-grossing '\n",
      " 'animated film ever** in early 2025 (Wikipedia/JustJared sources).  \\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### **2. *Inside Out 2***  \\n'\n",
      " '- **Gross**: ~$1.7 billion worldwide by January 2025 (*Statista* and '\n",
      " 'Wikipedia mentions pre-January performance).  \\n'\n",
      " '- **Status**: Previously held the top spot until overtaken by *Ne Zha 2*.  \\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### **3. *Moana 2***  \\n'\n",
      " '- **Gross**: While exact figures for 2025 aren’t detailed in tool results, '\n",
      " 'its strong 2024 release (mentioned in Dexerto) likely carried strong '\n",
      " 'earnings into early 2025 due to continued global popularity and streaming '\n",
      " 'performance.  \\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### **4. *Despicable Me 4***  \\n'\n",
      " '- **Gross**: Likely high-ranking based on the franchise’s track record and '\n",
      " 'mention alongside Moana/Inside Out as a 2023–2024 hit in Dexerto’s coverage '\n",
      " 'of late 2024 earnings.  \\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### **5. *Kung Fu Panda 4***  \\n'\n",
      " '- **Gross**: Similar to above, positioned among top-grossing sequels from '\n",
      " 'previous years with carryover box office revenue (referenced in Dexerto’s '\n",
      " 'article).  \\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### Key Notes:  \\n'\n",
      " '- These rankings depend on when films were released (late 2023–2024 vs. '\n",
      " 'early 2025) and ongoing earnings. For example:  \\n'\n",
      " '  - *Ne Zha 2* is highlighted as a **breakout hit of early 2025**, propelled '\n",
      " 'by its Chinese market dominance.  \\n'\n",
      " '  - Disney’s franchises (*Inside Out*, *Moana*) rely on widespread '\n",
      " 'international appeal and sequel momentum.  \\n'\n",
      " '\\n'\n",
      " '- Non-animated films like *Captain America: Brave New World* (noted in U.S. '\n",
      " 'domestic charts) are excluded here, as they aren’t animated titles.  \\n'\n",
      " '\\n'\n",
      " 'For precise 2025 rankings by year-end 2025, updates would be needed to '\n",
      " 'account for full-year performance and new releases later in the year.')\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(result.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Message history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ModelRequest(parts=[SystemPromptPart(content='Search DuckDuckGo for the given query and return the results.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='Can you list the top five highest-grossing animated films of 2025?', timestamp=datetime.datetime(2025, 3, 7, 19, 25, 23, 42614, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'),\n",
       " ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='duckduckgo_search', args='{\"query\":\"top five highest-grossing animated films of 2025\"}', tool_call_id='call_fzfnjuvc', part_kind='tool-call')], model_name='qwq:32b', timestamp=datetime.datetime(2025, 3, 7, 19, 26, 8, tzinfo=datetime.timezone.utc), kind='response'),\n",
       " ModelRequest(parts=[ToolReturnPart(tool_name='duckduckgo_search', content=[{'title': 'List of animated feature films of 2025 - Wikipedia', 'href': 'https://en.wikipedia.org/wiki/List_of_animated_feature_films_of_2025', 'body': \"Ne Zha 2 surpassed The Battle at Lake Changjin to become the highest-grossing Chinese film and highest-grossing non-English film. [110] It is currently the 7th highest grossing film of all time. [111]It surpassed Inside Out 2 to become the highest-grossing animated film of all time, [112] the first non-English film/studio to do so and breaking Disney's 14-year streak with the title after ...\"}, {'title': \"Top Animation Movies of 2025 - Best Animation Films | What's After the ...\", 'href': 'https://www.whatsafterthemovie.com/box-office/genre/animation/year/2025', 'body': \"Find out which Animation films topped the box office in 2025 with What's After the Movie. Dive into the world of Animation cinema and see the year's highest performers. ... Return. Box Office . Top Grossing Animation Movies in 2025 . Previous Year (2024) Next Year (2026) Rank Title Language Domestic Worldwide 1 :\"}, {'title': 'List of 2025 box office number-one films in the United States', 'href': 'https://en.wikipedia.org/wiki/List_of_2025_box_office_number-one_films_in_the_United_States', 'body': 'Captain America: Brave New World became the first film of 2025 to top the box office for three consecutive weekends. [10] Highest-grossing films. Highest-grossing films of 2025 by In-year release [11] Rank Title Distributor Domestic gross 1. Captain America: Brave New World: Disney: $167,151,846 2.'}, {'title': 'Top 10 Highest-Earning Animated Films at the Box Office Revealed ...', 'href': 'https://www.justjared.com/2025/02/17/top-10-highest-earning-animated-films-at-the-box-office-revealed-disney-dominates/6/', 'body': '1. Ne Zha 2. Studio: CMC Pictures Year Released: 2025 All Time Gross: $1.72 billion (As of February 20, 2025). Synopsis: After the heavenly lightning, although Ne Zha and Ao Bing survived by ...'}, {'title': 'Box Office Performance for Animation/Live Action Movies in 2025', 'href': 'https://www.the-numbers.com/market/2025/production-method/Animation-and-Live-Action', 'body': 'It includes movies released in previous years that earned money during 2025. For example, a movie released over Thanksgiving in 2010 will most likely earn money in 2010 and 2011. Click on the individual movie to see its total gross over all the years in which it played.'}, {'title': 'Biggest box office hits of 2025, including The Monkey', 'href': 'https://www.dexerto.com/tv-movies/highest-grossing-movies-2025-box-office-3142332/', 'body': '2024 was an interesting year at the global box office, with animated movies like Inside Out 2, Moana 2, Despicable Me 4, and Kung Fu Panda 4 all making a mint in cinemas, while Deadpool ...'}, {'title': 'The Numbers - Movie Market Summary for Year 2025', 'href': 'https://m.the-numbers.com/market/2025/summary', 'body': 'Top Grossing Movies of 2025. Rank Movie Release Date Distributor Genre 2025 ... The highest values in the column(s) No. 1 Box Office, ... 5: Stop-Motion Animation: 1: $45,868: 4,255: 0.00%: See complete chart Market Share for Each Creative Type in 2025. Rank Creative Type Movies 2025 Gross Tickets'}, {'title': 'Highest grossing animated movies ever 2025 | Statista', 'href': 'https://www.statista.com/statistics/1482040/highest-grossing-animated-movies-box-office-worldwide/', 'body': 'As of January 2025, \"Inside Out 2\" (2024) was the highest-grossing animated feature film ever released, grossing 1.7 billion U.S.'}, {'title': '2025 WORLDWIDE BOX OFFICE! The 100 Highest Grossing Films of the ... - IMDb', 'href': 'https://www.imdb.com/list/ls595371725/', 'body': 'This list is an overview of the Worldwide Box Office 2025 and includes the most successful films worldwide and the biggest box office hits of the film year 2025, what means all theatrical released hit films which made the audience go to cinema in different countries and all around the world that year. Here are the box office results of all the top-grossing films from the USA, China, India ...'}, {'title': 'Top 2025 Movies at the Worldwide Box Office', 'href': 'https://thenumbers.com/box-office-records/worldwide/all-movies/cumulative/released-in-2025', 'body': 'Top 2025 Movies at the Worldwide Box Office See also: Top 2025 Domestic - Top 2025 International Other Worldwide Cumulative records: All Time Worldwide - All Time Single Market - All Time Animated Worldwide - All Time Sequel Worldwide - All Time Non-Sequel Worldwide. This chart contains the total worldwide box office for the movies released in ...'}], tool_call_id='call_fzfnjuvc', timestamp=datetime.datetime(2025, 3, 7, 19, 26, 9, 703561, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'),\n",
       " ModelResponse(parts=[TextPart(content='<think>\\nAlright, let me tackle this query about the top five highest-grossing animated films of 2025. The user is asking for a list that\\'s specific to 2025, which means I need to ensure the data provided pertains accurately to that year.\\n\\nFirst, looking at the tool responses from DuckDuckGo, several sources are cited. Wikipedia mentions \"Ne Zha 2\" surpassing other films and becoming the highest-grossing animated film as of early 2025. Another entry on JustJared lists \"Ne Zha 2\" with a gross of $1.72 billion as of February 20, 2025. This suggests it\\'s at the top.\\n\\nNext, there are mentions of other films like \"Inside Out 2\" being noted in one source as the highest even though Ne Zha 2 overtook it. The Wikipedia entry about box office number ones in the U.S. lists \"Captain America: Brave New World\" as high-grossing domestically for Disney, but since that\\'s a live-action film (part of Captain America franchise), unless it\\'s an animated/live action hybrid, it might not count towards the pure animated list. I need to check if that\\'s considered animated here.\\n\\nThe Dexerto article talks about 2024 having success with various sequels like Moana 2 and Despicable Me 4, but the user is asking for 2025, so those might be older entries unless they have continued 2025 earnings. The Statista entry notes \"Inside Out 2\" as #1 as of January 2025, suggesting it\\'s the previous top before Ne Zha 2.\\n\\nLooking at another source from What\\'s After the Movie, their page for 2025 is listed but incomplete in the provided summary (like no titles after rank 1). The IMDB list and the-numbers.com site also refer to 2025 data. \\n\\nI need to compile these sources carefully. Possible contenders beyond Ne Zha 2 might include Inside Out 2, Moana 2, Despicable Me 4, Kung Fu Panda 4 (they were big in 2024 but maybe still grossing into 2025). However, the IMDB list\\'s detail isn\\'t given here. Wikipedia mentions \"Ne Zha 2\" surpassing Inside Out 2 as of early 2025, so perhaps a shift happened.\\n\\nAlso, checking for any animated Captain America film? The entry on Captain America: Brave New World is listed under highest-grossing in the US domestic charts but it\\'s possible that isn\\'t an animated movie. Looking at details, Ne Zha is from China, which makes sense as breaking Disney\\'s streak (mentioned in Wikipedia). Disney films like Inside Out 2 are part of their 2024 portfolio but still ongoing into 2025.\\n\\nPutting this together, the top five would likely be:\\n\\n1. Ne Zha 2 – leading with over $1.7B by early 2025\\n2. Inside Out 2 – previously held top spot\\n3. Moana 2 (maybe?)\\n4. Despicable Me 4\\n5. Kung Fu Panda 4? \\n\\nOr perhaps other films like \"Turning Red\" sequels or others, but given the data supplied, those four would fit alongside Ne Zha and Inside Out. Need to note that some might have overlapping years or continued earnings from previous years.\\n\\nI should also consider if any of these entries could be international co-productions or animated/live-action blends affecting their status. Since the query specifies animated films, I can safely list Moana 2, Despicable Me, etc., as they are animated. \\n\\nPotential issue: The Statista data says Inside Out is top until Jan 2025, then Ne Zha overtakes it in February (from JustJared). So ranking order may have changed. Also, other entries like \"Spider-Man: Across the Spider-Verse\" were huge in late 2023 and might still be earning in 2025? But that\\'s probably way past its release date by then.\\n\\nBased on tool responses provided, the top five are:\\n\\n1. Ne Zha 2\\n2. Inside Out 2 (if it held onto second place)\\nThen others like Moana 2 or other mentioned films from 2024 sequels which may have carried over revenue into early 2025. \\n\\nAlternatively, perhaps \"Turning Red\" 2? The user\\'s sources don\\'t name more beyond these.\\n\\nI\\'ll structure the answer listing Ne Zha as #1, then follow with Inside Out 2, and a couple of others based on mentions in the tool data. Need to mention that some films might have been released in late previous year but continued into this one, affecting earnings.\\n</think>\\n\\nHere’s a list of the **top five highest-grossing animated films of 2025**, based on the search results provided (note that these reflect projections or early-year data as of January/February 2025):\\n\\n---\\n\\n### **1. *Ne Zha 2***  \\n- **Gross**: Over **$1.72 billion** worldwide (as of February 20, 2025; via JustJared).  \\n- **Notable**: Surpassed *Inside Out 2* to become the **highest-grossing animated film ever** in early 2025 (Wikipedia/JustJared sources).  \\n\\n---\\n\\n### **2. *Inside Out 2***  \\n- **Gross**: ~$1.7 billion worldwide by January 2025 (*Statista* and Wikipedia mentions pre-January performance).  \\n- **Status**: Previously held the top spot until overtaken by *Ne Zha 2*.  \\n\\n---\\n\\n### **3. *Moana 2***  \\n- **Gross**: While exact figures for 2025 aren’t detailed in tool results, its strong 2024 release (mentioned in Dexerto) likely carried strong earnings into early 2025 due to continued global popularity and streaming performance.  \\n\\n---\\n\\n### **4. *Despicable Me 4***  \\n- **Gross**: Likely high-ranking based on the franchise’s track record and mention alongside Moana/Inside Out as a 2023–2024 hit in Dexerto’s coverage of late 2024 earnings.  \\n\\n---\\n\\n### **5. *Kung Fu Panda 4***  \\n- **Gross**: Similar to above, positioned among top-grossing sequels from previous years with carryover box office revenue (referenced in Dexerto’s article).  \\n\\n---\\n\\n### Key Notes:  \\n- These rankings depend on when films were released (late 2023–2024 vs. early 2025) and ongoing earnings. For example:  \\n  - *Ne Zha 2* is highlighted as a **breakout hit of early 2025**, propelled by its Chinese market dominance.  \\n  - Disney’s franchises (*Inside Out*, *Moana*) rely on widespread international appeal and sequel momentum.  \\n\\n- Non-animated films like *Captain America: Brave New World* (noted in U.S. domestic charts) are excluded here, as they aren’t animated titles.  \\n\\nFor precise 2025 rankings by year-end 2025, updates would be needed to account for full-year performance and new releases later in the year.', part_kind='text')], model_name='qwq:32b', timestamp=datetime.datetime(2025, 3, 7, 19, 30, 17, tzinfo=datetime.timezone.utc), kind='response')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.all_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent delegation\n",
    "\"Agent delegation\" refers to the scenario where an agent delegates work to another agent, then takes back control when the delegate agent (the agent called from within a tool) finishes.\n",
    "\n",
    "Since agents are stateless and designed to be global, you do not need to include the agent itself in agent dependencies.\n",
    "\n",
    "You'll generally want to pass ctx.usage to the usage keyword argument of the delegate agent run so usage within that run counts towards the total usage of the parent agent run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the joke I've generated for you:\n",
      "\n",
      "Why don't scientists trust atoms? Because they make up everything!\n",
      "\n",
      "I hope this joke brings a smile to your face! Let me know if you need another one or any other help.\n",
      "Usage(requests=1, request_tokens=161, response_tokens=48, total_tokens=209, details=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nUsage(\\n    requests=3, request_tokens=204, response_tokens=24, total_tokens=228, details=None\\n)\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic_ai import Agent, RunContext\n",
    "from pydantic_ai.usage import UsageLimits\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "qwen_model = OpenAIModel(\n",
    "    model_name='qwen2.5-coder:14b', provider=OpenAIProvider(base_url='http://localhost:11434/v1')\n",
    ")\n",
    "\n",
    "joke_selection_agent = Agent(  \n",
    "    qwen_model,\n",
    "    system_prompt=(\n",
    "        'Use the `joke_factory` to generate some jokes, then choose the best. '\n",
    "        'You must return just a single joke.'\n",
    "    ),\n",
    ")\n",
    "joke_generation_agent = Agent(  \n",
    "    qwen_model, result_type=list[str]\n",
    ")\n",
    "\n",
    "@joke_selection_agent.tool\n",
    "async def joke_factory(ctx: RunContext[None], count: int) -> list[str]:\n",
    "    r = await joke_generation_agent.run(  \n",
    "        f'Please generate {count} jokes.'\n",
    "        # usage=ctx.usage,  \n",
    "    )\n",
    "    return r.data  \n",
    "\n",
    "\n",
    "result = joke_selection_agent.run_sync(\n",
    "    'Tell me a joke.'\n",
    "    # usage_limits=UsageLimits(request_limit=5, total_tokens_limit=3000),\n",
    ")\n",
    "print(result.data)\n",
    "#> Did you hear about the toothpaste scandal? They called it Colgate.\n",
    "print(result.usage())\n",
    "\"\"\"\n",
    "Usage(\n",
    "    requests=3, request_tokens=204, response_tokens=24, total_tokens=228, details=None\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ModelRequest(parts=[SystemPromptPart(content='Use the `joke_factory` to generate some jokes, then choose the best. You must return just a single joke.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='Tell me a joke.', timestamp=datetime.datetime(2025, 3, 7, 19, 38, 8, 156676, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'),\n",
       " ModelResponse(parts=[TextPart(content=\"Here's the joke I've generated for you:\\n\\nWhy don't scientists trust atoms? Because they make up everything!\\n\\nI hope this joke brings a smile to your face! Let me know if you need another one or any other help.\", part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 7, 19, 38, 9, tzinfo=datetime.timezone.utc), kind='response')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.all_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally the delegate agent needs to either have the same dependencies as the calling agent, or dependencies which are a subset of the calling agent's dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Here is a joke for you:\\n'\n",
      " '\\n'\n",
      " \"Why don't scientists trust atoms?\\n\"\n",
      " '\\n'\n",
      " 'Because they make up everything!')\n",
      "Usage(requests=2,\n",
      "      request_tokens=360,\n",
      "      response_tokens=103,\n",
      "      total_tokens=463,\n",
      "      details=None)\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "import httpx\n",
    "\n",
    "from pydantic_ai import Agent, RunContext\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "@dataclass\n",
    "class ClientAndKey:  \n",
    "    http_client: httpx.AsyncClient\n",
    "    api_key: str\n",
    "\n",
    "\n",
    "joke_selection_agent = Agent(\n",
    "    qwen_model,\n",
    "    deps_type=ClientAndKey,  \n",
    "    system_prompt=(\n",
    "        'Use the `joke_factory` tool to generate some jokes on the given subject, '\n",
    "        'then choose the best. You must return just a single joke.'\n",
    "    ),\n",
    ")\n",
    "joke_generation_agent = Agent(\n",
    "    qwen_model,\n",
    "    deps_type=ClientAndKey,  \n",
    "    result_type=list[str],\n",
    "    system_prompt=(\n",
    "        'Use the \"get_jokes\" tool to get some jokes on the given subject, '\n",
    "        'then extract each joke into a list.'\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "@joke_selection_agent.tool\n",
    "async def joke_factory(ctx: RunContext[ClientAndKey], count: int) -> list[str]:\n",
    "    r = await joke_generation_agent.run(\n",
    "        f'Please generate {count} jokes.',\n",
    "        deps=ctx.deps\n",
    "        # usage=ctx.usage,\n",
    "    )\n",
    "    return r.data\n",
    "\n",
    "\n",
    "@joke_generation_agent.tool  \n",
    "async def get_jokes(ctx: RunContext[ClientAndKey], count: int) -> str:\n",
    "    response = await ctx.deps.http_client.get(\n",
    "        'https://example.com',\n",
    "        params={'count': count},\n",
    "        headers={'Authorization': f'Bearer {ctx.deps.api_key}'},\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    return response.text\n",
    "\n",
    "\n",
    "async with httpx.AsyncClient() as client:\n",
    "    deps = ClientAndKey(client, 'foobar')\n",
    "    result = joke_selection_agent.run_sync(\n",
    "        'Tell me a joke.', \n",
    "        deps=deps,\n",
    "        usage_limits=UsageLimits(total_tokens_limit=3000))\n",
    "    pp.pprint(result.data)\n",
    "    #> Did you hear about the toothpaste scandal? They called it Colgate.\n",
    "    pp.pprint(result.usage())  \n",
    "    \"\"\"\n",
    "    Usage(\n",
    "        requests=4,\n",
    "        request_tokens=309,\n",
    "        response_tokens=32,\n",
    "        total_tokens=341,\n",
    "        details=None,\n",
    "    )\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Union\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from pydantic_ai.usage import UsageLimits\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "from pydantic_ai.providers.openai import OpenAIProvider\n",
    "from pydantic_ai.usage import Usage, UsageLimits\n",
    "from pydantic_ai.messages import ModelMessage\n",
    "from rich.prompt import Prompt\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "qwen_model = OpenAIModel(\n",
    "    model_name='qwen2.5-coder:14b', provider=OpenAIProvider(base_url='http://localhost:11434/v1')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Where would you like to fly from and to?: </pre>\n"
      ],
      "text/plain": [
       "Where would you like to fly from and to?: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flight found: AK46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What seat would you like?: </pre>\n"
      ],
      "text/plain": [
       "What seat would you like?: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not understand seat prefeerence. Please try again.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What seat would you like?: </pre>\n"
      ],
      "text/plain": [
       "What seat would you like?: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not understand seat prefeerence. Please try again.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What seat would you like?: </pre>\n"
      ],
      "text/plain": [
       "What seat would you like?: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not understand seat prefeerence. Please try again.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What seat would you like?: </pre>\n"
      ],
      "text/plain": [
       "What seat would you like?: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seat preference: row=1 seat='A'\n"
     ]
    }
   ],
   "source": [
    "class FlightDetails(BaseModel):\n",
    "    flight_number: str\n",
    "\n",
    "\n",
    "class Failed(BaseModel):\n",
    "    \"\"\"Unable to find a satisfactory choice.\"\"\"\n",
    "\n",
    "flight_search_agent = Agent[None, Union[FlightDetails, Failed]](\n",
    "    qwen_model,\n",
    "    result_type=Union[FlightDetails, Failed], # type: ingore\n",
    "    system_prompt=(\n",
    "        'Use the \"flight_search\" tool to find a flight '\n",
    "        'from the given origin to the given destinaiton.'\n",
    "    )\n",
    ")\n",
    "\n",
    "@flight_search_agent.tool\n",
    "async def flight_search(\n",
    "    ctx: RunContext[None], origin: str, destinaiton: str\n",
    ") -> Union[FlightDetails, None]:\n",
    "    # in reality, this would call a flight search API or\n",
    "    # use a browser to scrap a flight search website\n",
    "    return FlightDetails(flight_number='AK46')\n",
    "\n",
    "usage_limits = UsageLimits(request_limit=60)\n",
    "\n",
    "async def find_flight(usage: Usage) -> Union[FlightDetails, None]:\n",
    "    message_history: Union[list[ModelMessage], None] = None\n",
    "    for _ in range(3):\n",
    "        prompt = Prompt.ask(\n",
    "            'Where would you like to fly from and to?'\n",
    "        )\n",
    "        result = await flight_search_agent.run(\n",
    "            prompt,\n",
    "            message_history=message_history,\n",
    "            usage=usage,\n",
    "            usage_limits=usage_limits\n",
    "        )\n",
    "        if isinstance(result.data, FlightDetails):\n",
    "            return result.data\n",
    "        else:\n",
    "            message_history = result.all_messages(\n",
    "                result_tool_return_content='Please try again.'\n",
    "            )\n",
    "\n",
    "\n",
    "class SeatPreference(BaseModel):\n",
    "    row: int = Field(ge=1, le=30)\n",
    "    seat: Literal['A', 'B', 'C', 'D', 'E', 'F']\n",
    "\n",
    "\n",
    "# This agent is responsible for extracting the user's seat selection\n",
    "seat_preference_agent = Agent[None, Union[SeatPreference, Failed]](\n",
    "    qwen_model,\n",
    "    result_type=Union[SeatPreference, Failed], # type: ignore\n",
    "    system_prompt=(\n",
    "        \"Extract the user's seat preference. \"\n",
    "        'Seats A and F are window seats. '\n",
    "        'Row 1 is the front row and has extra log room. '\n",
    "        'Rows 14, and 20 also have extra leg roow. '\n",
    "    )\n",
    ")\n",
    "\n",
    "async def find_seat(usage: Usage) -> SeatPreference:\n",
    "    message_history: Union[list[ModelMessage], None] = None\n",
    "    while True:\n",
    "        answer = Prompt.ask('What seat would you like?')\n",
    "\n",
    "        result = await seat_preference_agent.run(\n",
    "            answer,\n",
    "            message_history=message_history,\n",
    "            usage=usage,\n",
    "            usage_limits=usage_limits\n",
    "        )\n",
    "        if isinstance(result.data, SeatPreference):\n",
    "            return result.data\n",
    "        else:\n",
    "            print('Could not understand seat prefeerence. Please try again.')\n",
    "            message_history = result.all_messages()\n",
    "\n",
    "usage: Usage = Usage()\n",
    "\n",
    "opt_flight_details = await find_flight(usage)\n",
    "\n",
    "if opt_flight_details is not None:\n",
    "    print(f'Flight found: {opt_flight_details.flight_number}')\n",
    "    #> Flight found: AK456\n",
    "    seat_preference = await find_seat(usage)\n",
    "    print(f'Seat preference: {seat_preference}')\n",
    "    #> Seat prerence: row=1 seat='A'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programmic agent hand-off\n",
    "\"Programmatic agent hand-off\" refers to the scenario where multiple agents are called in succession, with application code and/or a human in the loop responsible for deciding which agent is caleld next.\n",
    "\n",
    "Here agents don't need to use the same deps.\n",
    "\n",
    "Here we show two agents used in succession, the first to find a flight and the second "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Union\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from rich.prompt import Prompt\n",
    "\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from pydantic_ai.messages import ModelMessage\n",
    "from pydantic_ai.usage import Usage, UsageLimits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Where would you like to fly from and to?: </pre>\n"
      ],
      "text/plain": [
       "Where would you like to fly from and to?: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flight found: AK456\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What seat would you like?: </pre>\n"
      ],
      "text/plain": [
       "What seat would you like?: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seat preference: row=1 seat='B'\n"
     ]
    }
   ],
   "source": [
    "class FlightDetails(BaseModel):\n",
    "    flight_number: str\n",
    "\n",
    "class Failed(BaseModel):\n",
    "    \"\"\"Unable to find a satisfactory choice.\"\"\"\n",
    "\n",
    "flight_search_agent = Agent[None, Union[FlightDetails, Failed]](\n",
    "    qwen_model,\n",
    "    result_type=Union[FlightDetails, Failed], # type: ignore\n",
    "    system_prompt=(\n",
    "        'Used the \"flight_search\" tool to find a flight '\n",
    "        'from the given origin to the given destination.'\n",
    "    )\n",
    ")\n",
    "\n",
    "@flight_search_agent.tool\n",
    "async def flight_search(\n",
    "    ctx: RunContext[None], origin: str, destination: str\n",
    ") -> Union[FlightDetails, None]:\n",
    "    # in reality, this would call a flight search API or\n",
    "    # use a browser to scrap a flight search website\n",
    "    return FlightDetails(flight_number='AK456')\n",
    "\n",
    "usage_limits = UsageLimits(request_limit=15)\n",
    "\n",
    "async def find_flight(usage: Usage) -> Union[FlightDetails, None]:\n",
    "    message_history: Union[list[ModelMessage], None] = None\n",
    "    for _ in range(3):\n",
    "        prompt = Prompt.ask(\n",
    "            'Where would you like to fly from and to?'\n",
    "        )\n",
    "        result = await flight_search_agent.run(\n",
    "            prompt,\n",
    "            message_history=message_history,\n",
    "            usage=usage,\n",
    "            usage_limits=usage_limits            \n",
    "        )\n",
    "        if isinstance(result.data, FlightDetails):\n",
    "            return result.data\n",
    "        else:\n",
    "            message_history = result.all_messages(\n",
    "                result_tool_return_content='Please try again.'\n",
    "            )\n",
    "\n",
    "class SeatPreference(BaseModel):\n",
    "    row: int = Field(ge=1, le=30)\n",
    "    seat: Literal['A', 'B', 'C', 'D', 'E', 'F']\n",
    "\n",
    "# This agent is responsible for extracting the user's seat selection\n",
    "seat_preference_agent = Agent[None, Union[SeatPreference, Failed]](\n",
    "    qwen_model,\n",
    "    result_type=Union[SeatPreference, Failed], # type: ignore\n",
    "    system_prompt=(\n",
    "        \"Extract the user's seat preference. \"\n",
    "        'Seats A and F are window seats. '\n",
    "        'Row 1 is the front row and has extra leg room. '\n",
    "        'Rows 14, and 20 also have extra leg room. '\n",
    "    )\n",
    ")\n",
    "\n",
    "async def find_seat(usage: Usage) -> SeatPreference:\n",
    "    message_history: Union[list[ModelMessage], None] = None\n",
    "    while True:\n",
    "        answer = Prompt.ask('What seat would you like?')\n",
    "\n",
    "        result = await seat_preference_agent.run(\n",
    "            answer,\n",
    "            message_history=message_history,\n",
    "            usage=usage,\n",
    "            usage_limits=usage_limits\n",
    "        )\n",
    "        if isinstance(result.data, SeatPreference):\n",
    "            return result.data\n",
    "        else:\n",
    "            print('Could not understand seat preference. Please try again.')\n",
    "            message_history = result.all_messages()\n",
    "\n",
    "usage: Usage = Usage()\n",
    "\n",
    "opt_flight_details = await find_flight(usage)\n",
    "if opt_flight_details is not None:\n",
    "    print(f'Flight found: {opt_flight_details.flight_number}')\n",
    "    #> Flight found: AK456\n",
    "    seat_preference = await find_seat(usage)\n",
    "    print(f'Seat preference: {seat_preference}')\n",
    "    #> Seat preference: row=1 seat='A'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs\n",
    "Graphs and finite state machins (FSMs) are a powerful abstraction to model, execute, control and visualize complex workflows.\n",
    "\n",
    "Along with Pydantic, we've developed `pydantic-graph` -- an async graph and state machine library for Python where nodes and edges are defined using type hints.\n",
    "\n",
    "While this library is developed as part of PydanticAI; it has no dependency on `pydantic-ai` and can be considered as a pure graph-based state machine library. You may find it useful whether or not you're using PydanticAI or even building with GenAI.\n",
    "\n",
    "`pydantic-graph` is designed for advanced users and makes heavy use of Python generics and type hints. It is not designed to be as beginner-friendly as PydanticAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! uvx pip install pydantic-graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Types\n",
    "`pydantic-graph` is made up of a few key components:\n",
    "\n",
    "### GraphRunContext\n",
    "`GraphRunContext` - The context for the graph run, similar to PydanticAI's `RunContext`. This holds the state of the graph and dependencies and is passed to nodes when they're run.\n",
    "\n",
    "`GraphRunContext` is generic in the state type of the graph it's used in, `StateT`.\n",
    "\n",
    "### End\n",
    "`End` - return value to indicate the graph run should end.\n",
    "End is generic in the graph return type of the graph it's used in, `RunEndT`.\n",
    "\n",
    "### Nodes\n",
    "Subclasses of `BaseNode` define nodes for execution in the graph.\n",
    "\n",
    "Nodes, which are generally `dataclass`es, generally consist of:\n",
    "- fields containing any parameters required/optional when calling the node\n",
    "- the business logic to execute the node, in the `run` method\n",
    "- return annotations of the `run` method, which are read by `pydantic-graph` to determine the outgoing edges of the node\n",
    "\n",
    "Nodes are generic in:\n",
    "- `state`, which must have the same type as the state of graphs they're included in, `StateT` has a default of `None`, so if you're not using state you can obmit this generic parameter.\n",
    "- `deps`, which must have the same type as the deps of the graph they're included in, `DepsT` has a default of `None`, so if your are not using deps you can omit this generic parameter.\n",
    "- `graph return type` - this only applies if the node returns `End`. `RunEndT` has a default of `Never` so this generic parameter can be omitted if the node doesn't return `End`, but must be included if it does.\n",
    "\n",
    "Here's an example of a start or intermediate node in a graph -- it can't end the run as it doesn't return `End`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "from pydantic_graph import BaseNode, GraphRunContext\n",
    "\n",
    "@dataclass\n",
    "class MyNode(BaseNode[MyState]):\n",
    "    foo: int\n",
    "\n",
    "    async def run(\n",
    "            self,\n",
    "            ctx: GraphRunContext[MyState],\n",
    "    ) -> AnotherNode:\n",
    "        ...\n",
    "        return AnotherNode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extend `MyNode` to optionally end the run if `foo` is divisible by 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "from pydantic_graph import BaseNode, End, GraphRunContext\n",
    "\n",
    "@dataclass\n",
    "class MyNode(BaseNode[MyState, None, int]):\n",
    "    foo: int\n",
    "\n",
    "    async def run(\n",
    "            self,\n",
    "            ctx: GraphRunContext[MyState]\n",
    "    ) -> AnotherNode | End[int]:\n",
    "        if self.foo % 5 == 0:\n",
    "            return End(self.foo)\n",
    "        else:\n",
    "            return AnotherNode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph\n",
    "`Graph` -- this is the execution graph itself, made up of a set of `node classes` (i.e., `BaseNode` subclasses).\n",
    "\n",
    "`Graph` is generic in:\n",
    "- state: the state of the graph, `StateT`\n",
    "- deps: the deps type of the graph, `DepsT`\n",
    "- graph return type: the return type of the graph run, `RunEndT`\n",
    "\n",
    "Here's an example of a simple graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[DivisibleBy5(foo=1),\n",
      " Increment(foo=1),\n",
      " DivisibleBy5(foo=2),\n",
      " Increment(foo=2),\n",
      " DivisibleBy5(foo=3),\n",
      " Increment(foo=3),\n",
      " DivisibleBy5(foo=4),\n",
      " Increment(foo=4),\n",
      " DivisibleBy5(foo=5),\n",
      " End(data=5)]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from pydantic_graph import BaseNode, End, Graph, GraphRunContext\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "@dataclass\n",
    "class DivisibleBy5(BaseNode[None, None, int]):\n",
    "    foo: int\n",
    "\n",
    "    async def run(\n",
    "            self,\n",
    "            ctx: GraphRunContext\n",
    "    ) -> Increment | End[int]:\n",
    "        if self.foo % 5 == 0:\n",
    "            return End(self.foo)\n",
    "        else:\n",
    "            return Increment(self.foo)\n",
    "        \n",
    "@dataclass\n",
    "class Increment(BaseNode):\n",
    "    foo: int\n",
    "\n",
    "    async def run(\n",
    "            self,\n",
    "            ctx: GraphRunContext\n",
    "    ) -> DivisibleBy5:\n",
    "        return DivisibleBy5(self.foo + 1)\n",
    "    \n",
    "fives_graph = Graph(nodes=[DivisibleBy5, Increment])\n",
    "result = fives_graph.run_sync(DivisibleBy5(1))\n",
    "print(result.output)\n",
    "#> 5\n",
    "# the full history is quite verbose, so we'll just print the summary\n",
    "pprint([item.data_snapshot() for item in result.history])\n",
    "#> [DivisibleBy5(foo=4), Increment(foo=4), DivisibleBy5(foo=5), End(data=)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `mermaid diagram` for this graph can be generated with the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "display(Image(fives_graph.mermaid_image(start_node=DivisibleBy5)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stateful Graphs\n",
    "The \"state\" concept in `pydantic-graph` provides an optional way to access and mutate an object (often a `dataclass` or Pydantic model) as nodes run in a graph. If you think of Graphs as a production line, then your state is the engine being passed along the line and built up by each node as the graph is run.\n",
    "\n",
    "In the future, we intend to extend `pydantic-graph` to provide state persistence with the state recorded after each node is run.\n",
    "\n",
    "Here's an example of a graph which represents a vending machine where the user may insert coins and select a product to purchase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Insert coins: </pre>\n"
      ],
      "text/plain": [
       "Insert coins: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Select product: </pre>\n"
      ],
      "text/plain": [
       "Select product: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purchase succesful item=water change=0.25\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from rich.prompt import Prompt\n",
    "\n",
    "from pydantic_graph import BaseNode, End, Graph, GraphRunContext\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "@dataclass\n",
    "class MachineState:\n",
    "    user_balance: float = 0.0\n",
    "    product: str | None = None\n",
    "\n",
    "@dataclass\n",
    "class InsertCoin(BaseNode[MachineState]):\n",
    "    async def run(self, ctx: GraphRunContext[MachineState]) -> CoinsInserted:\n",
    "        return CoinsInserted(float(Prompt.ask('Insert coins')))\n",
    "    \n",
    "@dataclass\n",
    "class CoinsInserted(BaseNode[MachineState]):\n",
    "    coins: float\n",
    "\n",
    "    async def run(\n",
    "            self,\n",
    "            ctx: GraphRunContext[MachineState]\n",
    "    ) -> SelectProduct | Purchase:\n",
    "        ctx.state.user_balance += self.coins\n",
    "        if ctx.state.product is not None:\n",
    "            return Purchase(ctx.state.product)\n",
    "        else:\n",
    "            return SelectProduct()\n",
    "        \n",
    "@dataclass\n",
    "class SelectProduct(BaseNode[MachineState]):\n",
    "    async def run(self, ctx: GraphRunContext[MachineState]) -> Purchase:\n",
    "        return Purchase(Prompt.ask('Select product'))\n",
    "    \n",
    "PRODUCT_PRICES = {\n",
    "    'water': 1.25,\n",
    "    'soda': 1.50,\n",
    "    'crisps': 1.75,\n",
    "    'chocolate': 2.00,\n",
    "}\n",
    "\n",
    "@dataclass\n",
    "class Purchase(BaseNode[MachineState, None, None]):\n",
    "    product: str\n",
    "\n",
    "    async def run(\n",
    "            self, ctx: GraphRunContext[MachineState]\n",
    "    ) -> End | InsertCoin | SelectProduct:\n",
    "        if price := PRODUCT_PRICES.get(self.product):\n",
    "            ctx.state.product = self.product\n",
    "            if ctx.state.user_balance >= price:\n",
    "                ctx.state.user_balance -= price\n",
    "                return End(None)\n",
    "            else:\n",
    "                diff = price - ctx.state.user_balance\n",
    "                print(f'Not enough money for {self.product}, need {diff:0.2f} more')\n",
    "                #> Not enough money for crisps, need 0.75 more\n",
    "                return InsertCoin()\n",
    "        else:\n",
    "            print(f'No such product: {self.product}, try again')\n",
    "            return SelectProduct()\n",
    "\n",
    "vending_machine_graph = Graph(\n",
    "    nodes=[InsertCoin, CoinsInserted, SelectProduct, Purchase]\n",
    ")\n",
    "\n",
    "state = MachineState(1.5)\n",
    "vending_machine_graph.run_sync(InsertCoin(), state=state)\n",
    "print(f'purchase succesful item={state.product} change={state.user_balance:0.2f}')\n",
    "#> purchase successful item=crips change=0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "display(Image(vending_machine_graph.mermaid_image(start_node=InsertCoin)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GenAI Example\n",
    "In this example, one agent generates a welcome email to a user and the other agent provides feedback on the email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email(subject='Welcome to Our Tech Blog!',\n",
      "      body='Dear John Doe,\\n'\n",
      "           '\\n'\n",
      "           \"Welcome to our tech blog! We're thrilled to have you aboard. As a \"\n",
      "           'fellow enthusiast of languages like Haskell, Lisp, and Fortran, we '\n",
      "           \"believe there's a wealth of knowledge awaiting you here.\\n\"\n",
      "           '\\n'\n",
      "           'We cover the latest trends, deep-dives into programming concepts, '\n",
      "           'and showcases from experts in your favored areas. Feel free to '\n",
      "           'explore, comment, and share your insights with our community.\\n'\n",
      "           '\\n'\n",
      "           'Once again, welcome aboard! We hope you enjoy your time here and '\n",
      "           'find this platform a valuable resource for your tech interests.\\n'\n",
      "           '\\n'\n",
      "           'Best regards,\\n'\n",
      "           'The Tech Blog Team')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nEmail(\\n        subject='Welcome to our tech blog!',\\n        body='Hello John, Welcome to our tech blog! ...',\\n    )\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import annotations as _annotations\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "from pydantic import BaseModel, EmailStr\n",
    "\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.format_as_xml import format_as_xml\n",
    "from pydantic_ai.messages import ModelMessage\n",
    "from pydantic_graph import BaseNode, End, Graph, GraphRunContext\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "from pydantic_ai.providers.openai import OpenAIProvider\n",
    "from pprint import pprint as pp\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "qwen_model = OpenAIModel(\n",
    "    model_name='qwen2.5-coder:14b', provider=OpenAIProvider(base_url='http://localhost:11434/v1')\n",
    ")\n",
    "\n",
    "@dataclass\n",
    "class User:\n",
    "    name:str\n",
    "    email: EmailStr\n",
    "    interests: list[str]\n",
    "\n",
    "@dataclass\n",
    "class Email:\n",
    "    subject: str\n",
    "    body: str\n",
    "\n",
    "@dataclass\n",
    "class State:\n",
    "    user: User\n",
    "    write_agent_messages: list[ModelMessage] = field(default_factory=list)\n",
    "\n",
    "email_writer_agent = Agent(\n",
    "    qwen_model,\n",
    "    result_type=Email,\n",
    "    system_prompt='Write a welcome email to our tech blog.'\n",
    ")\n",
    "\n",
    "@dataclass\n",
    "class WriteEmail(BaseNode[State]):\n",
    "    email_feedback: str | None = None\n",
    "\n",
    "    async def run(self, ctx: GraphRunContext[State]) -> Feedback:\n",
    "        if self.email_feedback:\n",
    "            prompt = (\n",
    "                f'Rewrite the email for the user:\\n'\n",
    "                f'{format_as_xml(ctx.state.user)}\\n'\n",
    "                f'Feedback: {self.email_feedback}'                \n",
    "            )\n",
    "        else:\n",
    "            prompt = (\n",
    "                f'Write a welcome email for the user;\\n'\n",
    "                f'{format_as_xml(ctx.state.user)}'\n",
    "            )\n",
    "\n",
    "        result = await email_writer_agent.run(\n",
    "            prompt,\n",
    "            message_history=ctx.state.write_agent_messages\n",
    "        )\n",
    "        ctx.state.write_agent_messages += result.all_messages()\n",
    "        return Feedback(result.data)\n",
    "    \n",
    "class EmailRequiresWrite(BaseModel):\n",
    "    feedback: str\n",
    "\n",
    "class EmailOk(BaseModel):\n",
    "    pass\n",
    "\n",
    "feedback_agent = Agent[None, EmailRequiresWrite | EmailOk](\n",
    "    qwen_model,\n",
    "    result_type=EmailRequiresWrite | EmailOk,\n",
    "    system_prompt=(\n",
    "        'Review the email and provide feedback, email must reference the users specific interests.'\n",
    "    )\n",
    ")\n",
    "\n",
    "@dataclass\n",
    "class Feedback(BaseNode[State, None, Email]):\n",
    "    email: Email\n",
    "\n",
    "    async def run(\n",
    "            self,\n",
    "            ctx: GraphRunContext[State]\n",
    "    ) -> WriteEmail | End[Email]:\n",
    "        prompt = format_as_xml({'user': ctx.state.user, 'email': self.email})\n",
    "        result = await feedback_agent.run(prompt)\n",
    "        if isinstance(result.data, EmailRequiresWrite):\n",
    "            return WriteEmail(email_feedback=result.data.feedback)\n",
    "        else:\n",
    "            return End(self.email)\n",
    "        \n",
    "\n",
    "user = User(\n",
    "    name='John Doe',\n",
    "    email='john.joe@example.com',\n",
    "    interests=['Haskel', 'Lisp', 'Fortran']\n",
    ")\n",
    "state = State(user)\n",
    "feedback_graph = Graph(nodes=(WriteEmail, Feedback))\n",
    "result = feedback_graph.run_sync(WriteEmail(), state=state)\n",
    "pp(result.output)\n",
    "\"\"\"\n",
    "Email(\n",
    "        subject='Welcome to our tech blog!',\n",
    "        body='Hello John, Welcome to our tech blog! ...',\n",
    "    )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "display(Image(feedback_graph.mermaid_image(start_node=WriteEmail)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ModelRequest(parts=[SystemPromptPart(content='Write a welcome email to our '\n",
      "                                              'tech blog.',\n",
      "                                      dynamic_ref=None,\n",
      "                                      part_kind='system-prompt'),\n",
      "                     UserPromptPart(content='Write a welcome email for the '\n",
      "                                            'user;\\n'\n",
      "                                            '<examples>\\n'\n",
      "                                            '  <name>John Doe</name>\\n'\n",
      "                                            '  '\n",
      "                                            '<email>john.joe@example.com</email>\\n'\n",
      "                                            '  <interests>\\n'\n",
      "                                            '    <example>Haskel</example>\\n'\n",
      "                                            '    <example>Lisp</example>\\n'\n",
      "                                            '    <example>Fortran</example>\\n'\n",
      "                                            '  </interests>\\n'\n",
      "                                            '</examples>',\n",
      "                                    timestamp=datetime.datetime(2025, 3, 8, 6, 5, 39, 732673, tzinfo=datetime.timezone.utc),\n",
      "                                    part_kind='user-prompt')],\n",
      "              kind='request'),\n",
      " ModelResponse(parts=[TextPart(content='', part_kind='text'),\n",
      "                      ToolCallPart(tool_name='final_result',\n",
      "                                   args='{\"body\":\"Dear John Doe,\\\\n\\\\nWelcome '\n",
      "                                        \"to our tech blog! We're thrilled to \"\n",
      "                                        'have you aboard. As a fellow '\n",
      "                                        'enthusiast of languages like Haskell, '\n",
      "                                        \"Lisp, and Fortran, we believe there's \"\n",
      "                                        'a wealth of knowledge awaiting you '\n",
      "                                        'here.\\\\n\\\\nWe cover the latest '\n",
      "                                        'trends, deep-dives into programming '\n",
      "                                        'concepts, and showcases from experts '\n",
      "                                        'in your favored areas. Feel free to '\n",
      "                                        'explore, comment, and share your '\n",
      "                                        'insights with our '\n",
      "                                        'community.\\\\n\\\\nOnce again, welcome '\n",
      "                                        'aboard! We hope you enjoy your time '\n",
      "                                        'here and find this platform a '\n",
      "                                        'valuable resource for your tech '\n",
      "                                        'interests.\\\\n\\\\nBest regards,\\\\nThe '\n",
      "                                        'Tech Blog Team\",\"subject\":\"Welcome to '\n",
      "                                        'Our Tech Blog!\"}',\n",
      "                                   tool_call_id='call_jb6gd4yg',\n",
      "                                   part_kind='tool-call')],\n",
      "               model_name='qwen2.5-coder:14b',\n",
      "               timestamp=datetime.datetime(2025, 3, 8, 6, 5, 44, tzinfo=datetime.timezone.utc),\n",
      "               kind='response'),\n",
      " ModelRequest(parts=[ToolReturnPart(tool_name='final_result',\n",
      "                                    content='Final result processed.',\n",
      "                                    tool_call_id='call_jb6gd4yg',\n",
      "                                    timestamp=datetime.datetime(2025, 3, 8, 6, 5, 44, 118098, tzinfo=datetime.timezone.utc),\n",
      "                                    part_kind='tool-return')],\n",
      "              kind='request')]\n"
     ]
    }
   ],
   "source": [
    "pp(state.write_agent_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Control Flow\n",
    "In many real-world applications, Graphs cannot run uninterrupted from start to finish -- they might require external input, or run over an extended period of time such as a single procuss cannot execute the entire graph run from start to finish without interruption.\n",
    "\n",
    "In these scenarios the `next` method can be used to run the graph one node at a time.\n",
    "\n",
    "In this example, an AI asks the user a question, the user provides an answer, the AI evaluates the answer and ends if the user got it right or asks another question if they got it wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What is the capital of France?: </pre>\n"
      ],
      "text/plain": [
       "What is the capital of France?: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: The answer provided ('fff') is incorrect. The capital of France is Paris.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What is 2 + 2?: </pre>\n"
      ],
      "text/plain": [
       "What is 2 + 2?: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: The correct answer should be 4.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What is the main function of a CPU in a computer?: </pre>\n"
      ],
      "text/plain": [
       "What is the main function of a CPU in a computer?: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: The answer 'fuck up' is incorrect. The main function of a CPU in a computer is to execute instructions and perform calculations.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What color of light has the shortest wavelength?: </pre>\n"
      ],
      "text/plain": [
       "What color of light has the shortest wavelength?: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answer ! The answer 'violet' is correct. Violet light indeed has the shortest wavelength among all visible colors.\n",
      "[<bound method NodeStep.data_snapshot of NodeStep(state=QuestionState(question='What is the capital of France?', ask_agent_messages=[ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response')], evaluate_agent_messages=[]), node=Ask(), start_ts=datetime.datetime(2025, 3, 8, 14, 10, 29, 680583, tzinfo=datetime.timezone.utc), duration=0.1703739007934928, kind='node')>, <bound method NodeStep.data_snapshot of NodeStep(state=QuestionState(question='What is the capital of France?', ask_agent_messages=[ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response')], evaluate_agent_messages=[]), node=Answer(question='What is the capital of France?', answer='fff'), start_ts=datetime.datetime(2025, 3, 8, 14, 10, 34, 686104, tzinfo=datetime.timezone.utc), duration=8.61380249261856e-06, kind='node')>, <bound method NodeStep.data_snapshot of NodeStep(state=QuestionState(question='What is the capital of France?', ask_agent_messages=[ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response')], evaluate_agent_messages=[ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request')]), node=Evaluate(answer='fff'), start_ts=datetime.datetime(2025, 3, 8, 14, 10, 34, 686426, tzinfo=datetime.timezone.utc), duration=0.8193083936348557, kind='node')>, <bound method NodeStep.data_snapshot of NodeStep(state=QuestionState(question=None, ask_agent_messages=[ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response')], evaluate_agent_messages=[ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request')]), node=Reprimand(comment=\"The answer provided ('fff') is incorrect. The capital of France is Paris.\"), start_ts=datetime.datetime(2025, 3, 8, 14, 10, 35, 505806, tzinfo=datetime.timezone.utc), duration=4.519708454608917e-05, kind='node')>, <bound method NodeStep.data_snapshot of NodeStep(state=QuestionState(question='What is 2 + 2?', ask_agent_messages=[ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 506128, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is 2 + 2?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response')], evaluate_agent_messages=[ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request')]), node=Ask(), start_ts=datetime.datetime(2025, 3, 8, 14, 10, 35, 505905, tzinfo=datetime.timezone.utc), duration=0.19418770540505648, kind='node')>, <bound method NodeStep.data_snapshot of NodeStep(state=QuestionState(question='What is 2 + 2?', ask_agent_messages=[ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 506128, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is 2 + 2?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response')], evaluate_agent_messages=[ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request')]), node=Answer(question='What is 2 + 2?', answer='3'), start_ts=datetime.datetime(2025, 3, 8, 14, 10, 39, 602834, tzinfo=datetime.timezone.utc), duration=8.299946784973145e-06, kind='node')>, <bound method NodeStep.data_snapshot of NodeStep(state=QuestionState(question='What is 2 + 2?', ask_agent_messages=[ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 506128, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is 2 + 2?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response')], evaluate_agent_messages=[ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[UserPromptPart(content='<examples>\\n  <question>What is 2 + 2?</question>\\n  <answer>3</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 39, 604465, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The correct answer should be 4.\",\"correct\":false}', tool_call_id='call_ldhwxgbd', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_ldhwxgbd', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, 414012, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request')]), node=Evaluate(answer='3'), start_ts=datetime.datetime(2025, 3, 8, 14, 10, 39, 603369, tzinfo=datetime.timezone.utc), duration=0.8108063479885459, kind='node')>, <bound method NodeStep.data_snapshot of NodeStep(state=QuestionState(question=None, ask_agent_messages=[ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 506128, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is 2 + 2?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response')], evaluate_agent_messages=[ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[UserPromptPart(content='<examples>\\n  <question>What is 2 + 2?</question>\\n  <answer>3</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 39, 604465, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The correct answer should be 4.\",\"correct\":false}', tool_call_id='call_ldhwxgbd', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_ldhwxgbd', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, 414012, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request')]), node=Reprimand(comment='The correct answer should be 4.'), start_ts=datetime.datetime(2025, 3, 8, 14, 10, 40, 414278, tzinfo=datetime.timezone.utc), duration=4.0046870708465576e-05, kind='node')>, <bound method NodeStep.data_snapshot of NodeStep(state=QuestionState(question='What is the main function of a CPU in a computer?', ask_agent_messages=[ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 506128, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is 2 + 2?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 506128, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is 2 + 2?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, 414606, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the main function of a CPU in a computer?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, tzinfo=datetime.timezone.utc), kind='response')], evaluate_agent_messages=[ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[UserPromptPart(content='<examples>\\n  <question>What is 2 + 2?</question>\\n  <answer>3</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 39, 604465, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The correct answer should be 4.\",\"correct\":false}', tool_call_id='call_ldhwxgbd', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_ldhwxgbd', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, 414012, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request')]), node=Ask(), start_ts=datetime.datetime(2025, 3, 8, 14, 10, 40, 414408, tzinfo=datetime.timezone.utc), duration=0.3026803666725755, kind='node')>, <bound method NodeStep.data_snapshot of NodeStep(state=QuestionState(question='What is the main function of a CPU in a computer?', ask_agent_messages=[ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 506128, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is 2 + 2?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 506128, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is 2 + 2?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, 414606, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the main function of a CPU in a computer?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, tzinfo=datetime.timezone.utc), kind='response')], evaluate_agent_messages=[ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[UserPromptPart(content='<examples>\\n  <question>What is 2 + 2?</question>\\n  <answer>3</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 39, 604465, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The correct answer should be 4.\",\"correct\":false}', tool_call_id='call_ldhwxgbd', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_ldhwxgbd', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, 414012, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request')]), node=Answer(question='What is the main function of a CPU in a computer?', answer='fuck up'), start_ts=datetime.datetime(2025, 3, 8, 14, 10, 46, 54535, tzinfo=datetime.timezone.utc), duration=6.572343409061432e-06, kind='node')>, <bound method NodeStep.data_snapshot of NodeStep(state=QuestionState(question='What is the main function of a CPU in a computer?', ask_agent_messages=[ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 506128, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is 2 + 2?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 506128, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is 2 + 2?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, 414606, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the main function of a CPU in a computer?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, tzinfo=datetime.timezone.utc), kind='response')], evaluate_agent_messages=[ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[UserPromptPart(content='<examples>\\n  <question>What is 2 + 2?</question>\\n  <answer>3</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 39, 604465, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The correct answer should be 4.\",\"correct\":false}', tool_call_id='call_ldhwxgbd', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_ldhwxgbd', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, 414012, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[UserPromptPart(content='<examples>\\n  <question>What is 2 + 2?</question>\\n  <answer>3</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 39, 604465, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The correct answer should be 4.\",\"correct\":false}', tool_call_id='call_ldhwxgbd', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_ldhwxgbd', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, 414012, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[UserPromptPart(content='<examples>\\n  <question>What is the main function of a CPU in a computer?</question>\\n  <answer>fuck up</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 46, 56330, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer \\'fuck up\\' is incorrect. The main function of a CPU in a computer is to execute instructions and perform calculations.\",\"correct\":false}', tool_call_id='call_ilfu67tz', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 47, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_ilfu67tz', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 47, 294845, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request')]), node=Evaluate(answer='fuck up'), start_ts=datetime.datetime(2025, 3, 8, 14, 10, 46, 55241, tzinfo=datetime.timezone.utc), duration=1.2398058278486133, kind='node')>, <bound method NodeStep.data_snapshot of NodeStep(state=QuestionState(question=None, ask_agent_messages=[ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 506128, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is 2 + 2?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 506128, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is 2 + 2?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, 414606, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the main function of a CPU in a computer?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, tzinfo=datetime.timezone.utc), kind='response')], evaluate_agent_messages=[ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[UserPromptPart(content='<examples>\\n  <question>What is 2 + 2?</question>\\n  <answer>3</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 39, 604465, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The correct answer should be 4.\",\"correct\":false}', tool_call_id='call_ldhwxgbd', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_ldhwxgbd', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, 414012, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[UserPromptPart(content='<examples>\\n  <question>What is 2 + 2?</question>\\n  <answer>3</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 39, 604465, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The correct answer should be 4.\",\"correct\":false}', tool_call_id='call_ldhwxgbd', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_ldhwxgbd', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, 414012, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[UserPromptPart(content='<examples>\\n  <question>What is the main function of a CPU in a computer?</question>\\n  <answer>fuck up</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 46, 56330, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer \\'fuck up\\' is incorrect. The main function of a CPU in a computer is to execute instructions and perform calculations.\",\"correct\":false}', tool_call_id='call_ilfu67tz', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 47, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_ilfu67tz', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 47, 294845, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request')]), node=Reprimand(comment=\"The answer 'fuck up' is incorrect. The main function of a CPU in a computer is to execute instructions and perform calculations.\"), start_ts=datetime.datetime(2025, 3, 8, 14, 10, 47, 295184, tzinfo=datetime.timezone.utc), duration=3.794953227043152e-05, kind='node')>, <bound method NodeStep.data_snapshot of NodeStep(state=QuestionState(question='What color of light has the shortest wavelength?', ask_agent_messages=[ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 506128, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is 2 + 2?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 506128, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is 2 + 2?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, 414606, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the main function of a CPU in a computer?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 506128, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is 2 + 2?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 506128, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is 2 + 2?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, 414606, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the main function of a CPU in a computer?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 47, 295558, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What color of light has the shortest wavelength?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 47, tzinfo=datetime.timezone.utc), kind='response')], evaluate_agent_messages=[ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[UserPromptPart(content='<examples>\\n  <question>What is 2 + 2?</question>\\n  <answer>3</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 39, 604465, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The correct answer should be 4.\",\"correct\":false}', tool_call_id='call_ldhwxgbd', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_ldhwxgbd', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, 414012, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[UserPromptPart(content='<examples>\\n  <question>What is 2 + 2?</question>\\n  <answer>3</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 39, 604465, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The correct answer should be 4.\",\"correct\":false}', tool_call_id='call_ldhwxgbd', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_ldhwxgbd', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, 414012, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[UserPromptPart(content='<examples>\\n  <question>What is the main function of a CPU in a computer?</question>\\n  <answer>fuck up</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 46, 56330, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer \\'fuck up\\' is incorrect. The main function of a CPU in a computer is to execute instructions and perform calculations.\",\"correct\":false}', tool_call_id='call_ilfu67tz', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 47, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_ilfu67tz', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 47, 294845, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request')]), node=Ask(), start_ts=datetime.datetime(2025, 3, 8, 14, 10, 47, 295345, tzinfo=datetime.timezone.utc), duration=0.36962381564080715, kind='node')>, <bound method NodeStep.data_snapshot of NodeStep(state=QuestionState(question='What color of light has the shortest wavelength?', ask_agent_messages=[ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 506128, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is 2 + 2?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 506128, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is 2 + 2?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, 414606, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the main function of a CPU in a computer?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 506128, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is 2 + 2?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 506128, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is 2 + 2?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, 414606, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the main function of a CPU in a computer?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 47, 295558, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What color of light has the shortest wavelength?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 47, tzinfo=datetime.timezone.utc), kind='response')], evaluate_agent_messages=[ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[UserPromptPart(content='<examples>\\n  <question>What is 2 + 2?</question>\\n  <answer>3</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 39, 604465, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The correct answer should be 4.\",\"correct\":false}', tool_call_id='call_ldhwxgbd', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_ldhwxgbd', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, 414012, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[UserPromptPart(content='<examples>\\n  <question>What is 2 + 2?</question>\\n  <answer>3</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 39, 604465, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The correct answer should be 4.\",\"correct\":false}', tool_call_id='call_ldhwxgbd', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_ldhwxgbd', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, 414012, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[UserPromptPart(content='<examples>\\n  <question>What is the main function of a CPU in a computer?</question>\\n  <answer>fuck up</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 46, 56330, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer \\'fuck up\\' is incorrect. The main function of a CPU in a computer is to execute instructions and perform calculations.\",\"correct\":false}', tool_call_id='call_ilfu67tz', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 47, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_ilfu67tz', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 47, 294845, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request')]), node=Answer(question='What color of light has the shortest wavelength?', answer='violet'), start_ts=datetime.datetime(2025, 3, 8, 14, 10, 58, 650199, tzinfo=datetime.timezone.utc), duration=6.386078894138336e-06, kind='node')>, <bound method NodeStep.data_snapshot of NodeStep(state=QuestionState(question='What color of light has the shortest wavelength?', ask_agent_messages=[ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 506128, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is 2 + 2?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 506128, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is 2 + 2?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, 414606, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the main function of a CPU in a computer?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 506128, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is 2 + 2?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, 680763, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the capital of France?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 29, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 506128, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is 2 + 2?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, 414606, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What is the main function of a CPU in a computer?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[UserPromptPart(content='Ask a sinple question with a single correct answer.', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 47, 295558, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='What color of light has the shortest wavelength?', part_kind='text')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 47, tzinfo=datetime.timezone.utc), kind='response')], evaluate_agent_messages=[ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[UserPromptPart(content='<examples>\\n  <question>What is 2 + 2?</question>\\n  <answer>3</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 39, 604465, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The correct answer should be 4.\",\"correct\":false}', tool_call_id='call_ldhwxgbd', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_ldhwxgbd', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, 414012, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[UserPromptPart(content='<examples>\\n  <question>What is 2 + 2?</question>\\n  <answer>3</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 39, 604465, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The correct answer should be 4.\",\"correct\":false}', tool_call_id='call_ldhwxgbd', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_ldhwxgbd', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, 414012, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[UserPromptPart(content='<examples>\\n  <question>What is the main function of a CPU in a computer?</question>\\n  <answer>fuck up</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 46, 56330, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer \\'fuck up\\' is incorrect. The main function of a CPU in a computer is to execute instructions and perform calculations.\",\"correct\":false}', tool_call_id='call_ilfu67tz', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 47, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_ilfu67tz', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 47, 294845, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[UserPromptPart(content='<examples>\\n  <question>What is 2 + 2?</question>\\n  <answer>3</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 39, 604465, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The correct answer should be 4.\",\"correct\":false}', tool_call_id='call_ldhwxgbd', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_ldhwxgbd', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, 414012, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[SystemPromptPart(content='Given a question and answer, evaluate if the answer is correct.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='<examples>\\n  <question>What is the capital of France?</question>\\n  <answer>fff</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 34, 687607, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer provided (\\'fff\\') is incorrect. The capital of France is Paris.\",\"correct\":false}', tool_call_id='call_zqpibmz0', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_zqpibmz0', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 35, 505593, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[UserPromptPart(content='<examples>\\n  <question>What is 2 + 2?</question>\\n  <answer>3</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 39, 604465, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The correct answer should be 4.\",\"correct\":false}', tool_call_id='call_ldhwxgbd', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_ldhwxgbd', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 40, 414012, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[UserPromptPart(content='<examples>\\n  <question>What is the main function of a CPU in a computer?</question>\\n  <answer>fuck up</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 46, 56330, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer \\'fuck up\\' is incorrect. The main function of a CPU in a computer is to execute instructions and perform calculations.\",\"correct\":false}', tool_call_id='call_ilfu67tz', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 47, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_ilfu67tz', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 47, 294845, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request'), ModelRequest(parts=[UserPromptPart(content='<examples>\\n  <question>What color of light has the shortest wavelength?</question>\\n  <answer>violet</answer>\\n</examples>', timestamp=datetime.datetime(2025, 3, 8, 14, 10, 58, 652179, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='', part_kind='text'), ToolCallPart(tool_name='final_result', args='{\"comment\":\"The answer \\'violet\\' is correct. Violet light indeed has the shortest wavelength among all visible colors.\",\"correct\":true}', tool_call_id='call_riesiaqv', part_kind='tool-call')], model_name='qwen2.5-coder:14b', timestamp=datetime.datetime(2025, 3, 8, 14, 11, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id='call_riesiaqv', timestamp=datetime.datetime(2025, 3, 8, 14, 11, 0, 98530, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request')]), node=Evaluate(answer='violet'), start_ts=datetime.datetime(2025, 3, 8, 14, 10, 58, 651082, tzinfo=datetime.timezone.utc), duration=1.447697564959526, kind='node')>, <bound method EndStep.data_snapshot of EndStep(result=End(data=\"The answer 'violet' is correct. Violet light indeed has the shortest wavelength among all visible colors.\"), ts=datetime.datetime(2025, 3, 8, 14, 11, 0, 98929, tzinfo=datetime.timezone.utc), kind='end')>]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations as _annotations\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "from pydantic_graph import BaseNode, End, Graph, GraphRunContext, HistoryStep\n",
    "\n",
    "from rich.prompt import Prompt\n",
    "\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.format_as_xml import format_as_xml\n",
    "from pydantic_ai.messages import ModelMessage\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "from pydantic_ai.providers.openai import OpenAIProvider\n",
    "\n",
    "qwen_model = OpenAIModel(\n",
    "    model_name='qwen2.5-coder:14b', provider=OpenAIProvider(base_url='http://localhost:11434/v1')\n",
    ")\n",
    "\n",
    "ask_agent = Agent(qwen_model, result_type=str)\n",
    "\n",
    "@dataclass\n",
    "class QuestionState:\n",
    "    question: str | None = None\n",
    "    ask_agent_messages: list[ModelMessage] = field(default_factory=list)\n",
    "    evaluate_agent_messages: list[ModelMessage] = field(default_factory=list)\n",
    "\n",
    "@dataclass\n",
    "class Ask(BaseNode[QuestionState]):\n",
    "    async def run(self, ctx: GraphRunContext[QuestionState]) -> Answer:\n",
    "        result = await ask_agent.run(\n",
    "            'Ask a sinple question with a single correct answer.',\n",
    "            message_history=ctx.state.ask_agent_messages\n",
    "        )\n",
    "        ctx.state.ask_agent_messages += result.all_messages()\n",
    "        ctx.state.question = result.data\n",
    "        return Answer(result.data)\n",
    "\n",
    "@dataclass\n",
    "class Answer(BaseNode[QuestionState]):\n",
    "    question: str\n",
    "    answer: str | None = None\n",
    "\n",
    "    async def run(self, ctx: GraphRunContext[QuestionState]) -> Evaluate:\n",
    "        assert self.answer is not None\n",
    "        return Evaluate(self.answer)\n",
    "    \n",
    "@dataclass\n",
    "class EvaluateResult():\n",
    "    correct: bool\n",
    "    comment: str\n",
    "\n",
    "evaluate_agent = Agent(\n",
    "    qwen_model,\n",
    "    result_type=EvaluateResult,\n",
    "    system_prompt='Given a question and answer, evaluate if the answer is correct.'\n",
    ")\n",
    "\n",
    "@dataclass\n",
    "class Evaluate(BaseNode[QuestionState]):\n",
    "    answer: str\n",
    "\n",
    "    async def run(\n",
    "            self, \n",
    "            ctx: GraphRunContext[QuestionState]\n",
    "    ) ->  End[None] | Reprimand:\n",
    "        assert ctx.state.question is not None\n",
    "        result = await evaluate_agent.run(\n",
    "            format_as_xml({'question': ctx.state.question, 'answer': self.answer}),\n",
    "            message_history=ctx.state.evaluate_agent_messages\n",
    "        )\n",
    "        ctx.state.evaluate_agent_messages += result.all_messages()\n",
    "        if result.data.correct:\n",
    "            return End(result.data.comment)\n",
    "        else:\n",
    "            return Reprimand(result.data.comment)\n",
    "\n",
    "@dataclass\n",
    "class Reprimand(BaseNode[QuestionState]):\n",
    "    comment: str\n",
    "\n",
    "    async def run(self, ctx: GraphRunContext[QuestionState]) -> Ask:\n",
    "        print(f'Comment: {self.comment}')\n",
    "        ctx.state.question = None\n",
    "        return Ask()\n",
    "    \n",
    "question_graph = Graph(nodes=(Ask, Answer, Evaluate, Reprimand))\n",
    "\n",
    "state = QuestionState()\n",
    "node = Ask()\n",
    "history: list[HistoryStep[QuestionState]] = []\n",
    "while True:\n",
    "    node = await question_graph.next(node, history, state=state)\n",
    "    if isinstance(node, Answer):\n",
    "        node.answer = Prompt.ask(node.question)\n",
    "    elif isinstance(node, End):\n",
    "        print(f'Correct answer ! {node.data}')\n",
    "        #> Correct answer! well done, 1 + 1 = 2\n",
    "        print([history_step.data_snapshot for history_step in history])\n",
    "        \"\"\"\n",
    "        [\n",
    "            Ask(),\n",
    "            Answer(question='What is the capital of France?', answer='Vichy'),\n",
    "            Evaluate(answer='Vichy'),\n",
    "            Reprimand(comment='Vichy is no longer the capital of France.'),\n",
    "            Ask(),\n",
    "            Answer(question='what is 1 + 1?', answer='2'),\n",
    "            Evaluate(answer='2'),\n",
    "            End(data='Well done, 1 + 1 = 2'),\n",
    "        ]\n",
    "        \"\"\"\n",
    "        break\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "display(Image(question_graph.mermaid_image(start_node=Ask)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
