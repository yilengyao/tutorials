{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6487090a-7cdf-4c7e-892c-aeffaafa699e",
   "metadata": {},
   "source": [
    "# What is PyTorch?\n",
    "- Popular research deep learning framework.\n",
    "- Write fast deep learning code in Python (able to run on a GPU/many GPUs)\n",
    "- Able to access many pre-built deep learning models (Torch Hub/torchvision.models)\n",
    "- Whole stack: preprocesss data, model data, deploy modle in your application/cloud\n",
    "\n",
    "Importing Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0427f98-61c5-43d1-b40d-2b9ed6cf4e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1+cu121'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636c015c-7a59-45f6-ba70-4519a8037c68",
   "metadata": {},
   "source": [
    "## What is a Tensor\n",
    "Tensors are fundamental building block of machine learning.\n",
    "Their job is to represent data in a numerical way.\n",
    "\n",
    "A `torch.Tensor` is a multi-dimensional matrix containing elements of a single data type.\n",
    "\n",
    "Lets create a scalar.\n",
    "\n",
    "### Scalar\n",
    "A scalar is a single number, or a zero dimension vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b30988e6-d529-4829-8c0c-cc5964162e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalr\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d5f727b-b859-4d31-a58e-5650c85e2d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check on the dimension of a tensor using ndim attribute\n",
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a29d21-f82c-41de-9fe8-812ea281ed55",
   "metadata": {},
   "source": [
    "`item()`: Method to retrieve a number from the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6fd6546-b973-40ec-b3d1-f2ce3612d5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the Python number within a tensor (only works with 1-element tensors)\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c15ae6-671a-42e4-8461-2c7b97441609",
   "metadata": {},
   "source": [
    "### Vector\n",
    "Vector is a single dimension tensor that can contain many numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e7829f55-d37d-41a0-9e4c-e0fc71cc5b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "81818296-fe9e-4c0b-9f5f-4ac6e33b0615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0646df7a-38f9-4a6d-bc3a-90dd187312b9",
   "metadata": {},
   "source": [
    "### Shape\n",
    "Shape attribute tells you how the elements inside them are arranged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9d6bc0c2-1c85-4084-b370-92d0519f19c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "87886aad-de06-4a2c-852e-42690632e4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix\n",
    "MATRIX = torch.tensor([[7, 8],\n",
    "                       [9, 10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "948c9bfc-cb19-404d-82bd-d48873645787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "54f67324-6213-4cee-ae20-c4ecaab12dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "980255b4-790d-474d-86d8-dc2f6675d5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4,5]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7d6ce917-de2b-4784-a1c9-85f6fc970227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a0ec3d16-2e0b-449b-87ee-e53b9a36da73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9667ad50-4200-47f5-b5f1-9397b41895de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [3, 6, 9],\n",
       "        [2, 4, 5]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c5f83941-7e3e-4410-a081-c7c30fb1279d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mTENSOR\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "TENSOR[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "993f7e95-7226-422c-a8d4-c61c5da78071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "547e7331-546b-446c-a0c8-685141c8787d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 4, 5])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d5ac99-318c-449a-bf4b-c6aa629f8255",
   "metadata": {},
   "source": [
    "## Random Tensors\n",
    "Tensors represent some form of data.\n",
    "Machine learning models susch as neural networks manipulate and seek patterns within tensors. But when building machine learning models with PyTorch, it's rare you'll create tensors by hand. Instead, a machine learning model often starts out with large random tensors of numbers and adjusts these random numbers as it works throught data to better represent it.\n",
    "\n",
    "In essence:\n",
    "\n",
    "```\n",
    "Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers...\n",
    "````\n",
    "\n",
    "Lets create a tensor of random numbers.\n",
    "\n",
    "We can do so using `torch.rand()` and passing in the `size` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c38e1f74-4841-4f16-ad10-48df2d5a8c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.7698, 0.8748, 0.3200, 0.9173],\n",
       "         [0.0349, 0.8915, 0.4879, 0.3367],\n",
       "         [0.0082, 0.0475, 0.0986, 0.5182]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (3, 4)\n",
    "random_tensor = torch.rand(size=(3, 4))\n",
    "random_tensor, random_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7ce1f9-993b-45da-ab25-b87f38d99233",
   "metadata": {},
   "source": [
    "The flexibility of `torch.rand()` is that we can adjust the `size` to be whatever we want.\n",
    "\n",
    "For example, say you wanted  a random tensor in the scommon image shape of `[224, 224, 3]` `([height, width, color_channels])`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "fddfc8ac-5865-4f99-a06f-96343a887f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 5, 3]), 3)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (224, 224, 3)\n",
    "random_image_size_tensor = torch.rand(size=(224, 5, 3))\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "c811d511-edf7-4196-a709-d07021af77fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1611, 0.4704, 0.4695],\n",
       "         [0.6632, 0.6139, 0.9958],\n",
       "         [0.4580, 0.0316, 0.2574],\n",
       "         [0.7860, 0.6027, 0.7729],\n",
       "         [0.2386, 0.0367, 0.5478]],\n",
       "\n",
       "        [[0.8969, 0.6494, 0.5929],\n",
       "         [0.3647, 0.7664, 0.3178],\n",
       "         [0.3145, 0.2281, 0.7609],\n",
       "         [0.4816, 0.7887, 0.8978],\n",
       "         [0.7446, 0.4158, 0.1385]],\n",
       "\n",
       "        [[0.9762, 0.5909, 0.1351],\n",
       "         [0.5448, 0.5314, 0.8870],\n",
       "         [0.9934, 0.8699, 0.7640],\n",
       "         [0.7952, 0.8220, 0.8724],\n",
       "         [0.7941, 0.1118, 0.4573]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.1838, 0.3318, 0.6432],\n",
       "         [0.3355, 0.2979, 0.0470],\n",
       "         [0.0516, 0.6750, 0.9755],\n",
       "         [0.4237, 0.3471, 0.0161],\n",
       "         [0.5369, 0.4983, 0.9655]],\n",
       "\n",
       "        [[0.7195, 0.0725, 0.7615],\n",
       "         [0.8931, 0.7393, 0.8636],\n",
       "         [0.3742, 0.5550, 0.6185],\n",
       "         [0.8954, 0.3570, 0.0303],\n",
       "         [0.6586, 0.7897, 0.5219]],\n",
       "\n",
       "        [[0.7488, 0.1396, 0.6514],\n",
       "         [0.0350, 0.3677, 0.6284],\n",
       "         [0.6115, 0.6368, 0.2742],\n",
       "         [0.9120, 0.0039, 0.9691],\n",
       "         [0.8345, 0.4375, 0.9134]]])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_size_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "f964f6b5-37a5-4d7b-b04e-6236624513cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1611, 0.4704, 0.4695],\n",
       "        [0.6632, 0.6139, 0.9958],\n",
       "        [0.4580, 0.0316, 0.2574],\n",
       "        [0.7860, 0.6027, 0.7729],\n",
       "        [0.2386, 0.0367, 0.5478]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_size_tensor[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04876cc0-9407-4a93-83dc-05bd811cc91c",
   "metadata": {},
   "source": [
    "## Zeros and Ones\n",
    "Sometimes you;ll just want to fill tensors with zeros and ones.\n",
    "This happens a lot with masking (like masking some oaf the values in one tensor with zeros to let a model know not to learn them).\n",
    "\n",
    "Let's create a tensor full of zeros with `torch.zeros()`\n",
    "\n",
    "Again, the `size` parameter comes to play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "f009837c-2753-4072-9b80-5b3f65901714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3, 4))\n",
    "zeros, zeros.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1c313c-ec57-4713-9c15-291f3a744520",
   "metadata": {},
   "source": [
    "We can do the same to create a tensor of all ones excep using `torch.ones()` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "5a605239-9635-4998-92cd-0503c0f4ed6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3, 4))\n",
    "ones, ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead83e3b-8346-4c83-957a-1fcba6b849e7",
   "metadata": {},
   "source": [
    "## Create a range and tensors like\n",
    "Sometimes you might want a range of numbers, such as 1 to 10 or 0 to 100.\n",
    "\n",
    "You can use `torch.arange(start, end, step)` to do so.\n",
    "\n",
    "Where:\n",
    "- `start` = start of range (eg., 0)\n",
    "- `end` = end of range (eg., 10)\n",
    "- `step` = how many steps in between each value (eg., 1)\n",
    "\n",
    "Note! In Python, you can use `range()` to create a range. However in PyTorch, `torch.range()` is deprecated and may show an aerror in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "307a5154-b252-4485-a54b-665bfdeb0819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a range of values 0 to 10\n",
    "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed1493d-c8f6-4810-8183-5ffdc01ec106",
   "metadata": {},
   "source": [
    "Sometimes you might want one tensor of a certain type with ther same shape as another tensor. For example, a tensor of all zeros with the same shape as a previous tensor.\n",
    "\n",
    "To do so you can use `torch.zeros_like(input)` or `torch.ones_like(input=zero_to_ten)` which return a tensor filled with zeros or ones in the same shape as the `input` respecively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "055c61d5-94e7-42e7-859b-7a90aa613a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also create a tensor of zeros similar to another tensor\n",
    "ten_zeros = torch.zeros_like(input=zero_to_ten) # will have same shape\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86fd29c-c075-45c0-a7bc-5fd78f7cc8bc",
   "metadata": {},
   "source": [
    "## Precision in Computing\n",
    "Precision is the amount of detail used to describe a number.\n",
    "\n",
    "The higher the precision value (8, 16, 32), the more detail and hence data used to express a number. \n",
    "\n",
    "This matters in deep learning and numerical computing because you're making so many operations, the more detail you have to calculate on, the more compute you have to use.\n",
    "\n",
    "So lower precision datatypes are generally faster to compute but sacrifice some performance on evaluation methorics like accuracy (faster to compute but less accurate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "3d88f5c9-2d7b-454d-92bc-8a59b0428874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default datatype for tensors is float32\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0,],\n",
    "                                dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
    "                                device=None, # defaults to None, which uses the default tensor type\n",
    "                                requires_grad=False) # if True, operations performed on the tensor are recorded\n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "cdf94b8b-32fa-4fbf-bdb2-fbbaeb4fc922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                                dtype=torch.float16) # torch.float16) # torch.half would alsowork\n",
    "float_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b465dcbc-7bd6-4905-bcef-0d68c985807e",
   "metadata": {},
   "source": [
    "## Getting Information from Tensors\n",
    "- `shape`: what shape is the tensor? (some operations require specific shape rules)\n",
    "- `dtype`: what datatype are the elements within the tensor stored in?\n",
    "- `device`: what device is the tensor stored on? (usually GPU or CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4049ec89-e3a3-45aa-b15d-b89bb213df78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3726, 0.3611, 0.8922, 0.6085],\n",
      "        [0.4945, 0.4295, 0.4961, 0.4770],\n",
      "        [0.5786, 0.6301, 0.2932, 0.1206]])\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "\n",
    "# find out details about it\n",
    "print(some_tensor)\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {some_tensor.device}\") # will default to CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc60af9-f43d-4824-8160-79b84690332b",
   "metadata": {},
   "source": [
    "# 3 Biggers in PyTorch and deep learning\n",
    "1. Tensors not right datatype\n",
    "2. Tensors not right shape\n",
    "3. Tensors not on the right device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9485b15a-311c-4c71-acbb-f6ef978e3748",
   "metadata": {},
   "source": [
    "# Manipulating tensors (tensors operations)\n",
    "In deep learning, data (images, text, video, audio, protein structures, etc) gets represented as tensors.\n",
    "\n",
    "A model learns by investigating those tensors and perfoming a series of operations (could be 1,0000,000s+) on tensors to create a representation of the patterns in the input data.\n",
    "\n",
    "These operations are often a wonderful dance between:\n",
    "- Addition\n",
    "- Subtraction\n",
    "- Multiplication (element-wise)\n",
    "- Division\n",
    "- Matrix multiplication.\n",
    "\n",
    "## Basic Operations\n",
    "Let's strat with a few of the fundamental operations, addition (`+`), subtraction (`-`), multiplication (`*`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6016ae4f-ab8c-4db1-ad8a-cf5a5ad2d422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of values and add a number to it\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "296aa0dd-b1f4-410d-808a-aafa384d60bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply it by 10\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601f7661-5e03-4b58-90de-6b84f36b0f5b",
   "metadata": {},
   "source": [
    "Notice how the tensor values didn't end up being `tensor([110, 120, 130])`, this is because the values inside the tensor don't change unless they're reassigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a12d91fc-bb97-48ac-9284-f41dab17f8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensors don't change unless reassigned\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "388ab0a5-a1b5-4b89-b362-8808d054589e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtract and reassign\n",
    "tensor = tensor - 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e68a775-21c6-4a3b-bc89-23d5b64d15bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add and reassign\n",
    "tensor = tensor + 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c1281f-6a83-4600-8752-b797358246fb",
   "metadata": {},
   "source": [
    "PyTorch also has a bunch of built-in functions like `torch.mul()` (short for multiplication) and `torch.add()` to perform basic operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "05260495-5a3f-457d-b021-fc622fc76f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also use torch functions\n",
    "torch.multiply(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "19e8d131-308d-49f3-8e55-6b1e0e74d7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original tensor is still unchanged\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55273651-5f95-4d6c-99c9-01aa16c72298",
   "metadata": {},
   "source": [
    "However, it's more common to use the operator symbols like `*` instead of `torch.mul()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c94b9ce4-fd48-4a3a-990e-32054aea035a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication (each element multiples its equibalent, index 0 -> 0, 1 -> 1, 2 -> 2)\n",
    "print(tensor, \"*\", tensor)\n",
    "print(\"Equals:\", tensor * tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6d83dd4a-cd1b-470b-b84f-10dee8b0b7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aabcd06-dd06-4f0e-8744-489a650f75a4",
   "metadata": {},
   "source": [
    "# Matrix multiplication (is all you need)\n",
    "One of the most common operations in machine learning and deep learning algorithms (like neural networks) is matrix multiplication.\n",
    "\n",
    "Pytorch implements matrix multiplicatin functionality in the `torch.matmul()` method.\n",
    "\n",
    "The main 2 rules for matrix multiplication to remember are:\n",
    "\n",
    "1. The inner dimensions must match:\n",
    "```\n",
    "(3, 2) @ (3, 2) won't work\n",
    "(2, 3) @ (3, 2) will work\n",
    "(3, 2) @ (2, 3) will work\n",
    "```\n",
    "2. The resulting matrix has the shape of the outer dimensions:\n",
    "```\n",
    "(2, 3) @ (3, 2) -> (2, 2)\n",
    "(3, 2) @ (2, 3) -> (3, 3)\n",
    "```\n",
    "Note: \"@\" in Python is the symbol for matrix multiplication.\n",
    "\n",
    "\n",
    "Lets create a tensor and perform element-wise multiplication and matrix multiplication on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f1ae8b40-31c4-40f2-9f30-3191c071f8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8359fb-ed19-4a96-92d9-dd56c9f3180a",
   "metadata": {},
   "source": [
    "The difference between element-wise multiplicaiton and matrix multiplication in the addition of values.\n",
    "\n",
    "For our `tensor` varialbe with values `[1, 2, 3]`:\n",
    "\n",
    "|Operation|Calculaltion|Code|\n",
    "|---|---|---|\n",
    "|Element-wise multiplication|`[1*1, 2*2, 3*3]`=`[1, 4, 5]`|`tensor * tensor`|\n",
    "|Matrix multiplicatin|`[1*1, 2*2, 3*3]`=`[14]`|`torch.matmul(tensor)`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9fbf139a-aad5-4837-a19e-18d42e540dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Element-wise matrix multiplication\n",
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8c7cc0f1-30d7-445b-a5c7-7d7ab269bdaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "38dc5461-4872-4764-b60c-1e722199bda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also use the \"@\" symbol for matrix multiplicaiton, through not recommended\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c00c1ce0-cedf-4e23-921c-f1b5a29cb89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A = torch.tensor([[1], [2], [3]])\n",
    "tensor_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "6e3620c5-f194-4491-a1f0-a9e9f1906792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor, tensor_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "2da1927f-3676-473f-b5db-5f60ee5445d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [2, 4, 6],\n",
       "        [3, 6, 9]])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor_A, tensor_A.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "c25a8380-bbec-40dd-aeae-d0b689d22561",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[224], line 10\u001b[0m\n\u001b[1;32m      2\u001b[0m tensor_A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m      3\u001b[0m                          [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m],\n\u001b[1;32m      4\u001b[0m                          [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      6\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[1;32m      7\u001b[0m                          [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m11\u001b[39m], \n\u001b[1;32m      8\u001b[0m                          [\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m12\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (this will error)\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shapes need to be in the right way  \n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11], \n",
    "                         [9, 12]], dtype=torch.float32)\n",
    "\n",
    "torch.matmul(tensor_A, tensor_B) # (this will error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16830bf-9025-40e2-a08a-74ab85fb7564",
   "metadata": {},
   "source": [
    "We can make matrix multiplication work between `tensor_A` and `tensor_B` by making their inner dimensions match.\n",
    "\n",
    "One of the ways to do thsi is with a `transpose` (swithc the dimensions of a given tensor).\n",
    "\n",
    "You can perform transposes in PyTorch using either:\n",
    "- `torch.transpose(input, dim0, dim1)`: where `input` is thedesired tensor to transpose and `dim0` and `dim1` are the dimensions to be swapped.\n",
    "- `tensor.T`: where `tensor` is the desired tensor to trnaspose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "5f5c2598-ca39-4f64-9c3f-98cda379032a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7., 10.],\n",
      "        [ 8., 11.],\n",
      "        [ 9., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# View tensor_A and tensor_B\n",
    "print(tensor_A)\n",
    "print(tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "07927f4b-52b3-4482-a73e-1b7b89c3621c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# View tensor_A and tensor_B\n",
    "print(tensor_A)\n",
    "print(tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "458ac761-942e-47a4-a0ca-75e80afcaff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27.,  30.,  33.],\n",
       "        [ 61.,  68.,  75.],\n",
       "        [ 95., 106., 117.]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor_A, tensor_B.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642a1d4b-397f-4d0a-a462-3d301cb3b809",
   "metadata": {},
   "source": [
    "You can also use `torch.mm()` which is short for `torch.matmul()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "334aebae-7645-4a6c-9415-0ce75b85bd65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27.,  30.,  33.],\n",
       "        [ 61.,  68.,  75.],\n",
       "        [ 95., 106., 117.]])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.mm is a shortcut for matmul\n",
    "torch.mm(tensor_A, tensor_B.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131342e7-002f-4b13-a6d0-f6e741c3d02b",
   "metadata": {},
   "source": [
    "# torch.nn.Linear()\n",
    "Neural networks are full of matrix multiplications and dot products.\n",
    "\n",
    "The `torch.nn.Linear()` module, also known as a feed-forward layer or fully connected layer, implements a matrix multiplicatiin between an input `x` and weights matrix `A`.\n",
    "\n",
    "$$\n",
    "y = x\\cdot A^{T}+b\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- `x`: is the input layer (deep learning is a stack of layers like `torch.nn.Linear()` and others on top of each other).\n",
    "- `A`: is the weights matrix created by the layer, this starts out as random numbers that get adjusted as a neural network learns to better represent patterns in the data (notice the \"`T`\", that's because the weights matrix gets transposed).\n",
    "- - Note: You might also often see `W` or another letter like `X` used to showcase the weights matrix.\n",
    "- `b` is the bias term used to slightly offset the weights and inputs.\n",
    "- `y` is the output (a manipulation of the input in the hopes to discover patterns in it).\n",
    "\n",
    "This is a linear function (you may have seen something like $y = mx + b$ in high school or elsewhere), and can be used to draw a straight line!\n",
    "\n",
    "Let's play around with a linear layer.\n",
    "\n",
    "Try changing the values of `in_features` and `out_features` below to see what happens.\n",
    "\n",
    "Do you notice anything to do with the shapes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9ee187-3ab5-4730-ad68-b2d7b7f52305",
   "metadata": {},
   "source": [
    "# since the linear layers starts with a random weights matrix, let's make it reproducible\n",
    "torch.manual_seed(42)\n",
    "# This uses matrix multiplication\n",
    "linear = torch.nn.Linear(in_features=2, # in_features = matches inner dimension of input\n",
    "                         out_features=6) # out_features = describes outer value\n",
    "x = tensor_A\n",
    "output = linear(x)\n",
    "print(f\"Input shape: {x.shape}\\n\")\n",
    "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f00f9a-67f8-481b-b961-726e70ffa373",
   "metadata": {},
   "source": [
    "## Reshaping, Stacking, Squeezing and Unsqueezing\n",
    "\n",
    "|Method|One-line description|\n",
    "|---|---|\n",
    "|torch.reshape(input, shape)|Reshapes input to shap (if compatible), cna also sue torch.tensor.reshape()|\n",
    "|Tensor.view(shape)|Returns a view of the original tensor.|\n",
    "|torch.stack(tensors, dim=0)|Concatinates a sequence of tensros along a new dimension (dim), all tensors must be same size.|\n",
    "|torch.squeeze(input)|Squeezes input to remove all the dimensions with value 1.|\n",
    "|torch.unsqueeze(input, dim)|Returns input with a dimension value of 1 added at dim.|\n",
    "|torch.permute(input, dims)|Returns a view of the original input with its dimensions permuted (rearranged to dims.|\n",
    "\n",
    "Lets create a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "b844d803-930c-47ca-ab29-1bdca0d38cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "import torch\n",
    "x = torch.arange(1., 8.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df79f967-a798-4019-b21e-eb070c72a9a4",
   "metadata": {},
   "source": [
    "Now let's add an extra dimension with `torch.reshape()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "3e5e08a3-19cd-4773-ab10-ece0aaafb435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension\n",
    "x_reshaped = x.reshape(1, 7)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4a44c6-d88b-47bf-86e1-c49f4cd01757",
   "metadata": {},
   "source": [
    "We can also change the view with `torch.view()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "6e2a227b-6cb3-4ffe-8630-9852ab2de0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change view (keeps same data as original but changes view)\n",
    "z = x.view(1, 7)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaad55d-ad10-44a1-a7f8-5887c4aa36a4",
   "metadata": {},
   "source": [
    "Remember though, changing the view of a tensor with `torch.view()` really only creates a new view of the same tensor.\n",
    "\n",
    "So changing the view changes the original tensor too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "55ff7e6b-c635-4845-be60-ddeb867af547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), tensor([1., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing z changesx x\n",
    "z[: 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5297b599-274d-48ac-8c1b-7f0468e21cd8",
   "metadata": {},
   "source": [
    "If we wanted to stack our new tensor on top of itself 5 times, we could do so with `torch.stack()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "1d216f8e-a365-441d-b8b4-f046cee59a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4., 5., 6., 7.],\n",
       "        [1., 2., 3., 4., 5., 6., 7.],\n",
       "        [1., 2., 3., 4., 5., 6., 7.],\n",
       "        [1., 2., 3., 4., 5., 6., 7.]])"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x, x, x, x], dim=0) # try changing dim to dim=1 and see what happens\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d0d25d-c2cc-44df-9713-d3d10a0fae01",
   "metadata": {},
   "source": [
    "We can use `torch.squeeze()` to remove all singel dimensions from a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "b43e07b7-6a14-4ef2-a20a-40fc91ec35da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[1., 2., 3., 4., 5., 6., 7.]])\n",
      "Previous shape: torch.Size([1, 7])\n",
      "\n",
      "New tensor: tensor([1., 2., 3., 4., 5., 6., 7.])\n",
      "New shape: torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "# Remove extra dimension from x_reshaped\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"\\nNew tensor: {x_squeezed}\")\n",
    "print(f\"New shape: {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0c2174-01ce-4912-bfe4-d84c7b001ed3",
   "metadata": {},
   "source": [
    "You can use `torch.unsqueeze()` to add a dimension value to 1 at a specific index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "892ea8e4-ae03-41fe-9e2b-557ceb41837b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([1., 2., 3., 4., 5., 6., 7.])\n",
      "Previous shape: torch.Size([7])\n",
      "\n",
      "New tensor: tensor([[1., 2., 3., 4., 5., 6., 7.]])\n",
      "New shape: torch.Size([1, 7])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previous tensor: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "## Add an extra dimension with unsqueeze\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd5e58d-22c8-4871-af36-4281f6db5185",
   "metadata": {},
   "source": [
    "You can also rearrange the order of axes values with `torch.permutate(input, dims)`, where the `input` gets turned into a view with new `dims`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "f86fd0b5-fa4d-4452-b2b9-db600d0966dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Create tensor with specific shape\n",
    "x_original = torch.rand(size=(224, 224, 3))\n",
    "\n",
    "# Permute the original tensor to rearrange the x axis order\n",
    "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6f820a-e156-4b86-a749-16c2a5288e9b",
   "metadata": {},
   "source": [
    "# Getting PyTorch to run on the GPU\n",
    "You can use a GPU to store data (tensors) and computing on data (performing operations on tensors).\n",
    "\n",
    "To do so, you can use the `torch.cuda` package.\n",
    "\n",
    "To test if PyTorch has access to a GPU using `torch.cuda.is_available()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8880232-7716-4096-ab5f-25a9c28edd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for GPU\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b08adfaf-0791-4dd6-a790-dca00e6597c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec  6 19:40:48 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070 ...    Off |   00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   37C    P8             10W /  285W |     191MiB /  16376MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
