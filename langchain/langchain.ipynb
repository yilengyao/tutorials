{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ced042c-e352-44cb-b52d-ab30e4fd1ad4",
   "metadata": {},
   "source": [
    "# Architecture\n",
    "- langchain-core: Base abstraction for chat models and other components\n",
    "- Integration packages (eg. langchain-openai, langchain-anthropic, etc.): Important integrations have been split into lightweight packages that are co-maintained by the Langchain team and the integration developers.\n",
    "- langchain: Chains, agents and retrieval strategies that make up an application's cognitive architecture.\n",
    "- langchain-community: Third-party integration that are community maintained.\n",
    "- langgraph: Orchestration framework for combining Langchain components into production ready applications with persistence streaming and other key featues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785ea8f4-cd62-4485-b73b-e10824b886ea",
   "metadata": {},
   "source": [
    "### BaseChatModel\n",
    "Base class for chat models\n",
    "\n",
    "Method|Input|Output|Description|\n",
    "|--|--|--|--|\n",
    "|invoke|str List[dict tuple BaseMessage] PromptValue|BaseMessage|A single chat model call.|\n",
    "|ainvoke|\"|BaseMessage|Defaults to running invoke in an async executor|\n",
    "|stream|‘’’|Iterator[BaseMessageChunk]|Defaults to yielding output of invoke.|\n",
    "|astream|‘’’|AsyncIterator[BaseMessageChunk]|Defaults to yielding output of ainvoke.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16be87d9-c0ca-4cf6-954f-2cb2e4d1539b",
   "metadata": {},
   "source": [
    "RunnableLambda converts python callable into a runnable.\n",
    "\n",
    "Callable is any object called like a function, eg. Functions, Methods, Classes, Instances with method `__call__`.\n",
    "\n",
    "Runnable is a interface that has invoke method.\n",
    "\n",
    "So we add the invoke method to the callable when we convert to RunnableLambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef3b0d85-e63e-4406-99f0-d635c79a209a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a RunnableLambda\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def add_one(x: int) -> int:\n",
    "    return x + 1\n",
    "\n",
    "runnable = RunnableLambda(add_one)\n",
    "\n",
    "runnable.invoke(1) # returns 2\n",
    "runnable.batch([1, 2, 3]) # returns [2, 3, 4]\n",
    "\n",
    "# Async is supported by default by delegating to the sync implementation\n",
    "await runnable.ainvoke(1) # returns 2\n",
    "await runnable.abatch([1, 2, 3]) # returns [2, 3, 4]\n",
    "\n",
    "async def add_one_async(x: int) -> int:\n",
    "    return x + 1\n",
    "\n",
    "runnable = RunnableLambda(add_one, afunc=add_one_async)\n",
    "runnable.invoke(1) # Uses add_one\n",
    "await runnable.ainvoke(1) # Uses add_one_async"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11675e58-c657-4ead-a655-e591ea2bbf14",
   "metadata": {},
   "source": [
    "#### format_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c555810-5ae4-4a17-94ad-6287a8e5855e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.schema import Document \n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def format_docs(docs: List[Document]) -> str:\n",
    "    '''Format the docs.'''\n",
    "    return \", \".join([doc.page_content for doc in docs])\n",
    "\n",
    "format_docs = RunnableLambda(format_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d35542-75b4-41e6-b9eb-dd8fad111ca0",
   "metadata": {},
   "source": [
    "#### some_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce9f96bd-da81-46bd-8381-1abcd9733bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def some_tool(x: int, y: str) -> dict:\n",
    "    '''Some_tool.'''\n",
    "    return {\"x\": x, \"y\": y}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be70c69-ec57-4d95-8ff9-9f5b2876eb01",
   "metadata": {},
   "source": [
    "#### prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28292ff9-a1db-4efb-870b-8ac8aca0cc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"You are Cat Agent 007\"), (\"human\", \"{question}\")]\n",
    ").with_config({\"run_name\": \"my_template\", \"tags\": [\"my_template\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16e48861-9205-4631-8a8f-702cdaee855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "async def reverse(s: str) -> str:\n",
    "    return s[::-1]\n",
    "\n",
    "chain = RunnableLambda(func=reverse)\n",
    "\n",
    "events = [\n",
    "    event async for event in chain.astream_events(\"hello\", version=\"v2\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23bc59ba-48cb-4dd5-bf66-4ec94aa60b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'event': 'on_chain_start',\n",
       "  'data': {'input': 'hello'},\n",
       "  'name': 'reverse',\n",
       "  'tags': [],\n",
       "  'run_id': '62ef125d-df2c-42fa-8a1b-c17efbc40bf3',\n",
       "  'metadata': {},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chain_stream',\n",
       "  'run_id': '62ef125d-df2c-42fa-8a1b-c17efbc40bf3',\n",
       "  'name': 'reverse',\n",
       "  'tags': [],\n",
       "  'metadata': {},\n",
       "  'data': {'chunk': 'olleh'},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chain_end',\n",
       "  'data': {'output': 'olleh'},\n",
       "  'run_id': '62ef125d-df2c-42fa-8a1b-c17efbc40bf3',\n",
       "  'name': 'reverse',\n",
       "  'tags': [],\n",
       "  'metadata': {},\n",
       "  'parent_ids': []}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726c88df-77be-4902-8a25-e5008b5dfd77",
   "metadata": {},
   "source": [
    "## Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c6bfb62-99ae-4119-89f7-ce28c4289180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"LANGSMITH_API_KEY\"):\n",
    "  os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter API key for LangSmith: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9350c1f2-03f8-48ae-9235-abb0c8a1ce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"pr-overcooked-push-81\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48c7a799-26c6-4eb6-b4b5-10ced0798c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langsmith\n",
    "from langchain_core.tracers.context import tracing_v2_enabled\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "langsmith_client = langsmith.Client(\n",
    " api_key=os.environ.get(\"LANGSMITH_API_KEY\"),\n",
    " api_url='https://api.smith.langchain.com'\n",
    ")\n",
    "with tracing_v2_enabled(client=langsmith_client, project_name=\"default\"):\n",
    "    model = init_chat_model(\"qwen2.5-coder:14b\", model_provider=\"ollama\")\n",
    "    model.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d3d3f7c-fcb6-4f70-bc3e-de6ff03f40e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={'model': 'qwen2.5-coder:14b', 'created_at': '2025-03-26T02:40:56.063796575Z', 'done': True, 'done_reason': 'stop', 'total_duration': 178903129, 'load_duration': 8050710, 'prompt_eval_count': 33, 'prompt_eval_duration': 2000000, 'eval_count': 10, 'eval_duration': 165000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-fd703b10-742e-4b43-9c65-ee4cb5f4c3a4-0', usage_metadata={'input_tokens': 33, 'output_tokens': 10, 'total_tokens': 43})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"qwen2.5-coder:14b\", model_provider=\"ollama\")\n",
    "model.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36809918-71a1-4bdf-9163-6fef697bcc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'aime programmer.\", additional_kwargs={}, response_metadata={'model': 'qwen2.5-coder:14b', 'created_at': '2025-03-26T02:40:56.22073688Z', 'done': True, 'done_reason': 'stop', 'total_duration': 123745494, 'load_duration': 9008977, 'prompt_eval_count': 33, 'prompt_eval_duration': 15000000, 'eval_count': 6, 'eval_duration': 96000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-c06f7835-c6ce-4aed-acae-9720ebe38223-0', usage_metadata={'input_tokens': 33, 'output_tokens': 6, 'total_tokens': 39})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "import langsmith\n",
    "from langchain_core.tracers.context import tracing_v2_enabled\n",
    "langsmith_client = langsmith.Client(\n",
    " api_key='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',\n",
    " api_url='https://api.smith.langchain.com'\n",
    ")\n",
    "llm = ChatOllama(\n",
    "    model=\"qwen2.5-coder:14b\",\n",
    "    temperature=0,\n",
    "    # other params...\n",
    ")\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "with tracing_v2_enabled(client=langsmith_client, project_name=\"default\"):\n",
    "    ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab13ddcd-89e3-411e-bb2d-9dd144244a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b2e3eb7-bf30-4c4c-a148-d43fb3c4d9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m26 packages\u001b[0m \u001b[2min 235ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)----\u001b[0m\u001b[0m     0 B/130.02 KiB                    \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)----\u001b[0m\u001b[0m 14.91 KiB/130.02 KiB                  \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)----\u001b[0m\u001b[0m 30.91 KiB/130.02 KiB                  \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)----\u001b[0m\u001b[0m 46.91 KiB/130.02 KiB                  \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)----\u001b[0m\u001b[0m 62.91 KiB/130.02 KiB                  \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)----\u001b[0m\u001b[0m 78.91 KiB/130.02 KiB                  \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)----\u001b[0m\u001b[0m 94.91 KiB/130.02 KiB                  \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)----\u001b[0m\u001b[0m 110.91 KiB/130.02 KiB                 \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)\u001b[2m\u001b[0m\u001b[0m 126.91 KiB/130.02 KiB                 \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m4 packages\u001b[0m \u001b[2min 40ms\u001b[0m\u001b[0m                                                  \u001b[1A\n",
      "\u001b[2mUninstalled \u001b[1m4 packages\u001b[0m \u001b[2min 5ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m4 packages\u001b[0m \u001b[2min 5ms\u001b[0m\u001b[0m48                               \u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mlangchain-core\u001b[0m\u001b[2m==0.3.45\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-core\u001b[0m\u001b[2m==0.3.48\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mlangchain-ollama\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-ollama\u001b[0m\u001b[2m==0.3.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mlangsmith\u001b[0m\u001b[2m==0.3.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangsmith\u001b[0m\u001b[2m==0.3.18\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1morjson\u001b[0m\u001b[2m==3.10.15\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1morjson\u001b[0m\u001b[2m==3.10.16\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install langchain\n",
    "!uv pip install -U langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c230216f-c610-469e-8a79-7f45d12e030e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, so I need to figure out what LangChain is. I\\'ve heard the term before in the context of AI and machine learning, but I\\'m not exactly sure what it refers to. Let me try to break this down.\\n\\nFirst, I know that \"chain\" often implies a sequence or a series of connected parts. In programming, especially with libraries and frameworks, chaining can refer to linking together different functions or modules to create a more complex system. So maybe LangChain is something related to combining different AI components?\\n\\nI remember hearing about various machine learning frameworks like TensorFlow and PyTorch. There\\'s also the concept of transformers in NLP, like BERT or GPT models. Perhaps LangChain is a framework that allows these different parts to work together more seamlessly?\\n\\nWait, I think there was something called \"LangChain\" specifically for language models. Maybe it\\'s a way to create chains where each step processes data and passes it along, much like a pipeline. For example, one model might extract information from text, another could analyze it, and then another could generate a response.\\n\\nSo, putting this together, LangChain might be a framework that lets you build complex AI workflows by chaining together different models or tasks. It probably makes it easier to integrate various NLP tools or machine learning models into a single pipeline without having to code everything from scratch each time.\\n\\nI also recall that in some projects, people use LangChain for creating chatbots or interactive systems where multiple steps are involved. So maybe it\\'s not just about static models but dynamic interactions where each step depends on the previous one.\\n\\nAnother thought: could LangChain be related to prompt engineering? Maybe it provides tools to design better prompts by chaining together different prompt templates or conditions. That would make sense because effective prompting is crucial for getting good results from language models.\\n\\nI should also consider if there are specific features of LangChain that set it apart from other frameworks. For instance, does it handle state management between steps? Does it provide logging or monitoring tools? Or maybe it\\'s more focused on ease of use and rapid prototyping?\\n\\nIn summary, LangChain seems to be a framework designed to help developers build complex AI applications by chaining together various models or processes in a modular way, making it easier to create sophisticated NLP workflows without starting from scratch each time.\\n</think>\\n\\nLangChain is a framework designed to facilitate the creation of complex AI applications, particularly in natural language processing (NLP). It allows developers to chain together various machine learning models and tasks into a cohesive workflow. This approach enables the development of systems where multiple steps—such as information extraction, analysis, and response generation—are connected sequentially, often resembling a pipeline or dynamic interaction.\\n\\nKey aspects of LangChain include:\\n\\n1. **Modular Workflow Construction**: It provides tools to integrate different NLP models and processes into a single application without rebuilding from scratch each time.\\n\\n2. **Chaining Components**: The framework allows for the linking of various AI components, enabling more sophisticated applications like chatbots or interactive systems where each step depends on the previous one.\\n\\n3. **Prompt Engineering**: LangChain may also support advanced prompting techniques, helping to design effective prompts that enhance model performance through chaining prompt templates or conditions.\\n\\n4. **Ease of Use and Prototyping**: It likely offers features aimed at ease of use, rapid prototyping, and possibly state management, logging, or monitoring tools to aid in development.\\n\\nIn essence, LangChain is a versatile toolset for building dynamic, multi-step AI applications by orchestrating various models and processes efficiently.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "deepseek_model = OllamaLLM(model=\"deepseek-r1:14b\")\n",
    "\n",
    "deepseek_chain = prompt | deepseek_model\n",
    "\n",
    "deepseek_chain.invoke({\"question\": \"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "860b23db-5020-4265-85c0-6606e8ca7195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LangChain is an open-source framework designed to simplify the process of building language models and applications that leverage these models. It provides a set of tools, libraries, and components that enable developers to easily create, deploy, and manage natural language processing (NLP) systems.\\n\\nTo break it down further:\\n1. **Open-Source**: This means that LangChain's source code is available for anyone to view, use, modify, and distribute. It fosters collaboration and innovation within the developer community.\\n2. **Framework**: It serves as a structured approach or set of guidelines for building software. In this case, it provides a framework for working with language models.\\n3. **Simplify the Process**: LangChain aims to make it easier for developers to work with complex NLP technologies. This includes abstracting away some of the technical details so that developers can focus more on the specific tasks they need to accomplish.\\n4. **Build, Deploy, Manage**: These are key functionalities provided by LangChain:\\n   - **Build**: Developers can use LangChain to create new language models or applications quickly and efficiently.\\n   - **Deploy**: Once built, LangChain provides tools for deploying these models and applications in various environments, ensuring they are accessible and performant.\\n   - **Manage**: It also includes features for managing deployed models, such as monitoring performance, updating models, and scaling them to meet demand.\\n\\n5. **Language Models and Applications**: LangChain is specifically tailored for working with language models, which are AI systems designed to understand, generate, and manipulate human language. These models can be used for a wide range of applications, including chatbots, translation services, text summarization, sentiment analysis, and more.\\n\\nOverall, LangChain is a valuable resource for anyone involved in developing or working with language-based technologies, offering a streamlined way to harness the power of AI in natural language processing tasks.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "qwen_model = OllamaLLM(model=\"qwen2.5-coder:14b\")\n",
    "\n",
    "qwen_chain = prompt | qwen_model\n",
    "\n",
    "qwen_chain.invoke({\"question\": \"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf78c3c6-c196-4437-947b-3c1a1dda3c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To solve the problem of multiplying 5 by 5:\\n\\n1. First, understand that multiplication is repeated addition. So, 5 * 5 can be thought of as adding 5 to itself 5 times.\\n2. We start with 0 and add 5 five times:\\n   - 0 + 5 = 5\\n   - 5 + 5 = 10\\n   - 10 + 5 = 15\\n   - 15 + 5 = 20\\n   - 20 + 5 = 25\\n\\nSo, 5 * 5 equals 25.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwen_chain.invoke({\"question\": \"What is 5*5?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30cb1c45-6166-48ba-bd75-b086d95d76a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nTo find the product of 5 multiplied by 5, I can start by understanding that multiplication is essentially repeated addition.\\n\\nTherefore, 5 times 5 means adding the number 5 to itself five times.\\n\\nPerforming this calculation gives me a total of 25.\\n</think>\\n\\n**Question:** What is \\\\(5 \\\\times 5\\\\)?\\n\\n---\\n\\n**Solution:**\\n\\nTo find the product of \\\\(5 \\\\times 5\\\\), follow these simple steps:\\n\\n1. **Understand Multiplication as Repeated Addition:**\\n   - \\\\(5 \\\\times 5\\\\) means adding the number 5 to itself five times.\\n\\n2. **Perform the Calculation:**\\n   \\\\[\\n   5 + 5 + 5 + 5 + 5 = 25\\n   \\\\]\\n\\n---\\n\\n**Answer:** \\\\(\\\\boxed{25}\\\\)'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepseek_chain.invoke({\"question\": \"What is 5*5?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0acacd0-c804-48cf-b844-04f508076681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To calculate 2555 * 2555, you can use the formula for squaring a number or perform direct multiplication. Here’s a step-by-step breakdown using both methods:\\n\\n### Method 1: Using the Squaring Formula\\n\\nThe square of a number \\\\( n \\\\) is given by:\\n\\\\[ n^2 = (n - a)(n + a) + a^2 \\\\]\\n\\nWhere \\\\( a \\\\) is chosen to make the calculation easier. Let's choose \\\\( a = 500 \\\\):\\n- Here, \\\\( n = 2555 \\\\)\\n- So, \\\\( a = 500 \\\\)\\n\\nNow plug these values into the formula:\\n\\\\[ (2555)^2 = (2555 - 500)(2555 + 500) + 500^2 \\\\]\\n\\\\[ = 2055 \\\\times 3055 + 250000 \\\\]\\n\\nNow calculate each part:\\n- \\\\( 2055 \\\\times 3055 = 6271025 \\\\)\\n- \\\\( 250000 = 250000 \\\\)\\n\\nAdd these results together:\\n\\\\[ 6271025 + 250000 = 6521025 \\\\]\\n\\nSo, \\\\( 2555 \\\\times 2555 = 6521025 \\\\).\\n\\n### Method 2: Direct Multiplication\\n\\nYou can also perform the multiplication directly:\\n\\\\[ 2555 \\\\times 2555 \\\\]\\n- First, multiply 2555 by 5 (the units digit of 2555):\\n\\\\[ 2555 \\\\times 5 = 12775 \\\\]\\n\\n- Next, multiply 2555 by 50 (the tens digit of 2555):\\n\\\\[ 2555 \\\\times 50 = 127750 \\\\]\\n\\n- Then, multiply 2555 by 500 (the hundreds digit of 2555):\\n\\\\[ 2555 \\\\times 500 = 1277500 \\\\]\\n\\n- Finally, multiply 2555 by 2000 (the thousands digit of 2555):\\n\\\\[ 2555 \\\\times 2000 = 5110000 \\\\]\\n\\nNow add all these results together:\\n\\\\[ 12775 + 127750 + 1277500 + 5110000 = 6521025 \\\\]\\n\\nSo, \\\\( 2555 \\\\times 2555 = 6521025 \\\\).\\n\\nBoth methods confirm that the product of 2555 and 2555 is 6521025.\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwen_chain.invoke({\"question\": \"What is 2555*2555?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f871186-82d1-4c46-9bbc-331a1252f627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<think>\\nTo calculate 2555 multiplied by 2555, I can start by breaking down the numbers to make the multiplication easier.\\n\\nFirst, I notice that 2555 is equal to 2000 plus 555. So, I'll express the multiplication as (2000 + 555) multiplied by itself, which forms a squared term: (2000 + 555)^2.\\n\\nNext, I'll apply the algebraic identity for squaring a binomial: (a + b)^2 = a^2 + 2ab + b^2. Here, a is 2000 and b is 555.\\n\\nCalculating each part separately:\\n1. a squared is 2000 multiplied by 2000, which equals 4,000,000.\\n2. 2 times a times b is 2 times 2000 times 555, totaling 2,220,000.\\n3. b squared is 555 multiplied by 555, resulting in 308,025.\\n\\nFinally, I'll add all these components together: 4,000,000 plus 2,220,000 equals 6,220,000, and adding 308,025 gives a total of 6,528,025.\\n\\nTherefore, the product of 2555 multiplied by itself is 6,528,025.\\n</think>\\n\\nCertainly! Let's calculate \\\\(2555 \\\\times 2555\\\\) step by step.\\n\\n### Step 1: Break Down the Multiplication\\nWe can express \\\\(2555 \\\\times 2555\\\\) as:\\n\\\\[\\n(2500 + 55) \\\\times (2500 + 55)\\n\\\\]\\nThis simplifies the multiplication using the formula for squaring a binomial:\\n\\\\[\\n(a + b)^2 = a^2 + 2ab + b^2\\n\\\\]\\n\\n### Step 2: Apply the Formula\\nLet \\\\(a = 2500\\\\) and \\\\(b = 55\\\\). Plugging these into the formula:\\n\\\\[\\n(2500 + 55)^2 = (2500)^2 + 2 \\\\times 2500 \\\\times 55 + (55)^2\\n\\\\]\\n\\n### Step 3: Calculate Each Term\\n1. **Calculate \\\\(a^2\\\\)**\\n   \\\\[\\n   2500^2 = 6,250,000\\n   \\\\]\\n   \\n2. **Calculate \\\\(2ab\\\\)**\\n   \\\\[\\n   2 \\\\times 2500 \\\\times 55 = 2 \\\\times 137,500 = 275,000\\n   \\\\]\\n   \\n3. **Calculate \\\\(b^2\\\\)**\\n   \\\\[\\n   55^2 = 3,025\\n   \\\\]\\n\\n### Step 4: Sum All Terms\\n\\\\[\\n6,250,000 + 275,000 + 3,025 = 6,528,025\\n\\\\]\\n\\n### Final Answer\\n\\\\[\\n\\\\boxed{6,\\\\!528,\\\\!025}\\n\\\\]\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepseek_chain.invoke({\"question\": \"What is 2555*2555?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "220509e2-93b2-423a-8771-ada607bb9487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6528025"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2555*2555"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811f1585-0d78-4dc6-a0a3-709bd7a6a013",
   "metadata": {},
   "source": [
    "## Techniques to mitigate LLM limitations\n",
    "limitations: outdated knowledge, inability to take action, lack of context, hallucination risks, biases and discrimination, lack of transparency, lack of context\n",
    "\n",
    "Mitigation techniques:\n",
    "- Retrieval augmenation: This technique accesses knowledge bases to supplement an LLM's outdated training data, providing external context and reducing hallucination risk.\n",
    "- Chaining: This technique integrates action like searches and calculations.\n",
    "- Prompt engineering: This involves the careful crafting of prompts by providing critical context the guides appropriate responses.\n",
    "- Monitoring, filtering, and review: This involves ongoing and effective oversight of emerging issues regarding the application's input and output to detect issues. Both manual reviews and automated filters then correct potential problems with the output. This includes the following:\n",
    "- - Filters, like block lists, sensitivity classifiers, and banned word filters, can automatically flag issues.\n",
    "  - Constitutional principles monitor and filter unethical and inappropriate content.\n",
    "  - Human reviews provide insight into model behaviour and output.\n",
    "- Memory: Retains conversation context by persisting conversation data and context across interactions.\n",
    "- Fine-tuning: Training and tuning the LLM on more appropriate data for the application domain and principles. This adapts the model's behaviour for its specific purpose.\n",
    "\n",
    "### LLM App\n",
    "LLM apps typically have the following components:\n",
    "- A client layer to collect user input as text queries or decisions.\n",
    "- A prompt engineering layer to construct prompts that guide the LLM.\n",
    "- An LLM backend to analyze prompts and produce relevant text responses.\n",
    "- An output parsing layer to interpret LLM responses for the application interface.\n",
    "- Optional integration with external services via function APIs, knwoledge bases, and reasoning algorithms to augment the LLM's capabilities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "91a302a8-5c3b-4b71-9f0c-6adf6faec874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install graphviz\n",
    "# !sudo apt-get install graphviz -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98e44ede-8d62-4039-817b-eb4284a01f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "from IPython.display import Image\n",
    "\n",
    "def create_llm_flow():\n",
    "    # Create a new directed graph\n",
    "    dot = Digraph(comment='LLM Processing Flow')\n",
    "    \n",
    "    # Configure graph attributes\n",
    "    dot.attr(rankdir='LR')  # Left to right layout\n",
    "    dot.attr('node', shape='box', style='rounded')\n",
    "    \n",
    "    # Add nodes\n",
    "    dot.node('client', 'Client')\n",
    "    dot.node('prompt', 'Prompt')\n",
    "    dot.node('llm', 'LLM')\n",
    "    dot.node('parser', 'Output Parser')\n",
    "    \n",
    "    # Add edges with arrows\n",
    "    dot.edge('client', 'prompt')\n",
    "    dot.edge('prompt', 'llm')\n",
    "    dot.edge('llm', 'parser')\n",
    "    \n",
    "    return dot\n",
    "\n",
    "# Create and save the graph\n",
    "flow = create_llm_flow()\n",
    "flow.render('llm_flow', format='png', cleanup=False)\n",
    "Image(\"./llm_flow.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1337fe62-893c-476a-a493-fe243131c0f6",
   "metadata": {},
   "source": [
    "LLM apps can integrate external services via:\n",
    "- Function APIs to access web tools and databases.\n",
    "- Advanced reasoning algorithms for complex logic chains.\n",
    "- Retrieval augmented generation via knowledge bases.\n",
    "\n",
    "Retrieval augmented generation (RAG), enhances the LLM with external knowledge. These extensions expand the capabilities of LLM apps beyond the LLM's knowledge alone. For instance:\n",
    "- Function calling allows parameterized API requests.\n",
    "- SQL functions enable conversational database queries.\n",
    "- Reasoning algorithms linke chain-of-though fcilitate multi-step logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd4c21de-5bc2-46f8-b496-4623d33b0413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def create_llm_flow():\n",
    "    dot = Digraph()\n",
    "    \n",
    "    # Basic left-to-right layout\n",
    "    dot.attr(rankdir='LR')\n",
    "    \n",
    "    # Simple boxes for nodes\n",
    "    dot.attr('node', shape='box')\n",
    "    \n",
    "    # Add nodes\n",
    "    dot.node('client', 'Client')\n",
    "    dot.node('frontend', 'Frontend')\n",
    "    dot.node('prompt', 'Prompt\\nEngineering')\n",
    "    dot.node('llm', 'LLM')\n",
    "    dot.node('parser', 'Output\\nParsing')\n",
    "    dot.node('ext', 'External Knowledge')\n",
    "    \n",
    "    # Main flow edges (solid)\n",
    "    dot.edge('client', 'frontend')\n",
    "    dot.edge('frontend', 'prompt')\n",
    "    dot.edge('prompt', 'llm')\n",
    "    dot.edge('llm', 'parser')\n",
    "    dot.edge('parser', 'frontend')\n",
    "    \n",
    "    # Dotted connections\n",
    "    dot.edge('ext', 'prompt', style='dotted')\n",
    "    dot.edge('parser', 'ext', style='dotted')\n",
    "    \n",
    "    # LLM self-loop\n",
    "    dot.edge('llm', 'llm', style='dashed', label='loop')\n",
    "    \n",
    "    return dot\n",
    "\n",
    "# Generate the diagram\n",
    "g = create_llm_flow()\n",
    "g.save('advance_llm_flow.dot')\n",
    "g.render('advance_llm_flow', format='png', cleanup=False)\n",
    "Image(\"./advance_llm_flow.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbb1868-6ccc-463d-b0f0-52d0f8abb324",
   "metadata": {},
   "source": [
    "# Key Components of LangChain\n",
    "- Chains\n",
    "- Agent\n",
    "- Memory\n",
    "- Tools\n",
    "\n",
    "### Chains\n",
    "Chains: a sequence of calls to components, which include other chains.\n",
    "\n",
    "Chains enables composing modular components into reusable pipelines.\n",
    "\n",
    "Eg. put together multiple LLM calls and other components in a swquence to create complex applicaitons.\n",
    "\n",
    "Prompt chaining: a technique that can be used to improve the performance of LangChain applicaitons, which involves chaining together multiple prompts to autocomplete a more complex response. More complex chains integrate models with tools like LLMMath, or SQLDatbaseChain. theese are called utility chains because they combine language models with specific tools.\n",
    "\n",
    "Benefits that Chains deliver\n",
    "- Modularity: Logic is divided into reusable components.\n",
    "- Composability: Components can be sequenced flexibly.\n",
    "- Readability: Each step in a pipeline is clear.\n",
    "- Maintainability: Steps can be added, removed and swapped.\n",
    "- Reusability: Common pilelines becomes configurable chains.\n",
    "- Tool integration: Easily incoporate LLMs, databases, APIs, etc.\n",
    "- Productivitiy: Quickly build prototypes of configurable chains.\n",
    "\n",
    "Chains are wrappers around multiple components - ranging from LLMs, APIs, libraries, databases, utility functions, etc.\n",
    "\n",
    "They are one of the core components of LangChain and enable you to really augment your LLM in a structed and easy way. You can craft your own chains or you can use the many existing ones. Chains are super important because they allow you to become a lot more creative with LLMs and solve increasing complex problems, through integrating various entities.\n",
    "\n",
    "These chains can be really simple such as having one LLM or they can be increasingly complex - combining multiple entities (also sometimes called utility chains).\n",
    "\n",
    "The ones related to RAG and conversational history are called\n",
    "- `ConversationChain`\n",
    "- `ConversationRetrievalChain`\n",
    "\n",
    "The conversation chain extends a simpler chain called an `LLMChain` which just receives a prompt and LLM and makes makes the call to the specified LLM and spits out the output.\n",
    "\n",
    "`ConversationChain` builds on this algorithm to load historical context into the prompt that is then passed into the LLMChain and queried.\n",
    "\n",
    "`ConversationalRetrievalChain` is for retrieving information from a datasource. It does 3 things\n",
    "1. It takes the chat history in and crafts an entirely new question based on history and new query.\n",
    "2. This question is passed into the retriever (ie., it becomes the query to the vector database)\n",
    "3. After getting the right documents, it passes the original question and fetched documents into the LLM jto get a response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e710529-96c6-401a-817e-8ff6a3cf1ce6",
   "metadata": {},
   "source": [
    "# Agents\n",
    "Agent is an application thati s powered by an LLM and interacts with differetn APIs, entities, libraries, chains, tools, etc.\n",
    "\n",
    "The LLM is the \"brain\" that makes the decisions on which chain and/or tools to execute, what to do with the output, and how to interpret various inputs/outputs and human interactions.\n",
    "\n",
    "Agent is an autonomous software entity that is capable of taking actions to accomplish goals and tasks.\n",
    "\n",
    "Both chains and agents is about the composiblity of LLMs and other components to work together.\n",
    "\n",
    "Difference between agents and chains\n",
    "- Agents do so by orchestrating chains while chains compose lower-level modules. While chains define reusable logic by sequencing components, agents leverage chains to take goal-driven actions.\n",
    "\n",
    "Action combine and orchestrate chains. Agents obeserves the environment, decides which chain to execute based on that observation, takes the chain's specified action and repeats.\n",
    "\n",
    "Agents decide which actions to take using LLMs as reasoning engines. The LLM is prompted with available tools, user input, and previous steps. It then selects the next action or final response.\n",
    "\n",
    "Tools are functions the agent calls to take real-world actions. Providing the right tools and effectively describing them is critical for action to accomplish goals.\n",
    "\n",
    "The agent executor runtime orchestrates the loop of querying the agent, executing tool actions, and feeding observations back. This handles lower-level complexities like error handling, logging, and parsing.\n",
    "\n",
    "Agents provide several key benefits:\n",
    "- Goal-oriented execution: Agents plan chains of logic targeting specific goals.\n",
    "- Dynamic responses: Observing environment changes lets agent react and adapt.\n",
    "- Statefulness: Agents can maintain memory and context across interactions.\n",
    "- Robustness: Errors can be handled by catching exceptions and trying alternative chains.\n",
    "- Composition: Agent logic combines reusable component chains.\n",
    "\n",
    "Together, this enables agent to handle complex, multi-step workflows and continuously interactive applications like chatbots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea155a6",
   "metadata": {},
   "source": [
    "Agent is a way of forcing the LLM to \"think\", that is a way of prompting the LLM to hink in a certain style. For example, a very simple way would gbe to jsut say \"think step by step\" after asking a question. \n",
    "\n",
    "LangChain provides a range of prebuilt algorityms for thinking:\n",
    "- `zero-shot-react-description`\n",
    "- `react-docstore`\n",
    "- `conversational-react-description`\n",
    "- `chat-zero-shot-react-description`\n",
    "- `chat-conversational-react-description`\n",
    "- `self-ask-with-search`\n",
    "\n",
    "## ReAct\n",
    "ReAct stands for reason and act.\n",
    "Paper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "262e9391-5d27-48fa-85df-f2135a9cad4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m37 packages\u001b[0m \u001b[2min 180ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m     0 B/38.17 KiB                     \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m 14.91 KiB/38.17 KiB                   \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m 30.91 KiB/38.17 KiB                   \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 33ms\u001b[0m\u001b[0m                                                   \u001b[1A\n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 0.43ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 4ms\u001b[0m\u001b[0m                                  \u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mkeyring\u001b[0m\u001b[2m==24.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mkeyring\u001b[0m\u001b[2m==25.6.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Installing Poetry\n",
    "!uv pip install poetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f73a320c-64c5-45f7-8962-f0d8a018ab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<your token>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8bc034b3-32f6-463d-8691-4056cdeac71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<your token>\n"
     ]
    }
   ],
   "source": [
    "!echo $OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "26b5d7fe-788a-4553-99f3-3a63509f2708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.py\n",
    "import os\n",
    "OPENAI_API_KEY = \"... \"\n",
    "\n",
    "# I'm omitting all other keys\n",
    "def set_environment():\n",
    "    variable_dict = globals().items()\n",
    "    for key, value in variable_dict:\n",
    "        if \"API\" in key or \"ID\" in key:\n",
    "             os.environ[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cc0c51c9-ffdb-44a4-9c6f-8c8939339c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    }
   ],
   "source": [
    "!echo $OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d80a6bd1-2cbf-4138-adb1-13451ed76888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable_dict = globals().items()\n",
    "# for key, value in variable_dict:\n",
    "#     if key:\n",
    "#         print(f'key: {key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5edb6d19-76d0-4559-a65e-76a9319ae6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "environment = os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88e7269-6ca4-488e-8b8b-dafacc4ab2c8",
   "metadata": {},
   "source": [
    "## Fake LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4fee7c2-89de-47c3-8de0-d2ee38f253dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m5 packages\u001b[0m \u001b[2min 5ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! uv pip install langchain-community langchain-core langchain-llm langchain-experimental langchain[docarray]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b29f472-7a4b-4316-aea3-8d719209ee1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1612885/2037961426.py:10: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n",
      "/tmp/ipykernel_1612885/2037961426.py:13: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  agent.run(\"whats 2 + 2\")\n",
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: Python_REPL\n",
      "Action Input: print(2 + 2)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m4\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: 4\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms.fake import FakeListLLM\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "tools = [PythonREPLTool()]\n",
    "responses = [\"Action: Python_REPL\\nAction Input: print(2 + 2)\", \"Final Answer: 4\"]\n",
    "llm = FakeListLLM(responses=responses)\n",
    "agent = initialize_agent(\n",
    " tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "agent.run(\"whats 2 + 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d4524f09-fd47-4f45-a860-732e09fd6334",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      8\u001b[39m     name: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mPython_REPL\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m     description: \u001b[38;5;28mstr\u001b[39m = (\n\u001b[32m     10\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA Python shell. Use this to execute python commands. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mInput should be a valid python command. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIf you want to see the output of a value, you should print it out \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     13\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwith `print(...)`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     14\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43md\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.tools.base import BaseTool\n",
    "from langchain.pydantic_v1 import BaseModel, Field, root_validator\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "class PythonREPLTool(BaseTool):\n",
    "    \"\"\"A tool for running python code in a REPL.\"\"\"\n",
    "\n",
    "    name: str = \"Python_REPL\"\n",
    "    description: str = (\n",
    "        \"A Python shell. Use this to execute python commands. \"\n",
    "        \"Input should be a valid python command. \"\n",
    "        \"If you want to see the output of a value, you should print it out \"\n",
    "        \"with `print(...)`.\"\n",
    "    )\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10d500d-0d11-428d-92ad-7b89aad3a4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2f06d-f4bb-4c96-b5c8-d5ca2cbeac3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo calculate 4 + 4, I will use Python's addition operator.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: print(4 + 4)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m8\n",
      "\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: 4 + 4 equals 8.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4 + 4 equals 8.'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "tools = [PythonREPLTool()]\n",
    "qwen_llm = OllamaLLM(temperature=0., model=\"qwen2.5-coder:14b\")\n",
    "\n",
    "agent = initialize_agent(\n",
    " tools, qwen_llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "agent.run(\"whats 4 + 4\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e12f03-88dd-4049-83c3-a64279b2c5b1",
   "metadata": {},
   "source": [
    "## Hugging Face\n",
    "Hugging Face provides Hugging Face Hub, a platform for hosting Git-based code repositories, machine learnning models, dtasets and web applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6536201f-5d11-4677-a046-9619bf8cff98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m61 packages\u001b[0m \u001b[2min 566ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 72ms\u001b[0m\u001b[0m                                              \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 15ms\u001b[0m\u001b[0m==3.4.1                         \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-huggingface\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msentence-transformers\u001b[0m\u001b[2m==3.4.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560b1cc0-1b3f-4a3f-a153-ea797b1c1279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f524823df81e46aabe46cca97be0ab21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "/home/yi/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In which country is Tokyo?\\n\\n# Answer\\nTokyo is the capital city of Japan. It is located on the eastern coast of the main island Honshu and is the political, economic, and cultural center of the country. Tokyo is known for its modernity, blending traditional Japanese culture with cutting-edge technology and fashion. It is also one of the most populous metropolitan areas in the world.'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\n",
    "        \"max_new_tokens\": 100,\n",
    "        \"top_k\": 50,\n",
    "        \"temperature\": 0.1,\n",
    "    },\n",
    ")\n",
    "llm.invoke(\"In which country is Tokyo?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653fd5c2-91e7-4fff-8146-529ea41fc2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import list_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eac9c82-2aff-41ab-9caf-d58f0ffe1bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-encoder/ms-marco-MiniLM-L-6-v2, 10485603\n",
      "\n",
      "distilbert/distilbert-base-uncased-finetuned-sst-2-english, 7730948\n",
      "\n",
      "papluca/xlm-roberta-base-language-detection, 4986307\n",
      "\n",
      "laurievb/OpenLID-v2, 4836437\n",
      "\n",
      "yiyanghkust/finbert-tone, 4324232\n",
      "\n",
      "facebook/bart-large-mnli, 3258391\n",
      "\n",
      "cardiffnlp/twitter-roberta-base-sentiment-latest, 2431001\n",
      "\n",
      "mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis, 2391929\n",
      "\n",
      "cardiffnlp/twitter-xlm-roberta-base-sentiment, 2060421\n",
      "\n",
      "cardiffnlp/twitter-roberta-base-sentiment, 2056152\n",
      "\n",
      "facebook/roberta-hate-speech-dynabench-r4-target, 1953988\n",
      "\n",
      "lxyuan/distilbert-base-multilingual-cased-sentiments-student, 1920043\n",
      "\n",
      "nlptown/bert-base-multilingual-uncased-sentiment, 1486629\n",
      "\n",
      "lucadiliello/BLEURT-20-D12, 1214117\n",
      "\n",
      "BAAI/bge-reranker-large, 1173427\n",
      "\n",
      "ProsusAI/finbert, 1131377\n",
      "\n",
      "cardiffnlp/twitter-roberta-base-emotion, 1110092\n",
      "\n",
      "pysentimiento/robertuito-sentiment-analysis, 1099897\n",
      "\n",
      "cross-encoder/ms-marco-TinyBERT-L-2-v2, 1052639\n",
      "\n",
      "cross-encoder/ms-marco-MiniLM-L-4-v2, 1040183\n",
      "\n",
      "mangoapps/fb_zeroshot_mnli_onnx, 995486\n",
      "\n",
      "BAAI/bge-reranker-v2-m3, 992853\n",
      "\n",
      "microsoft/deberta-large-mnli, 985217\n",
      "\n",
      "BAAI/bge-reranker-base, 942175\n",
      "\n",
      "GleghornLab/SYNTERACT, 924203\n",
      "\n",
      "cardiffnlp/twitter-xlm-roberta-base-sentiment-multilingual, 860989\n",
      "\n",
      "bunsenfeng/FactKB, 837576\n",
      "\n",
      "michellejieli/emotion_text_classifier, 808753\n",
      "\n",
      "cross-encoder/ms-marco-MiniLM-L-12-v2, 755954\n",
      "\n",
      "j-hartmann/emotion-english-distilroberta-base, 732801\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def list_most_popular(task: str):\n",
    "     for rank, model in enumerate(\n",
    "         list_models(filter=task, sort=\"downloads\", direction=-1)\n",
    "      ):\n",
    "         if rank == 30:\n",
    "             break\n",
    "         print(f\"{model.id}, {model.downloads}\\n\")\n",
    "list_most_popular(\"text-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b5bb75-c0b2-4315-9043-b7b1080e5f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.7691410779953003}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "customer_email = \"\"\"\n",
    "I am writing to pour my heart out about the recent unfortunate experience\n",
    "I had with one of your coffee machines that arrived broken. I anxiously\n",
    "unwrapped the box containing my highly anticipated coffee machine.\n",
    "However, what I discovered within broke not only my spirit but also any\n",
    "semblance of confidence I had placed in your brand.\n",
    "Its once elegant exterior was marred by the scars of travel, resembling a\n",
    "war-torn soldier who had fought valiantly on the fields of some espresso\n",
    "battlefield. This heartbreaking display of negligence shattered my dreams\n",
    "of indulging in daily coffee perfection, leaving me emotionally distraught\n",
    "and inconsolable\n",
    "\"\"\"\n",
    "sentiment_model = pipeline(\n",
    " task=\"sentiment-analysis\",\n",
    " model=\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    ")\n",
    "print(sentiment_model(customer_email))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb21a2d-cd31-4b4b-9059-e44b9bb40bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_2', 'score': 0.9900000691413879}]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_model(\"I am very super happy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d8e8ac-76e4-4f08-9ea5-f505cc2e433d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.9214368462562561}]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_model(\"Recently my cat has died\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47117ace-c100-4a27-8a15-b2f364fd8c8e",
   "metadata": {},
   "source": [
    "## Mitigating hallucinations throught fact-checking\n",
    "fact checking is verifying claims made by LLM's aggains evidence from external sources.\n",
    "\n",
    "Fact-checking 3 main stages:\n",
    "1. Claim detection: Identifying parts needing verification.\n",
    "2. Evidence retrieval: Find sources supporing or refuting the claim.\n",
    "3. Verdict prediction: Assess claim veracity based on evidence.\n",
    "\n",
    "LLMCheckerchain, is a chain for fact-checking, the model is prompted sequentially - first, to make the assumptions explicit, which looks like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec5dd2d-6292-436d-86b9-9b9e8f12b463",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMCheckerChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What type of mammal lays the biggest eggs?',\n",
       " 'result': \"Based on the information provided in the assertions, the mammal that lays the biggest eggs is the platypus. Despite being a relatively small animal, the egg laid by a platypus is larger in proportion to its body size compared to other mammals. However, it's important to note that while an ostrich egg is heavier and larger in absolute terms, it belongs to the bird kingdom, not the mammal kingdom.\"}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMCheckerChain\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.cache import InMemoryCache  # if available in your version\n",
    "\n",
    "qwen_model = OllamaLLM(model=\"qwen2.5-coder:14b\", temperature=\"0.7\")\n",
    "checker_chain = LLMCheckerChain.from_llm(qwen_model, verbose=True)\n",
    "checker_chain.model_rebuild()  # Finaliz\n",
    "\n",
    "text = \"What type of mammal lays the biggest eggs?\"\n",
    "checker_chain.invoke(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f71f38b-ca46-4791-8610-14e9675abaa9",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4b13b9-9d8f-41d7-9696-e17b5d98ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "prompt = \"\"\"\n",
    "Summarize this text in one sentence:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "qwen_model = OllamaLLM(model=\"qwen2.5-coder:14b\", temperature=\"0.7\")\n",
    "summary = qwen_model(prompt.format(text=text))\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064fa191-194d-4585-8d3f-b417c414cb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSummarize this text in one sentence:\\nWhat type of mammal lays the biggest eggs?\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7cda9d-12ba-4216-b619-895910ecbcf4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 7ms\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!uv pip install langchain_decorators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e5ffbf-3e49-4a4c-84b2-da411ac39b99",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mlangchain-decorators==0.6.1                                                   \u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m42 packages\u001b[0m \u001b[2min 383ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 939ms\u001b[0m\u001b[0m                                             \n",
      "\u001b[2mUninstalled \u001b[1m2 packages\u001b[0m \u001b[2min 49ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 19ms\u001b[0m\u001b[0m                                \u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mattrs\u001b[0m\u001b[2m==24.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mattrs\u001b[0m\u001b[2m==25.1.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.2.3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! uv pip install --upgrade langchain_decorators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d406e72-5a64-4fe5-a0cb-68c24c0750f1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "no validator found for <class 'langchain_core.messages.ai.AIMessage'>, see `arbitrary_types_allowed` in Config",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_decorators\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m llm_prompt\n\u001b[1;32m      3\u001b[0m \u001b[38;5;129m@llm_prompt\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msummarize\u001b[39m(text:\u001b[38;5;28mstr\u001b[39m, length\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshort\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m Summarize this text in {length} length:\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m {text}\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain_decorators/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogColors, GlobalSettings, print_log, PromptTypes, PromptTypeSettings, LlmSelector\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OutputWithFunctionCall\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompt_decorator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PromptDecoratorTemplate\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain_decorators/common.py:16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseMessage\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatMessagePromptTemplate\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OutputWithFunctionCall\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping_inspect\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_generic_type, is_union_type\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydantic\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain_decorators/schema.py:18\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, PrivateAttr\n\u001b[1;32m     16\u001b[0m T \u001b[38;5;241m=\u001b[39m TypeVar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;21;43;01mOutputWithFunctionCall\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mGeneric\u001b[49m\u001b[43m[\u001b[49m\u001b[43mT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mBaseModel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_text\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_message\u001b[49m\u001b[43m:\u001b[49m\u001b[43mAIMessage\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/pydantic/v1/main.py:197\u001b[0m, in \u001b[0;36mModelMetaclass.__new__\u001b[0;34m(mcs, name, bases, namespace, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    190\u001b[0m         is_untouched(value)\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m ann_type \u001b[38;5;241m!=\u001b[39m PyObject\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m         )\n\u001b[1;32m    195\u001b[0m     ):\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m     fields[ann_name] \u001b[38;5;241m=\u001b[39m \u001b[43mModelField\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mann_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mannotation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mann_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_validators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_validators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mann_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ann_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m namespace \u001b[38;5;129;01mand\u001b[39;00m config\u001b[38;5;241m.\u001b[39munderscore_attrs_are_private:\n\u001b[1;32m    205\u001b[0m     private_attributes[ann_name] \u001b[38;5;241m=\u001b[39m PrivateAttr()\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/pydantic/v1/fields.py:504\u001b[0m, in \u001b[0;36mModelField.infer\u001b[0;34m(cls, name, value, annotation, class_validators, config)\u001b[0m\n\u001b[1;32m    501\u001b[0m     required \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    502\u001b[0m annotation \u001b[38;5;241m=\u001b[39m get_annotation_from_field_info(annotation, field_info, name, config\u001b[38;5;241m.\u001b[39mvalidate_assignment)\n\u001b[0;32m--> 504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtype_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mannotation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43malias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_validators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_validators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequired\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequired\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfield_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/pydantic/v1/fields.py:434\u001b[0m, in \u001b[0;36mModelField.__init__\u001b[0;34m(self, name, type_, class_validators, model_config, default, default_factory, required, final, alias, field_info)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m SHAPE_SINGLETON\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mprepare_field(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 434\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/pydantic/v1/fields.py:555\u001b[0m, in \u001b[0;36mModelField.prepare\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault \u001b[38;5;129;01mis\u001b[39;00m Undefined \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 555\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopulate_validators\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/pydantic/v1/fields.py:829\u001b[0m, in \u001b[0;36mModelField.populate_validators\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msub_fields \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m SHAPE_GENERIC:\n\u001b[1;32m    826\u001b[0m     get_validators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__get_validators__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    827\u001b[0m     v_funcs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    828\u001b[0m         \u001b[38;5;241m*\u001b[39m[v\u001b[38;5;241m.\u001b[39mfunc \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m class_validators_ \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39meach_item \u001b[38;5;129;01mand\u001b[39;00m v\u001b[38;5;241m.\u001b[39mpre],\n\u001b[0;32m--> 829\u001b[0m         \u001b[38;5;241m*\u001b[39m(get_validators() \u001b[38;5;28;01mif\u001b[39;00m get_validators \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfind_validators\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m),\n\u001b[1;32m    830\u001b[0m         \u001b[38;5;241m*\u001b[39m[v\u001b[38;5;241m.\u001b[39mfunc \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m class_validators_ \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39meach_item \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mpre],\n\u001b[1;32m    831\u001b[0m     )\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidators \u001b[38;5;241m=\u001b[39m prep_validators(v_funcs)\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_validators \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/pydantic/v1/validators.py:768\u001b[0m, in \u001b[0;36mfind_validators\u001b[0;34m(type_, config)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(type_, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__pydantic_core_schema__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    767\u001b[0m     warn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMixing V1 and V2 models is not supported. `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` is a V2 model.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;167;01mUserWarning\u001b[39;00m)\n\u001b[0;32m--> 768\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno validator found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, see `arbitrary_types_allowed` in Config\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: no validator found for <class 'langchain_core.messages.ai.AIMessage'>, see `arbitrary_types_allowed` in Config"
     ]
    }
   ],
   "source": [
    "from langchain_decorators import llm_prompt\n",
    "\n",
    "@llm_prompt\n",
    "def summarize(text:str, length=\"short\") -> str:\n",
    " \"\"\"\n",
    " Summarize this text in {length} length:\n",
    " {text}\n",
    " \"\"\"\n",
    " return\n",
    "summary = summarize(text=\"let me tell you a boring story from when I was young...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df36770e-9954-42e2-8b2b-eca297b19fdd",
   "metadata": {},
   "source": [
    "## Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53651f8-2470-44a8-83fa-aad8e37c7056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.schema import StrOutputParser\n",
    "llm = OllamaLLM(model=\"qwen2.5-coder:14b\")\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Summarize tis text: {text}?\"\n",
    ")\n",
    "runnable = prompt | llm | StrOutputParser()\n",
    "summary = runnable.invoke({\"text\": text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af28bead-39f5-476b-85bc-0d8702378d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='Summarize tis text: {text}?')\n",
       "| OllamaLLM(model='qwen2.5-coder:14b')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcdf559-0609-4db0-a469-fe4d43c0427c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The mammal that lays the biggest eggs is the platypus. Platypuses are monotremes, which means they lay eggs instead of giving birth to live young. The average size of a platypus egg is about 1.5 centimeters in length and weighs around 0.2 grams. This makes them the largest eggs laid by any mammal.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576cd808-36d0-4cb3-95aa-f3ffb4bdb897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The type of mammal that lays the largest eggs is the platypus. While it is not commonly known, the platypus is an egg-laying mammal, scientifically classified as monotremes along with the echidnas. Platypus eggs are about 2 cm in length and weigh around 0.1 grams. Although they are relatively small by human standards, compared to other mammals, platypus eggs are indeed some of the largest laid by any mammal.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d83ec6d-450b-43c8-872c-8b29ba4cb40e",
   "metadata": {},
   "source": [
    "## Chain of density\n",
    "Chain of density, a prompt-guided techniques to incrementallly increase the information density of GPT-4 gnerated summaries while controlling length.\n",
    "\n",
    "This is the prompt to sue with CoD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99f1266-e440-4563-a6cf-9fe568c1f860",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Article: { text }\n",
    "You will generate incressingly concise, entity-dense summaries of the \n",
    "above article.\n",
    "Repeat the following 2 steps 5 times.\n",
    "Step 1. Identify 1-3 information entities (\";\" delimited) from the \n",
    "article which are missing from the previously generated summary.\n",
    "Step 2. Write a new, denser summary of indentical length which covers \n",
    "every entity and detail from the previous summary plus the missing \n",
    "entities.\n",
    "A missing entity is:\n",
    "- relevant to the main story,\n",
    "- specific yet concise (5 words or fewer),\n",
    "- novel (not in the previous summary),\n",
    "- faithful (present in the article),\n",
    "- anywhere (can be located anywhere in the article).\n",
    "Guideline:\n",
    "- The first summary should be long (4-5 sentences, ~80 workds) yet highly\n",
    "non-specific, containing little information beyond the entities marked as missing.\n",
    "Use overly verbose language and fillers (e.g., \"this article discussses\") to reach ~80 words.\n",
    "- Make every word count: rewrite the previous summary to improve flow and make space\n",
    "for additional entities.\n",
    "- Make space with fusion, compression, and removal of uninformative phrases\n",
    "like \"the article discusses\".\n",
    "- The summaries should become highly dense and concise yet self-contained, i.e.,\n",
    "easily understood without the article.\n",
    "- Missing entities can appear anywhere in the new summary.\n",
    "- Never drop entities from the previous summary. If space cannot be made, add fewer new entities.\n",
    "Remember, use the exact same number of words for each summary.\n",
    "Answer in JSON. The JSON should be a list (length 5) of dictionaries whose\n",
    "keys are \"Missing_Entities\" and \"Denser_Summary\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82be9060-603e-4020-ac5b-5b8244b70e53",
   "metadata": {},
   "source": [
    "# Map-Reduce pipelines\n",
    "Key steps\n",
    "1. Map: Each document is passed through a summarization chain (LLM chain)\n",
    "2. Collapse (optional): The summarize documents are combined into a single document.\n",
    "3. Reduce: The collapse document goes through a final LLM chain to produce the output.\n",
    "\n",
    "The map step applies a chain to each document in parallel. the reduce step aggregates the mapped output and gneerates the final result.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038c859-cd2d-4df1-8d4a-d647098b8ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 7ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! uv pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e34a5a-df3b-477d-861a-b72cc848c27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "# pdf_file_path = \"<pdf_file_path>\"\n",
    "# pdf_loader = PyPDFLoader(pdf_file_path)\n",
    "# docs = pdf_loader.load_and_split()\n",
    "# llm = OllamaLLM(model=\"qwen2.5-coder:14b\")\n",
    "# chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "# chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb3ff83-f6ae-4233-ac67-18eb05cad9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 226ms\u001b[0m\u001b[0m                                          \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 61ms\u001b[0m\u001b[0m                                               \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 11ms\u001b[0m\u001b[0m                                 \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpypdf\u001b[0m\u001b[2m==5.3.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! uv pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb482fde-d042-4b8e-9b92-aa473bee0e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file_path = \"openresume-resume.pdf\"\n",
    "pdf_loader = PyPDFLoader(pdf_file_path)\n",
    "docs = pdf_loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0a320e-5f76-4260-8d08-e6fd3a95095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model=\"qwen2.5-coder:14b\")\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "response = chain.invoke(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456632d4-65d0-48a1-811d-536ba533a55d",
   "metadata": {},
   "source": [
    "### Monitor token usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546706f2-7805-4932-873e-e7a9c26a10b1",
   "metadata": {},
   "source": [
    "Can't get tokens from openai callback using ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b155017d-3b0f-4ed5-b374-1a481b582532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 0\n",
      "Prompt Tokens: 0\n",
      "Completion Tokens: 0\n",
      "Total Cost (USD): $0.0\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "with get_openai_callback() as cb:\n",
    "    response = chain.invoke(docs) \n",
    "    # print(response)\n",
    "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Total Cost (USD): ${cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723462eb-f88c-4f61-9e0b-43b966a4ab25",
   "metadata": {},
   "source": [
    "### Extracting information from documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f21cee-46b4-4ab0-b8df-e3f401a547cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "import os\n",
    "\n",
    "# Define your Pydantic models\n",
    "class Experience(BaseModel):\n",
    "    start_date: Optional[str]\n",
    "    end_date: Optional[str]\n",
    "    description: Optional[str]\n",
    "\n",
    "class Study(Experience):\n",
    "    degree: Optional[str]\n",
    "    university: Optional[str]\n",
    "    country: Optional[str]\n",
    "    grade: Optional[str]\n",
    "\n",
    "class WorkExperience(Experience):\n",
    "    company: str\n",
    "    job_title: str\n",
    "\n",
    "class Resume(BaseModel):\n",
    "    first_name: str\n",
    "    last_name: str\n",
    "    linkedin_url: Optional[str]\n",
    "    nationality: Optional[str]\n",
    "    skill: Optional[str]\n",
    "    study: Optional[Study]\n",
    "    work_experience: Optional[WorkExperience]\n",
    "    hobby: Optional[str]\n",
    "\n",
    "# Load and split your PDF document\n",
    "pdf_file_path = os.path.expanduser(\"openresume-resume.pdf\")\n",
    "pdf_loader = PyPDFLoader(pdf_file_path)\n",
    "docs = pdf_loader.load_and_split()\n",
    "\n",
    "# Initialize the output parser\n",
    "parser = PydanticOutputParser(pydantic_object=Resume)\n",
    "\n",
    "# Create the prompt template\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Extract the following information from the provided document:\\n{format_instructions}\\n\\nDocument:\\n{document}\",\n",
    "    input_variables=[\"document\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# Initialize the ChatOllama model\n",
    "llm = ChatOllama(model=\"qwen2.5-coder:14b\", format=\"json\", temperature=0)\n",
    "\n",
    "# Create the LLMChain\n",
    "# chain = LLMChain(llm=llm, prompt=prompt)\n",
    "chain = prompt | llm | SimpleJsonOutputParser()  \n",
    "\n",
    "summary = chain.invoke({\"document\": doc})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96215dd8-1977-455b-b9b0-389690b4a26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_name': 'John',\n",
       " 'last_name': 'Doe',\n",
       " 'linkedin_url': 'linkedin.com/in/john-doe',\n",
       " 'nationality': None,\n",
       " 'skill': 'HTML, TypeScript, CSS, React, Python, C++',\n",
       " 'study': {'start_date': 'Sep 2019',\n",
       "  'end_date': 'May 2023',\n",
       "  'description': 'Won 1st place in 2022 Education Hackathon, 2nd place in 2023 Health Tech Competition\\nTeaching Assistant for Programming for the Web (2022 - 2023)\\nCoursework: Object-Oriented Programming (A+), Programming for the Web (A+), Cloud Computing (A), Introduction to Machine Learning (A-), Algorithms Analysis (A-)',\n",
       "  'degree': 'Bachelor of Science in Computer Science',\n",
       "  'university': 'XYZ University',\n",
       "  'country': None,\n",
       "  'grade': '3.8 GPA'},\n",
       " 'work_experience': {'start_date': 'May 2023',\n",
       "  'end_date': 'Present',\n",
       "  'description': 'Lead a cross-functional team of 5 engineers in developing a search bar, which enables thousands of daily active users to search content across the entire platform\\nCreate stunning home page product demo animations that drives up sign up rate by 20%\\nWrite clean code that is modular and easy to maintain while ensuring 100% test coverage',\n",
       "  'company': 'ABC Company',\n",
       "  'job_title': 'Software Engineer'},\n",
       " 'hobby': None}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b40e9d5-2165-4f67-8cbc-cebbc460e604",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e9d97a-c923-4124-825a-37e1c58db3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_agent() -> AgentExecutor:\n",
    "    llm = ChatOllama(model=\"qwen2.5-coder:14b\", temperature=0, streaming=True)\n",
    "    # DuckDuckGoSearchRun, folfram alpha, arxiv search, wikipedia\n",
    "    # Todo: try wolfram-alpha!\n",
    "    tools = load_tools(\n",
    "        tool_names=[\"ddg-search\", \"arxiv\", \"wikipedia\"],\n",
    "        llm=llm\n",
    "    )\n",
    "\n",
    "    return initialize_agent(\n",
    "        tools=tools, llm=llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019ed326-b720-4dd1-bf38-f199a7a4269f",
   "metadata": {},
   "source": [
    "AgentExecutor, is a chain. The Zero-Shot agent is a general-purpose action agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ab5536-ceda-41f9-9a1b-830f6a411d6c",
   "metadata": {},
   "source": [
    "## Building a visual interface with streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e6f369-6781-4449-a258-71bf04c0f18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m60 packages\u001b[0m \u001b[2min 282ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 270ms\u001b[0m\u001b[0m                                              \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 0.24ms\u001b[0m\u001b[0m                               \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwikipedia\u001b[0m\u001b[2m==1.4.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! uv pip install streamlit duckduckgo-search wolframalpha arxiv wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac005613-a8c5-43a6-a2cb-f998ed2e8ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-14 23:33:13.476 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-14 23:33:13.483 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-14 23:33:13.485 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-14 23:33:13.485 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-14 23:33:13.486 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-14 23:33:13.486 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-14 23:33:13.530 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/yi/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-02-14 23:33:13.531 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from langchain.callbacks import StreamlitCallbackHandler\n",
    "\n",
    "chain = load_agent()\n",
    "st_callback = StreamlitCallbackHandler(st.container())\n",
    "\n",
    "if prompt := st.chat_input():\n",
    "    st.chat_message(\"user\").write(prompt)\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        st_callback = StreamlitCallbackHandler(st.container())\n",
    "        response = chain.run(prompt, callback=[st_callback])\n",
    "        st.write(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6411ecb5-5040-4ea2-aa90-59ee6472253d",
   "metadata": {},
   "source": [
    "## Reasoning Strategies\n",
    "\n",
    "Hybrid systems that combine neural pattern completion with deliberate symbolic manipulation can master skills including these:\n",
    "- Multi-step deductive reasoning to draw conclusions from a chain of facts\n",
    "- Mathematical reasoning like solving equations throught a series of transformations\n",
    "- Planning tactics to break down a problem into an optimized sequence of actions\n",
    "\n",
    "By integrating tools togethter with explicit reasoning steps instead of pure pattern completion, our agent can tackle problems requiring abstractio nand imagination, and can arrive at a complex understanding of the world enabling them to hold more meaningful conversations abut complex concepts.\n",
    "\n",
    "The tools are the available resources thatthe aggent can use, such as search engines or databases. The LLMChain is responsible for generating text prompts and parsing the output to determine the next action. The agent class uses the output of the LLMChain to decide which action to take.\n",
    "\n",
    "While tool-augmented language models combine LLMs with external resources like search engines and databases to enhance reasoning capabilities, this can be further enhanced with agents.\n",
    "\n",
    "In LangChain, this consists of 3 parts:\n",
    "- Tools\n",
    "- An LLMChain\n",
    "- The agent itself\n",
    "\n",
    "Thre are 2 key agent architectures:\n",
    "- Action agents reason iteratively based on observations after each action.\n",
    "- Plan-and-execute agents plan completely upfront before taking any action.\n",
    "\n",
    "In observation-dependent reasoning, the agent iteratively providees context and exampels to an LLM to generate thoughts and actions. Observations from tools are incorporated to inform the next reasoning step. this approach is used in action agents.\n",
    "\n",
    "An alternative is plan-and-execute agents that first create a complete plan and then gather evidence to execute it. The Planner LLM produces a list of plans (P). The agent gathers evidence (E) using tools. P and E are combined and fed to the Solver LLM to generate the final output.\n",
    "\n",
    "Plan-and-execute separates planning from execution. Smaller specialized models can be used for the Planner and solver roles. The trade-off is that plan-and-execute requires more upfront planning.\n",
    "\n",
    "Observation-dependent reasoning involves making judgments, predictions, or choices based on the current state of knowledge or the evidence fetched through observation. In each iteration, the agent provides context and examples to the LLM. A user's task is first combined with the context and examples and given to the LLM to initiate reasoning. The LLM generates a though and an action and then waits for an observation from tools. The observation is added to the prompt to initiate the next call to the LLM. In LangChain, this is an action agent (also ZERO_SHOT_REACT_DESCRIPTION), which is the default setting when you create an agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb4cac7-2431-4a9e-8bfb-328e7aee32dc",
   "metadata": {},
   "source": [
    "### Planning\n",
    "The strategy of making plans ahead of any actions is called the \"plan-and-execute\" agent).\n",
    "\n",
    "Thye Planner (an LLM), which can be fine-tuned for planning and tool usage, produces a list of plans (P) and calls a worker (in LangChain, the agent) to gater evidence (E) by using tools. P and E are combined with the task and then fed into the Solver (an LLM) for the final anser. we can write a pseudo algorithmn like this:\n",
    "1. Plan out all the steps (Planner).\n",
    "2. for each step, determine the proper tools to accomplish the step and execute.\n",
    "\n",
    "The Planner and the Solver can be distinct language models. This opens the possibility of using smaller, specialized models for Planner and Solver, and using fewer tokens for each of the calls.\n",
    "\n",
    "First add the strategy variable to the `load_agent()` function. It can take 2 values, either `plan-and-solve` or `zero-shot-react`. For `zero-shot-react`, the logic stays the same. For `plan-and-solve`, we'll define a planner and an executor, which we'll use to create a `PlanAndExecute` agent executor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c4b8d6-ed07-4bd3-aed9-021df32522cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain.agents import initialize_agent, load_tools, AgentType\n",
    "from langchain.chains.base import Chain\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_experimental.plan_and_execute import (\n",
    "    load_chat_planner, load_agent_executor, PlanAndExecute\n",
    ")\n",
    "import streamlit as st\n",
    "\n",
    "ReasoningStrategies = Literal[\"zero-shot-react\", \"plan-and-solve\"]\n",
    "\n",
    "def load_agent(\n",
    "    tool_names: list[str],\n",
    "    strategy: ReasoningStrategies = \"zero-shot-react\"\n",
    "\n",
    ") -> Chain:\n",
    "    llm = ChatOllama(model=\"qwen2.5-coder:14b\", temperature=0, streaming=True)\n",
    "    tools = load_tools(\n",
    "        tool_names=tool_names,\n",
    "        llm=llm\n",
    "    )\n",
    "    if strategy == \"plan-and-solve\":\n",
    "        planner = load_chat_planner(llm)\n",
    "        executor = load_agent_executor(llm, tools, verbose=True)\n",
    "        return PlanAndExecute(planner=planner, executor=executor, verbose=True)\n",
    "\n",
    "    return initialize_agent(\n",
    "        tools=tools, llm=llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96526de0-5e19-4a41-a6b6-f2917abff11c",
   "metadata": {},
   "source": [
    "Let's define a new variable that's set through a radio button in Streamlit. We'll pass tyhis variable over the `load_agent()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bee041-3fdc-4846-b7b1-54f663672ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-15 14:08:00.214 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-15 14:08:00.217 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-15 14:08:00.219 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-15 14:08:00.220 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-15 14:08:00.221 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n",
      "2025-02-15 14:08:00.222 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-15 14:08:00.249 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/yi/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-02-15 14:08:00.249 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "strategy = st.radio(\n",
    "    \"Reasoning strategy\",\n",
    "    (\"plan-and-solve\", \"zero-shot-react\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3f91bc-8454-4b73-88b3-5efbdc41086d",
   "metadata": {},
   "source": [
    "You might have noticed that the `load_agent()` method takes a list of strings, `tool_names`. This can be chosen in the user interface (UI) as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595e4157-b3bf-468a-93fc-44699b7f5ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-15 15:37:03.314 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-15 15:37:03.317 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-15 15:37:03.319 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-15 15:37:03.320 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-15 15:37:03.320 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "tool_names = st.multiselect(\n",
    "    'Which tools do you want to use?',\n",
    "    [\n",
    "        \"google-search\", \"ddg-search\", \"arxiv\",\n",
    "        \"wikipedia\", \"python_repl\", \"pal_math\", \"llm-math\"\n",
    "    ],\n",
    "    [\"ddg-search\", \"wikipedia\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0188d1df-4326-4b90-99df-c2c70e5a5755",
   "metadata": {},
   "source": [
    "Finally, still the app, the agent is loaded like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f98aed-211b-4d8e-9767-2a865426a436",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain = load_agent(tool_names=tool_names, strategy=strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1fb962-dea5-4570-b79e-128835db7401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, Tool, create_self_ask_with_search_agent\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
    "from langchain_community.tools.ddg_search import DuckDuckGoSearchRun\n",
    "from langchain_community.tools.google_search import GoogleSearchRun\n",
    "from langchain_community.tools.wikipedia.tool import WikipediaQueryRun\n",
    "from langchain_community.tools.wolfram_alpha import WolframAlphaQueryRun\n",
    "from langchain_community.utilities.arxiv import ArxivAPIWrapper\n",
    "from langchain_community.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper\n",
    "from langchain_community.utilities.google_search import GoogleSearchAPIWrapper\n",
    "from langchain_community.utilities.wikipedia import WikipediaAPIWrapper\n",
    "from langchain_community.utilities.wolfram_alpha import WolframAlphaAPIWrapper\n",
    "from langchain_core.language_models import BaseLanguageModel\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_experimental.tools import PythonREPLTool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5e7b9b-9af5-4f81-a90c-407b52e06a64",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Chain' from 'langchain.chains' (/home/yi/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain/chains/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chain\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Chain' from 'langchain.chains' (/home/yi/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain/chains/__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain.chains import Chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca14cd6-fa22-444e-b18e-9fd6da236102",
   "metadata": {},
   "source": [
    "# Embeddding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6110728d-f69b-4285-ba19-3e49c3b56590",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8044437170028687, 0.914264440536499, -4.007643699645996, -1.1118558645248413, 0.896572470664978, -0.7128822803497314, 0.4467930197715759, 0.25961872935295105, 0.514275848865509, -0.07405504584312439, 0.4172780513763428, 0.7774555683135986, 0.6251865029335022, -0.22206376492977142, -1.510133981704712, -0.6109319925308228, -0.13520467281341553, -2.364330768585205, 0.7819806933403015, 1.0423827171325684, -0.8954195976257324, -0.6870061159133911, -1.1416879892349243, -0.7331091165542603, 2.818359613418579, -0.49423250555992126, -0.8752056956291199, 0.34464550018310547, -1.2165148258209229, -0.13152295351028442, 0.011937551200389862, 0.008786272257566452, 0.38013291358947754, -0.34124353528022766, -1.4954615831375122, -1.4013972282409668, 0.06516040861606598, 0.3660874366760254, 0.4461685121059418, 0.12468599528074265, 1.058765172958374, 0.19058313965797424, 0.3387684226036072, -0.6107196807861328, 1.0274360179901123, -0.1766473948955536, 1.2721312046051025, 0.01457289606332779, 0.468231737613678, -0.3646760582923889, 0.25328612327575684, -0.38508033752441406, -0.034075889736413956, -0.2625436782836914, 1.6218408346176147, -0.3954959511756897, 0.8835822939872742, 0.786931574344635, -0.41004133224487305, -0.0717080608010292, 0.6167240142822266, 0.6280854344367981, -1.1026015281677246, 1.7120983600616455, -0.0492042601108551, 0.04554732143878937, -1.0489130020141602, 0.6597670316696167, -0.1412431299686432, -0.0037580616772174835, 0.21188677847385406, 0.31927934288978577, 0.6532340049743652, 0.12999697029590607, -0.5469524264335632, -0.9763076305389404, -0.43240195512771606, -0.5472317934036255, 0.05899326130747795, 0.7569355368614197, 0.7365849018096924, -0.2666846215724945, -0.142245814204216, 0.5043704509735107, 1.852942705154419, 0.30336490273475647, -0.513504683971405, -1.003780484199524, -0.07406271994113922, 0.39938753843307495, 1.0190588235855103, 0.9369532465934753, 1.3362271785736084, 0.9628337621688843, -0.17943760752677917, 0.4920896291732788, -0.12790052592754364, -0.11360777914524078, 0.3676949441432953, -0.6176630258560181, -0.718382716178894, 0.08532889932394028, -0.512789249420166, -0.163164421916008, 1.2950767278671265, 1.2518855333328247, -0.5970855355262756, 0.7189294099807739, -0.9984252452850342, -0.4626355767250061, -0.8104238510131836, 1.4123730659484863, -0.5368174314498901, 0.31124377250671387, -0.5507797598838806, 0.31449592113494873, 1.41633141040802, 0.12391753494739532, -0.3131893277168274, 0.8194953799247742, -0.41285058856010437, 0.9113914966583252, -0.4771904945373535, 2.005005359649658, -0.7039973735809326, 1.1389180421829224, -1.3721855878829956, 1.3454957008361816, 0.07116085290908813, -0.25826072692871094, -0.7875304222106934, -0.5297619104385376, -0.5102025270462036, -0.3415515720844269, 1.022637963294983, 0.11160090565681458, -0.09578373283147812, -0.29198503494262695, -0.5340188145637512, 0.3388572335243225, 0.183818519115448, 0.6096537113189697, 0.16049988567829132, 0.5427781343460083, -0.26044467091560364, -0.34140703082084656, 1.080935001373291, 0.23882436752319336, -0.6395606994628906, 0.19202300906181335, -0.47973892092704773, 0.4902794361114502, 0.9816949367523193, 0.14281947910785675, 0.1707281768321991, -0.9725269675254822, -0.03736187517642975, 0.18149103224277496, 0.1562289446592331, 0.4593706727027893, 1.5237706899642944, -0.2460366189479828, -1.0950273275375366, 1.2935333251953125, 0.2864754796028137, -1.4393548965454102, -0.16526487469673157, 1.5597236156463623, 0.7117866277694702, 0.9605814218521118, -0.7201734185218811, -1.5715501308441162, -1.1289993524551392, -0.5713915824890137, 0.32543259859085083, -1.2109376192092896, 1.5635037422180176, -0.9105020761489868, 1.3143813610076904, -0.690172553062439, 1.4425814151763916, -0.8971078395843506, 0.6747006773948669, -0.2607221305370331, 0.4103473424911499, -0.22611814737319946, -0.18671879172325134, 0.22478635609149933, 0.2634037733078003, -0.5630409717559814, -0.9242621660232544, -0.4638790488243103, -1.5689945220947266, -0.950800895690918, -1.1435754299163818, -0.4851548671722412, 1.4297902584075928, 0.11645187437534332, -0.23357319831848145, -0.01095234602689743, 0.08553431183099747, -0.2917191982269287, -1.3155730962753296, 0.6947311758995056, -0.870396614074707, 1.1639409065246582, 0.02675742842257023, -0.00757400318980217, -0.06582240760326385, 0.7310864925384521, 1.6883107423782349, -0.2152671068906784, -0.2575601041316986, 0.2289905846118927, -0.3452957570552826, -0.383836567401886, 0.37028807401657104, -0.3511035144329071, 0.30727526545524597, 0.9167230129241943, 0.16529880464076996, -0.08870425820350647, -0.07466022670269012, -0.22717313468456268, 1.2716755867004395, -0.3626006841659546, -0.72105473279953, -0.27062472701072693, -0.8028567433357239, 0.41013363003730774, -0.5425398349761963, -2.0842463970184326, 0.4041130542755127, -0.34933018684387207, 0.3199901282787323, 0.029382653534412384, -0.38217610120773315, 1.6072299480438232, -0.2139957696199417, -0.637221097946167, -0.18173830211162567, 0.1673598438501358, -0.18535053730010986, 0.10515467822551727, -0.744253396987915, 0.4610694944858551, 0.20036108791828156, -0.3284285068511963, 1.7458646297454834, -0.5771574974060059, 0.3509202003479004, -0.008606445044279099, 0.31601208448410034, 0.1548401117324829, 0.6219085454940796, -2.1394405364990234, 0.15845006704330444, 0.07197026163339615, 0.25262656807899475, 0.06579053401947021, 0.0445045605301857, -1.5967918634414673, 1.8780783414840698, -1.1272008419036865, -1.4500362873077393, -0.8423309922218323, -0.5889037251472473, 0.10737437009811401, -0.07164796441793442, -0.1722888946533203, 0.22112224996089935, -0.08096855878829956, 0.09016288816928864, -0.015506371855735779, 0.10452095419168472, 0.1783527135848999, 0.02364836260676384, 0.5742096304893494, -0.3019937574863434, 0.2933950424194336, -0.3305946886539459, -0.49256622791290283, -0.059250205755233765, 0.8852847814559937, 0.15039357542991638, 1.7080079317092896, 0.5615624785423279, -0.4722549617290497, 0.06665326654911041, -0.053205665200948715, 0.46467503905296326, -0.4685993790626526, 0.9537866115570068, 0.7504734992980957, -0.8837864398956299, 0.44542402029037476, 1.8851397037506104, -0.5816881060600281, 0.6869587302207947, -0.10550442337989807, -0.6511985063552856, 0.8737318515777588, 2.2194552421569824, 1.2419313192367554, 0.21116036176681519, -0.3628416359424591, 1.440630316734314, -1.3291226625442505, 1.0883355140686035, -0.04502640292048454, -0.9480500221252441, -0.906582772731781, -0.7449914813041687, 0.939568042755127, -0.5612624287605286, 0.4725874662399292, -0.07543990761041641, 0.38291752338409424, 1.0286462306976318, -0.07602817565202713, 0.3971967101097107, -1.1995474100112915, -0.1210896372795105, -0.8076462149620056, 0.12150028347969055, 1.1633524894714355, -1.0278759002685547, 1.177788496017456, 0.06634192913770676, -1.2192283868789673, 0.1740211546421051, 0.5201773643493652, -0.8111301064491272, -1.288145899772644, -0.27786847949028015, 0.6161328554153442, 0.8101293444633484, 0.007606773171573877, 0.035237520933151245, 1.3804470300674438, 0.8519508838653564, -1.0262749195098877, 0.17429286241531372, -1.095607876777649, 0.2541939914226532, 0.007228606380522251, -1.442422866821289, -0.4704830050468445, 0.22845083475112915, 0.12824192643165588, -0.8381829261779785, -0.19229429960250854, -0.17392075061798096, -0.4106745421886444, -0.09530826658010483, 0.9916165471076965, 1.749085783958435, -0.20967581868171692, 0.5671603679656982, 0.21464723348617554, 1.4567283391952515, -0.9175335764884949, 0.8255200386047363, -1.2971831560134888, 0.5479162931442261, 0.9204725027084351, 0.603603720664978, 0.8515881299972534, 1.1539498567581177, 0.20463557541370392, -0.9595168828964233, -0.6182208061218262, 0.47038084268569946, 0.8802950382232666, 1.2574964761734009, 0.25806090235710144, -1.7487750053405762, 0.3909752666950226, 0.1275852918624878, 0.1595713496208191, 1.3253744840621948, 0.2859867215156555, -0.021600738167762756, -0.11634626984596252, 0.1914636641740799, -0.19843390583992004, -1.2265040874481201, 0.5082444548606873, -1.0700277090072632, -0.48363667726516724, 0.04220283031463623, -0.2783801555633545, -1.2666594982147217, 0.5552852749824524, -1.0010043382644653, -0.7412916421890259, -0.00696071982383728, -0.41582563519477844, -0.1663159877061844, 0.9998428821563721, -0.18952274322509766, -0.855100154876709, 0.43295201659202576, -0.22480016946792603, 0.24677151441574097, 0.7880158424377441, 0.1878882199525833, -1.427490472793579, 0.6650503873825073, -0.2278839647769928, 0.6151002645492554, -0.054425887763500214, -0.6759178042411804, -0.589756965637207, 0.43854469060897827, 0.30054864287376404, 0.9150928854942322, 0.4147998094558716, -0.04440080001950264, -0.4580157995223999, 0.22061532735824585, 0.41980263590812683, 0.26662352681159973, 0.4565787613391876, 0.5112394094467163, 0.05719628185033798, -0.3491061329841614, 1.5927963256835938, 0.34465542435646057, -1.2306889295578003, -0.2372240275144577, 1.203948736190796, 0.5743578672409058, -0.07707618921995163, 0.26614508032798767, 0.5174498558044434, 0.08720869570970535, -0.40794065594673157, -0.08094697445631027, 0.5723485350608826, 0.15519119799137115, -0.19262124598026276, -0.5193743109703064, 0.15939033031463623, -0.20561040937900543, 2.5811452865600586, 0.9577866196632385, -0.3562552034854889, -0.6102741956710815, 0.8176755309104919, 0.2999020516872406, 0.6822009086608887, -0.64531409740448, 0.07283516228199005, 1.8610464334487915, -1.1735154390335083, 1.1155844926834106, -0.846867561340332, 0.4257456064224243, 1.3773072957992554, 1.0212963819503784, 0.06295029819011688, -0.5410007834434509, 0.4713560938835144, 0.2380068153142929, -1.685140609741211, -0.43778514862060547, -0.2452441155910492, 0.5806519985198975, 1.118287205696106, -1.2926483154296875, -0.354763001203537, -0.11173619329929352, -0.8812477588653564, 0.8788036704063416, -0.38362836837768555, -0.6677197813987732, 0.19325655698776245, -0.5496029257774353, 1.0646995306015015, 0.5734899044036865, -0.3100234270095825, -0.02941722422838211, -1.38490891456604, -0.053607355803251266, -0.4247777760028839, 0.16731971502304077, -0.5463887453079224, 0.17031806707382202, -0.2082882821559906, 0.5809780359268188, 0.15737177431583405, 0.43513578176498413, 0.44566935300827026, -0.21819503605365753, -1.2199230194091797, -0.5034757852554321, 0.365889310836792, 0.1134243756532669, -0.05393238365650177, 0.00018548965454101562, 0.7535566687583923, -0.24979719519615173, -0.06920288503170013, 0.14372405409812927, 0.8699983358383179, -0.10850094258785248, -1.0291668176651, -1.1403017044067383, 0.18761798739433289, 0.07944390922784805, 0.8200569152832031, 0.5068116784095764, 0.8284112215042114, 1.0778926610946655, -0.15227077901363373, 0.881582498550415, 0.4976547956466675, 0.22178523242473602, 0.7190673351287842, 0.5022713541984558, -0.8390051126480103, -0.8458074331283569, 0.5035760402679443, -1.132439374923706, 0.3206050395965576, 0.8730059862136841, -0.7293544411659241, 1.1887582540512085, -0.536067008972168, 0.184086412191391, -0.0061746202409267426, -0.9968743324279785, -0.6617611050605774, -0.30276548862457275, -0.8800727128982544, -1.4914606809616089, 0.9848299026489258, 0.5839979648590088, 0.5962715148925781, -1.1709980964660645, -0.361942857503891, 0.7435777187347412, -0.7745550870895386, 1.1696758270263672, 0.7242509722709656, -0.6915848851203918, -0.787778377532959, 0.11844758689403534, -1.2081997394561768, 0.14505332708358765, -1.4934430122375488, -0.7551590204238892, -0.33239734172821045, -0.11613748967647552, -0.835224986076355, 0.041516564786434174, -0.486211359500885, -0.8266245126724243, -1.0862727165222168, -0.042742036283016205, -0.3630317449569702, 0.4700332283973694, -0.7208739519119263, 0.4421793520450592, -0.24472950398921967, 0.07859735190868378, 0.3036835789680481, -0.9068487286567688, 0.004197359085083008, -0.3117341697216034, -0.8673655986785889, 0.086043581366539, -0.4867948889732361, 0.02780327945947647, 0.4692065119743347, -0.31901735067367554, 0.9330568313598633, -0.5587276816368103, -0.8066303730010986, 0.8747535943984985, -1.3673468828201294, 1.1037567853927612, 1.065603256225586, -0.20639903843402863, 0.07380551844835281, -0.6449920535087585, -0.007001563906669617, 0.3872873783111572, -1.416000485420227, -0.6492065787315369, -0.1413963884115219, -0.15609252452850342, -0.8483040928840637, 0.2748755216598511, -0.25501638650894165, 0.46451982855796814, -0.766758918762207, -0.3260316252708435, -0.944282054901123, -0.22435949742794037, -0.47462332248687744, 0.821194589138031, -0.8952817916870117, 0.5062146186828613, 1.4404066801071167, 0.24215632677078247, 0.830852746963501, 0.3258543908596039, -0.33261948823928833, -0.2819332182407379, -0.054409854114055634, -0.6536542773246765, -0.0002258196473121643, 0.2287123203277588, -2.163848876953125, 0.4728994369506836, -0.2937215566635132, -0.592559814453125, -0.14317551255226135, 0.039955977350473404, -1.0689506530761719, 0.8625741004943848, 0.07933633029460907, 0.15700379014015198, 0.6035330295562744, -1.5662319660186768, 0.6467610597610474, 0.9645611047744751, 0.8330069780349731, -0.8484874963760376, 0.22334331274032593, -1.7014796733856201, -0.9566660523414612, -1.904868245124817, 0.30771690607070923, -0.4173128306865692, 1.169834852218628, 0.6773732304573059, 1.4417786598205566, 0.5682870745658875, 0.16476663947105408, -0.5171328186988831, 0.23206613957881927, -0.2203277051448822, -0.15800534188747406, 2.278604745864868, 0.7326521873474121, 1.1791720390319824, -0.36607858538627625, 2.0449931621551514, 2.2656683921813965, 0.9902157187461853, -0.5656656622886658, 0.34445494413375854, 0.4609249234199524, 1.712591528892517, -0.043530285358428955, -0.7936089038848877, -1.6434675455093384, -0.22187204658985138, 0.06266161054372787, -1.0595815181732178, -0.12223401665687561, 0.3657125234603882, 0.2871432900428772, -0.7559854984283447, -0.7056323885917664, -0.7905158996582031, -1.404165506362915, 0.7598892450332642, -0.49735403060913086, 0.938809871673584, 0.04672111198306084, -0.7948818802833557, 0.13423866033554077, 1.3974982500076294, 1.304200291633606, -0.22204415500164032, -1.0997984409332275, -0.5225594639778137, 0.3850887715816498, 0.4527633786201477, -0.2574901878833771, 0.32859504222869873, -1.9477046728134155, -0.4563472867012024, -0.8940701484680176, -0.4159628450870514, -1.4608163833618164, -0.44772791862487793, -0.6451098322868347, 0.058615703135728836, -0.5323455333709717, -0.6399465799331665, -0.8719016313552856, -0.028044264763593674, -1.228973627090454, -0.40776175260543823, 1.2645659446716309, -0.9751258492469788, 1.5251442193984985, 0.5983078479766846, 0.8372694253921509, -0.9175456166267395, -1.200682520866394, 0.9528214335441589, 0.10896246135234833, -0.25260257720947266, -1.3545072078704834, 0.14294293522834778, 0.5459114909172058, 0.08216950297355652, 0.726294994354248, 0.6206281781196594, 0.14097777009010315, -1.0048028230667114, -0.9762288928031921, 0.25027066469192505, -0.04658249765634537, 0.8456312417984009, 0.8607296347618103, -0.49984002113342285, -0.7294963598251343, -0.7603419423103333, -0.8006911873817444, 0.7774250507354736, -0.13334687054157257, 0.8028297424316406, -1.002670407295227, -0.7334121465682983, -0.22275318205356598, -1.093764305114746, 0.8965562582015991, -0.18334081768989563, 0.013336321339011192, -0.2743288576602936, -0.5601423978805542, -0.08687029778957367, 0.26383528113365173, -1.2060879468917847, 0.8257660269737244, -0.389912873506546, 0.1416797786951065, -0.055221959948539734, -0.43209052085876465, -0.9172345995903015, -0.4291463792324066, 0.7032018899917603, -0.5472372770309448, 0.6098455190658569, -0.7383185625076294, -0.39531785249710083, 0.1445864886045456, 0.8167325258255005, -0.7275242805480957, 0.4934079647064209, 1.8279733657836914, 2.6550207138061523, 1.181665301322937, -0.08337263762950897, -0.3833933472633362, 0.2246008664369583, 0.7001459002494812, -0.07276690006256104, -0.5093886852264404, -1.202061653137207, 0.12638913094997406]\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    ")\n",
    "\n",
    "text = \"This is a sample query.\"\n",
    "query_result = embeddings.embed_query(text)\n",
    "print(query_result)\n",
    "print(len(query_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e3e69d-96ac-4d18-ad0a-11e0bb0cdf36",
   "metadata": {},
   "source": [
    "This code passes a single string input to the embed_query method and retrieves the corresponding\n",
    "text embedding. The result is stored in the query_result variable. The length of the embedding\n",
    "(the number of dimensions) can be obtained using the len() function. \n",
    "\n",
    "You can also obtain embeddings for multiple document inputs using the embed_documents() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25744e60-b4ad-448d-b1e2-09269e048c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "words = [\"cat\", \"dog\", \"computer\", \"animal\"]\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    ")\n",
    "doc_vectors = embeddings.embed_documents(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd9cfb5-ca20-4a22-ba8c-9af450154073",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.7717188596725464,\n",
       "  1.0309089422225952,\n",
       "  -3.2454001903533936,\n",
       "  -1.6525245904922485,\n",
       "  0.7204437851905823,\n",
       "  0.7939174771308899,\n",
       "  -0.9439053535461426,\n",
       "  0.6470693349838257,\n",
       "  -1.8985167741775513,\n",
       "  -0.5372151136398315,\n",
       "  -0.6041316986083984,\n",
       "  1.4551784992218018,\n",
       "  2.1501429080963135,\n",
       "  0.578033447265625,\n",
       "  -0.014118000864982605,\n",
       "  -0.5572053790092468,\n",
       "  1.6918145418167114,\n",
       "  -1.1941981315612793,\n",
       "  0.6711783409118652,\n",
       "  0.31632357835769653,\n",
       "  0.44778701663017273,\n",
       "  0.4624062776565552,\n",
       "  0.30035534501075745,\n",
       "  0.017211640253663063,\n",
       "  2.849835157394409,\n",
       "  1.7002432346343994,\n",
       "  0.3621326982975006,\n",
       "  0.7707653045654297,\n",
       "  -1.0500714778900146,\n",
       "  0.7595260739326477,\n",
       "  0.8547594547271729,\n",
       "  -0.4365848898887634,\n",
       "  -0.2862957715988159,\n",
       "  -0.18457455933094025,\n",
       "  -2.1360435485839844,\n",
       "  -0.22779615223407745,\n",
       "  2.0792272090911865,\n",
       "  0.45198410749435425,\n",
       "  0.24995695054531097,\n",
       "  1.1447800397872925,\n",
       "  1.0145636796951294,\n",
       "  0.6517409682273865,\n",
       "  -0.6026995778083801,\n",
       "  -0.5098872184753418,\n",
       "  0.06362254172563553,\n",
       "  0.14950408041477203,\n",
       "  0.15848112106323242,\n",
       "  -1.1765817403793335,\n",
       "  -0.5461001992225647,\n",
       "  0.25635138154029846,\n",
       "  -0.3247138559818268,\n",
       "  -0.02989530749619007,\n",
       "  -0.45935365557670593,\n",
       "  -1.5642194747924805,\n",
       "  1.002726435661316,\n",
       "  1.5515649318695068,\n",
       "  2.196007490158081,\n",
       "  -1.2716171741485596,\n",
       "  -1.0397694110870361,\n",
       "  -0.24005688726902008,\n",
       "  2.0366032123565674,\n",
       "  0.1055912896990776,\n",
       "  -0.8343712687492371,\n",
       "  1.7663559913635254,\n",
       "  0.9955558776855469,\n",
       "  -0.04884622246026993,\n",
       "  -0.06846214830875397,\n",
       "  1.588670253753662,\n",
       "  -0.585758626461029,\n",
       "  -0.3135237693786621,\n",
       "  1.7530680894851685,\n",
       "  0.48562175035476685,\n",
       "  0.47513556480407715,\n",
       "  -0.0967918410897255,\n",
       "  -0.3522239625453949,\n",
       "  -0.6930463314056396,\n",
       "  0.10556233674287796,\n",
       "  -0.08557747304439545,\n",
       "  -0.5448663830757141,\n",
       "  1.2778301239013672,\n",
       "  -0.04396652430295944,\n",
       "  0.8077526688575745,\n",
       "  1.4546115398406982,\n",
       "  -0.2289680540561676,\n",
       "  1.2318462133407593,\n",
       "  -0.37697628140449524,\n",
       "  0.005574333015829325,\n",
       "  -0.4103069305419922,\n",
       "  -1.5279557704925537,\n",
       "  0.31838133931159973,\n",
       "  -0.9687839150428772,\n",
       "  0.20178952813148499,\n",
       "  1.2407273054122925,\n",
       "  -0.5009133815765381,\n",
       "  -0.44029945135116577,\n",
       "  0.5512824654579163,\n",
       "  0.04253587871789932,\n",
       "  -0.37795376777648926,\n",
       "  -0.2410614788532257,\n",
       "  -1.8790688514709473,\n",
       "  -1.391498327255249,\n",
       "  -0.24647077918052673,\n",
       "  0.49601903557777405,\n",
       "  -0.177149698138237,\n",
       "  1.1561039686203003,\n",
       "  2.4225831031799316,\n",
       "  -0.3926570415496826,\n",
       "  0.11284277588129044,\n",
       "  -0.683449923992157,\n",
       "  -0.6288449764251709,\n",
       "  -1.0372049808502197,\n",
       "  0.4892081022262573,\n",
       "  -0.35152995586395264,\n",
       "  -0.7828144431114197,\n",
       "  0.3683066964149475,\n",
       "  0.3150665760040283,\n",
       "  1.840786337852478,\n",
       "  -0.3345949351787567,\n",
       "  0.5866679549217224,\n",
       "  0.5109255313873291,\n",
       "  -0.7154868841171265,\n",
       "  -0.23612508177757263,\n",
       "  0.4988676905632019,\n",
       "  1.2062671184539795,\n",
       "  0.6303960680961609,\n",
       "  0.9342679977416992,\n",
       "  -1.5946791172027588,\n",
       "  0.22777897119522095,\n",
       "  0.1231391653418541,\n",
       "  0.979138970375061,\n",
       "  0.12451925873756409,\n",
       "  -0.07808464020490646,\n",
       "  0.2901894450187683,\n",
       "  0.4251309037208557,\n",
       "  -0.1523093432188034,\n",
       "  0.8938007354736328,\n",
       "  0.21761372685432434,\n",
       "  -1.5049446821212769,\n",
       "  0.958389163017273,\n",
       "  0.8523901104927063,\n",
       "  1.2856967449188232,\n",
       "  0.016827888786792755,\n",
       "  0.8588170409202576,\n",
       "  -0.05441920831799507,\n",
       "  -0.2588103711605072,\n",
       "  -0.3514874577522278,\n",
       "  1.7121809720993042,\n",
       "  -0.9637351036071777,\n",
       "  -0.705095112323761,\n",
       "  0.10265382379293442,\n",
       "  -0.11031029373407364,\n",
       "  0.9762860536575317,\n",
       "  0.15868020057678223,\n",
       "  1.9091726541519165,\n",
       "  1.199974775314331,\n",
       "  -1.0201307535171509,\n",
       "  0.46402934193611145,\n",
       "  0.4196373522281647,\n",
       "  -0.71122807264328,\n",
       "  0.9507030844688416,\n",
       "  0.9318891167640686,\n",
       "  -0.2839198708534241,\n",
       "  -1.6326780319213867,\n",
       "  -0.18009252846240997,\n",
       "  -0.35140863060951233,\n",
       "  -0.9784924387931824,\n",
       "  1.1271792650222778,\n",
       "  1.0512758493423462,\n",
       "  0.39662325382232666,\n",
       "  1.461558222770691,\n",
       "  0.2423381805419922,\n",
       "  -0.6903484463691711,\n",
       "  -1.224905252456665,\n",
       "  0.5333160758018494,\n",
       "  -0.29480814933776855,\n",
       "  -0.5494104623794556,\n",
       "  1.04952871799469,\n",
       "  -1.0742552280426025,\n",
       "  -0.18073925375938416,\n",
       "  -1.1039963960647583,\n",
       "  1.107704997062683,\n",
       "  -0.9043551087379456,\n",
       "  0.37729412317276,\n",
       "  0.772900402545929,\n",
       "  -0.38230034708976746,\n",
       "  -0.5238728523254395,\n",
       "  -0.6514272093772888,\n",
       "  -0.4255037307739258,\n",
       "  -0.7489071488380432,\n",
       "  -0.9789689183235168,\n",
       "  -1.5457431077957153,\n",
       "  1.1009552478790283,\n",
       "  -0.7427445650100708,\n",
       "  0.0217752605676651,\n",
       "  -1.1479634046554565,\n",
       "  -0.878333568572998,\n",
       "  0.9554181694984436,\n",
       "  -0.8347075581550598,\n",
       "  -0.7021329998970032,\n",
       "  -0.6732887625694275,\n",
       "  -0.6074435114860535,\n",
       "  -0.28873300552368164,\n",
       "  -1.6774314641952515,\n",
       "  0.2731853127479553,\n",
       "  -1.3502634763717651,\n",
       "  0.41903698444366455,\n",
       "  -1.2755171060562134,\n",
       "  0.5554221868515015,\n",
       "  -0.01929435320198536,\n",
       "  0.8720799684524536,\n",
       "  1.8964661359786987,\n",
       "  0.26167795062065125,\n",
       "  -0.8453285098075867,\n",
       "  0.3316769301891327,\n",
       "  -0.5040820837020874,\n",
       "  -1.3847360610961914,\n",
       "  -0.44811975955963135,\n",
       "  -0.8052797913551331,\n",
       "  -0.8454448580741882,\n",
       "  0.09548759460449219,\n",
       "  0.7942990660667419,\n",
       "  -0.21607032418251038,\n",
       "  1.2302740812301636,\n",
       "  -1.123327612876892,\n",
       "  1.092645287513733,\n",
       "  0.005274377763271332,\n",
       "  0.09565601497888565,\n",
       "  -0.46209415793418884,\n",
       "  -1.297376036643982,\n",
       "  0.4264374375343323,\n",
       "  -0.9719712138175964,\n",
       "  -0.5039177536964417,\n",
       "  0.537325918674469,\n",
       "  0.35907649993896484,\n",
       "  -0.323403924703598,\n",
       "  1.4548649787902832,\n",
       "  1.5576244592666626,\n",
       "  1.4307992458343506,\n",
       "  -0.14294220507144928,\n",
       "  -0.3142551779747009,\n",
       "  0.12488598376512527,\n",
       "  0.7693071365356445,\n",
       "  -1.0795468091964722,\n",
       "  -0.43083685636520386,\n",
       "  -0.7070075869560242,\n",
       "  0.9877952933311462,\n",
       "  0.541462242603302,\n",
       "  -0.3064242899417877,\n",
       "  0.24975767731666565,\n",
       "  1.398213505744934,\n",
       "  -0.34613120555877686,\n",
       "  -0.1266421675682068,\n",
       "  1.3266624212265015,\n",
       "  -0.5417084097862244,\n",
       "  0.6054713129997253,\n",
       "  -1.6421997547149658,\n",
       "  0.15010711550712585,\n",
       "  -0.22961771488189697,\n",
       "  -0.36248746514320374,\n",
       "  -0.16898034512996674,\n",
       "  -0.22509612143039703,\n",
       "  -1.8888791799545288,\n",
       "  0.1831808090209961,\n",
       "  -1.5224852561950684,\n",
       "  -0.7752118706703186,\n",
       "  -0.28544875979423523,\n",
       "  -0.1327562928199768,\n",
       "  -0.10425572842359543,\n",
       "  0.7837252020835876,\n",
       "  -0.5917967557907104,\n",
       "  1.0060734748840332,\n",
       "  0.9952933192253113,\n",
       "  0.13420811295509338,\n",
       "  0.1817181408405304,\n",
       "  -0.26962003111839294,\n",
       "  -0.5949024558067322,\n",
       "  -0.22602251172065735,\n",
       "  -1.1835291385650635,\n",
       "  0.002728927182033658,\n",
       "  0.0896616280078888,\n",
       "  0.4849497079849243,\n",
       "  -0.574141800403595,\n",
       "  -1.3573524951934814,\n",
       "  -0.3496896028518677,\n",
       "  -0.16940537095069885,\n",
       "  0.42721959948539734,\n",
       "  0.7620348930358887,\n",
       "  1.0262267589569092,\n",
       "  0.4583868682384491,\n",
       "  -0.5553185343742371,\n",
       "  1.3292019367218018,\n",
       "  -0.08294368535280228,\n",
       "  -0.439804345369339,\n",
       "  1.446977138519287,\n",
       "  -0.023847388103604317,\n",
       "  -1.080198049545288,\n",
       "  1.6332080364227295,\n",
       "  -0.1856248527765274,\n",
       "  0.7109230756759644,\n",
       "  -0.6336239576339722,\n",
       "  0.6012776494026184,\n",
       "  1.1852916479110718,\n",
       "  -0.01399028580635786,\n",
       "  0.8154668807983398,\n",
       "  0.15580549836158752,\n",
       "  0.4048525393009186,\n",
       "  0.810660183429718,\n",
       "  -0.16322484612464905,\n",
       "  0.7393059134483337,\n",
       "  -0.14775961637496948,\n",
       "  -1.3208004236221313,\n",
       "  -1.0560216903686523,\n",
       "  0.5694972276687622,\n",
       "  0.046508222818374634,\n",
       "  -1.7898499965667725,\n",
       "  0.14747563004493713,\n",
       "  -0.5379517078399658,\n",
       "  0.2635370194911957,\n",
       "  0.6264338493347168,\n",
       "  0.6743236780166626,\n",
       "  0.07289448380470276,\n",
       "  -0.8318761587142944,\n",
       "  1.1051573753356934,\n",
       "  -0.708375096321106,\n",
       "  -0.02606232278048992,\n",
       "  -0.46742555499076843,\n",
       "  -1.0567244291305542,\n",
       "  0.7915072441101074,\n",
       "  -0.09900666773319244,\n",
       "  -0.8598942756652832,\n",
       "  -0.002344781067222357,\n",
       "  0.9677391052246094,\n",
       "  1.108209252357483,\n",
       "  -0.693670392036438,\n",
       "  -0.25385820865631104,\n",
       "  0.4955112338066101,\n",
       "  0.3077719509601593,\n",
       "  0.30681633949279785,\n",
       "  -0.8235563039779663,\n",
       "  0.0891232043504715,\n",
       "  1.5751142501831055,\n",
       "  -1.1872918605804443,\n",
       "  0.30879950523376465,\n",
       "  -1.190129041671753,\n",
       "  1.752550721168518,\n",
       "  -1.8320722579956055,\n",
       "  -0.8718439340591431,\n",
       "  0.12316052615642548,\n",
       "  0.5515384078025818,\n",
       "  0.29594218730926514,\n",
       "  -1.5279649496078491,\n",
       "  -0.4028342664241791,\n",
       "  -0.11077675968408585,\n",
       "  0.7411999106407166,\n",
       "  -0.00516924075782299,\n",
       "  0.44908416271209717,\n",
       "  0.5719848275184631,\n",
       "  0.23600201308727264,\n",
       "  -0.9713648557662964,\n",
       "  0.10699208080768585,\n",
       "  0.7867777943611145,\n",
       "  -1.5073375701904297,\n",
       "  -0.18160225450992584,\n",
       "  0.2526625990867615,\n",
       "  0.7136651873588562,\n",
       "  1.2816606760025024,\n",
       "  1.2717022895812988,\n",
       "  0.11030080914497375,\n",
       "  0.643733024597168,\n",
       "  0.8880311250686646,\n",
       "  -0.30827978253364563,\n",
       "  -0.6592755913734436,\n",
       "  0.3237406015396118,\n",
       "  -0.14927874505519867,\n",
       "  1.6379448175430298,\n",
       "  0.036529578268527985,\n",
       "  -1.012722134590149,\n",
       "  -0.5369856953620911,\n",
       "  -0.6051604151725769,\n",
       "  0.32562828063964844,\n",
       "  0.09142249822616577,\n",
       "  0.07321256399154663,\n",
       "  -0.08948999643325806,\n",
       "  0.014572588726878166,\n",
       "  1.1371452808380127,\n",
       "  -0.006079866085201502,\n",
       "  -1.115062952041626,\n",
       "  0.7125245928764343,\n",
       "  0.023113785311579704,\n",
       "  0.6941862106323242,\n",
       "  -0.1712031215429306,\n",
       "  0.03096742182970047,\n",
       "  -1.5838181972503662,\n",
       "  0.011837157420814037,\n",
       "  0.15208235383033752,\n",
       "  -0.8160439729690552,\n",
       "  1.0468640327453613,\n",
       "  0.20977744460105896,\n",
       "  -0.7248472571372986,\n",
       "  0.9138599634170532,\n",
       "  -0.6523595452308655,\n",
       "  -0.5285582542419434,\n",
       "  -0.0473300963640213,\n",
       "  1.0422221422195435,\n",
       "  -0.05311259627342224,\n",
       "  1.3386367559432983,\n",
       "  0.6724856495857239,\n",
       "  -1.1155232191085815,\n",
       "  0.998680591583252,\n",
       "  0.08679145574569702,\n",
       "  -0.2301873415708542,\n",
       "  1.3336597681045532,\n",
       "  -0.3755987286567688,\n",
       "  -0.8694241642951965,\n",
       "  0.4305688440799713,\n",
       "  0.6393604278564453,\n",
       "  0.8939700722694397,\n",
       "  0.41612526774406433,\n",
       "  -0.5270268321037292,\n",
       "  -0.7999024391174316,\n",
       "  0.856759786605835,\n",
       "  0.8167700171470642,\n",
       "  -1.2533085346221924,\n",
       "  0.22464297711849213,\n",
       "  0.14728766679763794,\n",
       "  -0.4207245111465454,\n",
       "  -0.3963267207145691,\n",
       "  1.1979588270187378,\n",
       "  -0.2997722029685974,\n",
       "  -1.1774760484695435,\n",
       "  -0.3242214322090149,\n",
       "  0.06816720962524414,\n",
       "  0.24156619608402252,\n",
       "  1.1271814107894897,\n",
       "  -0.6004382371902466,\n",
       "  0.1700972616672516,\n",
       "  -0.5967203974723816,\n",
       "  0.17321617901325226,\n",
       "  0.6428110599517822,\n",
       "  1.264747142791748,\n",
       "  0.46136990189552307,\n",
       "  -0.8873606324195862,\n",
       "  -1.0125309228897095,\n",
       "  -0.32157784700393677,\n",
       "  -0.12144031375646591,\n",
       "  1.018362045288086,\n",
       "  0.6709908843040466,\n",
       "  -1.8514460325241089,\n",
       "  -0.7859243154525757,\n",
       "  1.4994125366210938,\n",
       "  -0.8792381882667542,\n",
       "  1.0098834037780762,\n",
       "  0.0908581018447876,\n",
       "  0.7294541001319885,\n",
       "  1.958188533782959,\n",
       "  -2.4478888511657715,\n",
       "  -0.7683789134025574,\n",
       "  -0.48894304037094116,\n",
       "  0.861936092376709,\n",
       "  0.36668452620506287,\n",
       "  0.7450284957885742,\n",
       "  1.2996495962142944,\n",
       "  -1.7239775657653809,\n",
       "  0.14674760401248932,\n",
       "  1.3924596309661865,\n",
       "  -0.005840398836880922,\n",
       "  0.5947576761245728,\n",
       "  0.06643101572990417,\n",
       "  1.2641160488128662,\n",
       "  1.9817460775375366,\n",
       "  -0.18922047317028046,\n",
       "  0.265972763299942,\n",
       "  0.15900413691997528,\n",
       "  -1.2620110511779785,\n",
       "  -0.002400543773546815,\n",
       "  -0.49055561423301697,\n",
       "  0.04068054258823395,\n",
       "  0.11052843928337097,\n",
       "  -0.09277691692113876,\n",
       "  0.8249126076698303,\n",
       "  -0.036879461258649826,\n",
       "  0.3875325620174408,\n",
       "  0.006523560266941786,\n",
       "  -1.7011520862579346,\n",
       "  0.08573286980390549,\n",
       "  0.09346818923950195,\n",
       "  0.06263946741819382,\n",
       "  0.2614154815673828,\n",
       "  -0.8819417953491211,\n",
       "  -0.3836766481399536,\n",
       "  0.3471566140651703,\n",
       "  0.5071466565132141,\n",
       "  -0.009198149666190147,\n",
       "  -0.38470953702926636,\n",
       "  -0.48576033115386963,\n",
       "  -0.1670895516872406,\n",
       "  0.6298079490661621,\n",
       "  0.08343801647424698,\n",
       "  1.6419697999954224,\n",
       "  0.9222766160964966,\n",
       "  0.10167840868234634,\n",
       "  -0.05571391060948372,\n",
       "  -0.22247156500816345,\n",
       "  1.244828462600708,\n",
       "  1.0560728311538696,\n",
       "  -0.6795501112937927,\n",
       "  -0.7548357248306274,\n",
       "  -1.3618488311767578,\n",
       "  -0.8311790227890015,\n",
       "  -0.5852933526039124,\n",
       "  -0.7320753931999207,\n",
       "  0.13202480971813202,\n",
       "  0.17710180580615997,\n",
       "  0.9820990562438965,\n",
       "  1.9385817050933838,\n",
       "  -0.12593215703964233,\n",
       "  0.6712968349456787,\n",
       "  -0.08072341233491898,\n",
       "  -0.011091061867773533,\n",
       "  0.4034143090248108,\n",
       "  0.8651745915412903,\n",
       "  -0.37840771675109863,\n",
       "  -0.9809575080871582,\n",
       "  -0.02545921318233013,\n",
       "  -0.4582943320274353,\n",
       "  0.1296907216310501,\n",
       "  0.9257448315620422,\n",
       "  -1.3508086204528809,\n",
       "  -0.3541356325149536,\n",
       "  -0.6715032458305359,\n",
       "  0.5206411480903625,\n",
       "  0.15575915575027466,\n",
       "  -1.469618558883667,\n",
       "  -1.159159779548645,\n",
       "  -0.5257123708724976,\n",
       "  -1.0179297924041748,\n",
       "  -0.4411426782608032,\n",
       "  -0.2670416831970215,\n",
       "  -0.2148827612400055,\n",
       "  -0.21003630757331848,\n",
       "  -0.6067033410072327,\n",
       "  -0.2259945571422577,\n",
       "  -0.16094231605529785,\n",
       "  0.8364918828010559,\n",
       "  0.07500556111335754,\n",
       "  0.15515436232089996,\n",
       "  -0.18441544473171234,\n",
       "  -0.054110415279865265,\n",
       "  -1.311026930809021,\n",
       "  -1.0159006118774414,\n",
       "  0.9717004895210266,\n",
       "  -1.6968779563903809,\n",
       "  -0.6202425956726074,\n",
       "  0.07101313769817352,\n",
       "  -0.027882220223546028,\n",
       "  -0.9476311802864075,\n",
       "  -0.024282194674015045,\n",
       "  0.7042746543884277,\n",
       "  -0.42948758602142334,\n",
       "  -1.2749850749969482,\n",
       "  0.7522425055503845,\n",
       "  -0.07714198529720306,\n",
       "  1.2460532188415527,\n",
       "  0.7929213643074036,\n",
       "  0.13030824065208435,\n",
       "  0.3000372052192688,\n",
       "  -0.08276354521512985,\n",
       "  0.8421987295150757,\n",
       "  0.3410131335258484,\n",
       "  -0.4564364552497864,\n",
       "  -0.5429307222366333,\n",
       "  -0.03839618340134621,\n",
       "  -0.7350100874900818,\n",
       "  -0.42190688848495483,\n",
       "  0.12831735610961914,\n",
       "  0.06646454334259033,\n",
       "  0.160757377743721,\n",
       "  0.4789015054702759,\n",
       "  -1.2288028001785278,\n",
       "  -0.6107956171035767,\n",
       "  0.2703644931316376,\n",
       "  -0.7860599756240845,\n",
       "  -1.0737498998641968,\n",
       "  -0.4944068491458893,\n",
       "  -0.397602379322052,\n",
       "  -0.06884487718343735,\n",
       "  -1.0788127183914185,\n",
       "  -0.696276843547821,\n",
       "  0.16415351629257202,\n",
       "  0.217951238155365,\n",
       "  0.11478794366121292,\n",
       "  -0.7414450645446777,\n",
       "  -0.2931674122810364,\n",
       "  -0.5881572365760803,\n",
       "  0.2339896559715271,\n",
       "  0.4488842189311981,\n",
       "  -0.2896333932876587,\n",
       "  -1.1560879945755005,\n",
       "  0.1793527454137802,\n",
       "  -0.7595891952514648,\n",
       "  -0.657190203666687,\n",
       "  0.9133917689323425,\n",
       "  1.686598300933838,\n",
       "  -1.2731852531433105,\n",
       "  -0.7472933530807495,\n",
       "  0.7811073064804077,\n",
       "  0.5431769490242004,\n",
       "  -0.002333683893084526,\n",
       "  -0.6218106150627136,\n",
       "  -0.9381048679351807,\n",
       "  0.5377113819122314,\n",
       "  0.030855827033519745,\n",
       "  -0.11299119144678116,\n",
       "  -0.05787980929017067,\n",
       "  0.7855027914047241,\n",
       "  -0.45281559228897095,\n",
       "  1.7289831638336182,\n",
       "  -0.295168399810791,\n",
       "  -0.4090964198112488,\n",
       "  -0.1329704225063324,\n",
       "  -0.3964812755584717,\n",
       "  -1.222161889076233,\n",
       "  0.7611773610115051,\n",
       "  -0.42005303502082825,\n",
       "  0.8915858864784241,\n",
       "  -0.1170075386762619,\n",
       "  -0.8446839451789856,\n",
       "  -0.001760056708008051,\n",
       "  0.20800752937793732,\n",
       "  1.2219257354736328,\n",
       "  -0.5880127549171448,\n",
       "  0.5252568125724792,\n",
       "  -1.6013755798339844,\n",
       "  -1.3631951808929443,\n",
       "  -0.15263701975345612,\n",
       "  -0.15198394656181335,\n",
       "  -1.2317065000534058,\n",
       "  -0.6378090977668762,\n",
       "  -0.22366882860660553,\n",
       "  0.3695838749408722,\n",
       "  0.5606662631034851,\n",
       "  0.1019764319062233,\n",
       "  -0.0465066060423851,\n",
       "  -0.6323215365409851,\n",
       "  0.30917036533355713,\n",
       "  -1.1920294761657715,\n",
       "  0.946891725063324,\n",
       "  0.024523157626390457,\n",
       "  0.4017939865589142,\n",
       "  -1.0535391569137573,\n",
       "  1.2081104516983032,\n",
       "  2.269792318344116,\n",
       "  -0.3203449547290802,\n",
       "  0.301181435585022,\n",
       "  1.3386542797088623,\n",
       "  -1.408956527709961,\n",
       "  0.18556584417819977,\n",
       "  -1.0557657480239868,\n",
       "  -0.4524129033088684,\n",
       "  -0.4709186851978302,\n",
       "  0.04988342896103859,\n",
       "  -0.2784005403518677,\n",
       "  -0.38063928484916687,\n",
       "  0.062404315918684006,\n",
       "  1.124484896659851,\n",
       "  -0.5457385778427124,\n",
       "  0.18301555514335632,\n",
       "  -0.9940823912620544,\n",
       "  -1.3185933828353882,\n",
       "  -0.6086262464523315,\n",
       "  0.6446277499198914,\n",
       "  0.3065759837627411,\n",
       "  0.7932758331298828,\n",
       "  -0.02652924880385399,\n",
       "  0.1861618310213089,\n",
       "  1.0218502283096313,\n",
       "  0.1745915710926056,\n",
       "  1.5522938966751099,\n",
       "  0.8037228584289551,\n",
       "  -1.0254851579666138,\n",
       "  0.4695143401622772,\n",
       "  -0.43184104561805725,\n",
       "  -0.42588284611701965,\n",
       "  0.9569547176361084,\n",
       "  0.2863008379936218,\n",
       "  -2.608757257461548,\n",
       "  0.6452140808105469,\n",
       "  -1.460004210472107,\n",
       "  0.28106728196144104,\n",
       "  -0.8086926341056824,\n",
       "  0.4732748866081238,\n",
       "  -1.923712134361267,\n",
       "  0.8174495100975037,\n",
       "  -0.46725404262542725,\n",
       "  -0.38184577226638794,\n",
       "  -0.3004201054573059,\n",
       "  0.4805849492549896,\n",
       "  -0.19583794474601746,\n",
       "  -0.32933440804481506,\n",
       "  1.9813865423202515,\n",
       "  -0.178144633769989,\n",
       "  0.7716463804244995,\n",
       "  -0.04054054617881775,\n",
       "  0.7955785393714905,\n",
       "  -0.13705474138259888,\n",
       "  -0.8767654299736023,\n",
       "  -0.5034687519073486,\n",
       "  0.023362671956419945,\n",
       "  -0.03572553023695946,\n",
       "  0.18504399061203003,\n",
       "  -0.26133331656455994,\n",
       "  0.9350084662437439,\n",
       "  -0.6821648478507996,\n",
       "  0.2717694640159607,\n",
       "  0.476837158203125,\n",
       "  -0.11573164165019989,\n",
       "  -0.28683924674987793,\n",
       "  0.1582363396883011,\n",
       "  -0.45678025484085083,\n",
       "  1.7875688076019287,\n",
       "  0.6387368440628052,\n",
       "  -0.2774260938167572,\n",
       "  0.13193930685520172,\n",
       "  -0.18086875975131989,\n",
       "  -0.02152128331363201,\n",
       "  -1.0069630146026611,\n",
       "  0.5355061888694763,\n",
       "  -0.7195471525192261,\n",
       "  1.532026767730713,\n",
       "  0.4902706444263458,\n",
       "  0.4162465035915375,\n",
       "  -0.011204197071492672,\n",
       "  -1.3698997497558594,\n",
       "  0.709191620349884,\n",
       "  -0.4755409359931946,\n",
       "  -0.0008497544913552701,\n",
       "  -1.3356274366378784,\n",
       "  -0.06233725696802139,\n",
       "  0.22705072164535522,\n",
       "  -0.8277896642684937,\n",
       "  -1.192234754562378,\n",
       "  -0.2525407373905182,\n",
       "  0.2907256484031677,\n",
       "  -0.07354174554347992,\n",
       "  -0.21418067812919617,\n",
       "  0.03646191209554672,\n",
       "  -0.9436604380607605,\n",
       "  -0.055509302765131,\n",
       "  1.536651849746704,\n",
       "  -0.9829429388046265,\n",
       "  0.5547512769699097,\n",
       "  -0.733458936214447,\n",
       "  -1.455413818359375,\n",
       "  -0.33601972460746765,\n",
       "  -0.09978052228689194,\n",
       "  0.7373764514923096,\n",
       "  -0.6842513680458069,\n",
       "  1.6015714406967163,\n",
       "  1.105846643447876,\n",
       "  0.041324879974126816,\n",
       "  0.3278428614139557,\n",
       "  -0.671728789806366,\n",
       "  1.708365797996521,\n",
       "  -0.1280783712863922,\n",
       "  -0.23385797441005707,\n",
       "  -0.4904670715332031,\n",
       "  -0.5624747276306152,\n",
       "  -0.784548819065094],\n",
       " [0.26116693019866943,\n",
       "  0.038772113621234894,\n",
       "  -3.6801345348358154,\n",
       "  -1.833993673324585,\n",
       "  0.4224504828453064,\n",
       "  0.6381832361221313,\n",
       "  -0.6209225058555603,\n",
       "  1.0520128011703491,\n",
       "  -1.4182243347167969,\n",
       "  -1.5008978843688965,\n",
       "  -0.6659188866615295,\n",
       "  1.107799768447876,\n",
       "  1.086401104927063,\n",
       "  0.2433466613292694,\n",
       "  0.4389606714248657,\n",
       "  -0.7664315104484558,\n",
       "  1.489372968673706,\n",
       "  -1.7160091400146484,\n",
       "  1.277543544769287,\n",
       "  0.18449483811855316,\n",
       "  0.21702635288238525,\n",
       "  1.530013084411621,\n",
       "  0.3127829134464264,\n",
       "  0.6465379595756531,\n",
       "  4.0531840324401855,\n",
       "  0.885586142539978,\n",
       "  0.175531804561615,\n",
       "  0.7073987722396851,\n",
       "  -0.7657634615898132,\n",
       "  0.6932646036148071,\n",
       "  -0.05120917782187462,\n",
       "  -0.014230617322027683,\n",
       "  -0.6604363322257996,\n",
       "  0.23944923281669617,\n",
       "  -0.605119526386261,\n",
       "  -0.38504931330680847,\n",
       "  1.1493961811065674,\n",
       "  1.2239164113998413,\n",
       "  -0.4355546832084656,\n",
       "  0.48017147183418274,\n",
       "  1.267346978187561,\n",
       "  0.5638874173164368,\n",
       "  -0.06826653331518173,\n",
       "  0.05691782757639885,\n",
       "  1.1236907243728638,\n",
       "  -0.9128497838973999,\n",
       "  1.1121691465377808,\n",
       "  -0.7505840063095093,\n",
       "  -0.004655277822166681,\n",
       "  -0.13548317551612854,\n",
       "  0.6585513353347778,\n",
       "  0.7583655118942261,\n",
       "  0.4916955828666687,\n",
       "  -0.9202736020088196,\n",
       "  1.709333062171936,\n",
       "  0.886333703994751,\n",
       "  1.4176640510559082,\n",
       "  -0.571077823638916,\n",
       "  -0.8772395253181458,\n",
       "  -0.0161251500248909,\n",
       "  2.1780591011047363,\n",
       "  0.7860655784606934,\n",
       "  -1.3375502824783325,\n",
       "  0.10557258874177933,\n",
       "  1.3357110023498535,\n",
       "  -1.9370609521865845,\n",
       "  -0.04315654933452606,\n",
       "  1.2566384077072144,\n",
       "  -0.7461757659912109,\n",
       "  -0.07906919717788696,\n",
       "  2.2896573543548584,\n",
       "  -0.07713937014341354,\n",
       "  0.5732525587081909,\n",
       "  -0.13998711109161377,\n",
       "  -0.43324360251426697,\n",
       "  -1.3175331354141235,\n",
       "  -0.3733130991458893,\n",
       "  0.11386211216449738,\n",
       "  -0.05979745090007782,\n",
       "  0.5730257034301758,\n",
       "  0.049055445939302444,\n",
       "  0.909483790397644,\n",
       "  1.4257992506027222,\n",
       "  -0.057918380945920944,\n",
       "  1.3833730220794678,\n",
       "  -0.7386223077774048,\n",
       "  -0.7074645757675171,\n",
       "  -1.0608172416687012,\n",
       "  -1.420855164527893,\n",
       "  0.4414244294166565,\n",
       "  -0.39080536365509033,\n",
       "  0.07382475584745407,\n",
       "  0.7635982036590576,\n",
       "  -0.1549527943134308,\n",
       "  -0.7397984266281128,\n",
       "  -0.49877238273620605,\n",
       "  0.10076575726270676,\n",
       "  -0.20258183777332306,\n",
       "  0.11044430732727051,\n",
       "  -1.4272416830062866,\n",
       "  -1.23902428150177,\n",
       "  -0.46430742740631104,\n",
       "  0.45732933282852173,\n",
       "  0.5306390523910522,\n",
       "  0.3189138174057007,\n",
       "  2.4266321659088135,\n",
       "  0.5188050866127014,\n",
       "  0.4634227752685547,\n",
       "  -0.37856772541999817,\n",
       "  -0.2842203974723816,\n",
       "  -1.4788354635238647,\n",
       "  0.820239782333374,\n",
       "  0.4760490357875824,\n",
       "  -0.7486407160758972,\n",
       "  0.5231245756149292,\n",
       "  0.5307334661483765,\n",
       "  1.9244084358215332,\n",
       "  0.1255560964345932,\n",
       "  0.0874878391623497,\n",
       "  1.3813098669052124,\n",
       "  -1.1592975854873657,\n",
       "  -0.01796971634030342,\n",
       "  -0.00026943429838865995,\n",
       "  1.7435722351074219,\n",
       "  0.06974436342716217,\n",
       "  0.31219542026519775,\n",
       "  -0.6374872326850891,\n",
       "  0.7604613900184631,\n",
       "  -0.10163278877735138,\n",
       "  0.26956191658973694,\n",
       "  -0.10968491435050964,\n",
       "  -0.4570991098880768,\n",
       "  0.16582705080509186,\n",
       "  0.3514387905597687,\n",
       "  0.276719868183136,\n",
       "  0.6200173497200012,\n",
       "  -0.3400534689426422,\n",
       "  -0.9092640280723572,\n",
       "  -0.07239007949829102,\n",
       "  0.7907003164291382,\n",
       "  0.7049591541290283,\n",
       "  0.9526897668838501,\n",
       "  0.3290935158729553,\n",
       "  0.13856758177280426,\n",
       "  -0.29997140169143677,\n",
       "  -0.8539673089981079,\n",
       "  0.9694918990135193,\n",
       "  -1.09037446975708,\n",
       "  0.020646924152970314,\n",
       "  -0.4371296465396881,\n",
       "  0.04117100313305855,\n",
       "  0.7539941668510437,\n",
       "  -0.5939452648162842,\n",
       "  1.7234046459197998,\n",
       "  1.37495756149292,\n",
       "  -0.7032638192176819,\n",
       "  0.581520140171051,\n",
       "  0.8406816124916077,\n",
       "  -0.5699050426483154,\n",
       "  0.9465509653091431,\n",
       "  1.0383472442626953,\n",
       "  -0.7503629922866821,\n",
       "  -0.5458738207817078,\n",
       "  0.5256272554397583,\n",
       "  -0.14682190120220184,\n",
       "  -0.32458898425102234,\n",
       "  -0.08087358623743057,\n",
       "  0.9091811776161194,\n",
       "  0.22184619307518005,\n",
       "  1.1871908903121948,\n",
       "  0.32528793811798096,\n",
       "  -1.4938852787017822,\n",
       "  -0.1692320853471756,\n",
       "  0.48471370339393616,\n",
       "  -0.2013004571199417,\n",
       "  -0.3664359450340271,\n",
       "  0.33452481031417847,\n",
       "  -1.6204346418380737,\n",
       "  -0.626704752445221,\n",
       "  -0.6758406758308411,\n",
       "  0.7439106702804565,\n",
       "  -1.004127860069275,\n",
       "  0.32866066694259644,\n",
       "  0.8638191819190979,\n",
       "  -0.2317979633808136,\n",
       "  -0.1025610864162445,\n",
       "  0.17297345399856567,\n",
       "  -0.6059375405311584,\n",
       "  -0.6176363229751587,\n",
       "  -1.059140682220459,\n",
       "  -2.2299885749816895,\n",
       "  0.7223286032676697,\n",
       "  -0.3382948637008667,\n",
       "  -0.31816786527633667,\n",
       "  -1.3380799293518066,\n",
       "  -0.45552632212638855,\n",
       "  0.10040359199047089,\n",
       "  -1.4642211198806763,\n",
       "  0.2017996609210968,\n",
       "  -0.8667886257171631,\n",
       "  0.5515345335006714,\n",
       "  -0.029977425932884216,\n",
       "  -1.3176624774932861,\n",
       "  -0.19027186930179596,\n",
       "  -1.9932100772857666,\n",
       "  -0.5231024026870728,\n",
       "  -0.8608329892158508,\n",
       "  0.7749274969100952,\n",
       "  -0.3433953821659088,\n",
       "  0.7932929992675781,\n",
       "  1.6613712310791016,\n",
       "  -0.2827411890029907,\n",
       "  -1.3413333892822266,\n",
       "  -0.13402971625328064,\n",
       "  0.07052887231111526,\n",
       "  -0.6914217472076416,\n",
       "  -0.056977737694978714,\n",
       "  0.08615285903215408,\n",
       "  -0.23085452616214752,\n",
       "  0.460419237613678,\n",
       "  0.7956045269966125,\n",
       "  0.3772701323032379,\n",
       "  -0.19755510985851288,\n",
       "  -1.7860207557678223,\n",
       "  0.6352857351303101,\n",
       "  0.039055902510881424,\n",
       "  -0.30562862753868103,\n",
       "  -1.0513406991958618,\n",
       "  -1.261817216873169,\n",
       "  -0.03972509875893593,\n",
       "  -1.12368643283844,\n",
       "  -0.9232870936393738,\n",
       "  0.5584235191345215,\n",
       "  -0.04115595668554306,\n",
       "  -0.09763065725564957,\n",
       "  0.6378311514854431,\n",
       "  1.268212914466858,\n",
       "  0.8583604097366333,\n",
       "  -0.2739948630332947,\n",
       "  -0.019364643841981888,\n",
       "  0.8680413961410522,\n",
       "  0.6478082537651062,\n",
       "  -0.6450585722923279,\n",
       "  -0.4016840159893036,\n",
       "  -1.2573447227478027,\n",
       "  1.4290746450424194,\n",
       "  0.32772940397262573,\n",
       "  -0.7948550581932068,\n",
       "  0.6839030385017395,\n",
       "  1.448806643486023,\n",
       "  -0.4473227858543396,\n",
       "  -0.11941312253475189,\n",
       "  1.5912643671035767,\n",
       "  0.5280860662460327,\n",
       "  0.4523899257183075,\n",
       "  -1.5019543170928955,\n",
       "  -0.11070962250232697,\n",
       "  -0.3451181650161743,\n",
       "  -0.09698765724897385,\n",
       "  0.7159489989280701,\n",
       "  0.5060527324676514,\n",
       "  -1.0716689825057983,\n",
       "  0.6371404528617859,\n",
       "  -1.4368233680725098,\n",
       "  -0.7147471308708191,\n",
       "  -0.5795784592628479,\n",
       "  0.4172072410583496,\n",
       "  0.8052682876586914,\n",
       "  0.4731942415237427,\n",
       "  -0.8303520679473877,\n",
       "  0.9867832064628601,\n",
       "  0.5039276480674744,\n",
       "  -0.8633431196212769,\n",
       "  -0.1894151121377945,\n",
       "  -0.3201891779899597,\n",
       "  -0.3723387122154236,\n",
       "  -0.36844488978385925,\n",
       "  0.44518694281578064,\n",
       "  -0.4115259349346161,\n",
       "  0.15836496651172638,\n",
       "  1.0039143562316895,\n",
       "  -0.6516207456588745,\n",
       "  -1.0226401090621948,\n",
       "  -0.40603330731391907,\n",
       "  -0.01206947211176157,\n",
       "  0.01792364940047264,\n",
       "  0.7848408222198486,\n",
       "  0.9689167141914368,\n",
       "  0.5476568341255188,\n",
       "  -0.1855144500732422,\n",
       "  0.11753524839878082,\n",
       "  -0.15436530113220215,\n",
       "  -0.24178831279277802,\n",
       "  2.259841203689575,\n",
       "  0.19985194504261017,\n",
       "  0.9386550784111023,\n",
       "  2.18548583984375,\n",
       "  -0.14953221380710602,\n",
       "  0.6958175301551819,\n",
       "  -1.2729911804199219,\n",
       "  0.30697405338287354,\n",
       "  -0.193930983543396,\n",
       "  0.23331376910209656,\n",
       "  -0.03428679704666138,\n",
       "  0.01614851877093315,\n",
       "  0.3104041516780853,\n",
       "  1.286163091659546,\n",
       "  -0.3895758390426636,\n",
       "  0.83771151304245,\n",
       "  -0.3576473891735077,\n",
       "  -1.6707720756530762,\n",
       "  -0.6408941745758057,\n",
       "  -0.2049487829208374,\n",
       "  0.18853944540023804,\n",
       "  -2.1170990467071533,\n",
       "  0.4394288659095764,\n",
       "  -1.0021344423294067,\n",
       "  0.16966202855110168,\n",
       "  0.8604320287704468,\n",
       "  -0.22565817832946777,\n",
       "  0.08514931797981262,\n",
       "  -0.6377639770507812,\n",
       "  0.8594900965690613,\n",
       "  -1.0785536766052246,\n",
       "  0.08991825580596924,\n",
       "  -0.09713326394557953,\n",
       "  -1.3326719999313354,\n",
       "  0.967808723449707,\n",
       "  -0.1333334892988205,\n",
       "  -0.6737678050994873,\n",
       "  0.19274969398975372,\n",
       "  0.7614172697067261,\n",
       "  0.20615220069885254,\n",
       "  -1.4896306991577148,\n",
       "  -0.71359783411026,\n",
       "  0.4344363212585449,\n",
       "  0.6863661408424377,\n",
       "  0.20231084525585175,\n",
       "  -1.2087875604629517,\n",
       "  0.4193990230560303,\n",
       "  1.3792412281036377,\n",
       "  -1.7645938396453857,\n",
       "  0.5365091562271118,\n",
       "  -1.2639312744140625,\n",
       "  0.7760234475135803,\n",
       "  -1.4914004802703857,\n",
       "  -0.2638087570667267,\n",
       "  0.21576613187789917,\n",
       "  0.44951435923576355,\n",
       "  -0.15245577692985535,\n",
       "  -1.2970750331878662,\n",
       "  0.5318872332572937,\n",
       "  -0.5387690663337708,\n",
       "  0.12893910706043243,\n",
       "  0.40404486656188965,\n",
       "  -0.051749102771282196,\n",
       "  0.5621098279953003,\n",
       "  0.6083804368972778,\n",
       "  -0.8774632811546326,\n",
       "  -0.7465337514877319,\n",
       "  0.9466308951377869,\n",
       "  -1.08622407913208,\n",
       "  0.5396193861961365,\n",
       "  -0.5406872034072876,\n",
       "  1.3841018676757812,\n",
       "  0.5092250108718872,\n",
       "  0.9283649921417236,\n",
       "  0.44977277517318726,\n",
       "  0.8962411284446716,\n",
       "  0.5589155554771423,\n",
       "  -0.6870251297950745,\n",
       "  -0.023673387244343758,\n",
       "  -0.11839049309492111,\n",
       "  0.34504786133766174,\n",
       "  1.9699097871780396,\n",
       "  -0.4586862027645111,\n",
       "  -1.5847116708755493,\n",
       "  -0.06835588812828064,\n",
       "  -0.6620163917541504,\n",
       "  -0.03149261325597763,\n",
       "  -0.43398013710975647,\n",
       "  0.4114474058151245,\n",
       "  0.17512066662311554,\n",
       "  -0.11331960558891296,\n",
       "  0.511317253112793,\n",
       "  -0.04602227360010147,\n",
       "  -0.4383625388145447,\n",
       "  -0.10859739780426025,\n",
       "  0.055974602699279785,\n",
       "  0.7802956700325012,\n",
       "  -0.0889681801199913,\n",
       "  -0.5351454615592957,\n",
       "  -1.0946017503738403,\n",
       "  -0.08098442852497101,\n",
       "  0.7722717523574829,\n",
       "  -0.36493876576423645,\n",
       "  0.9538620114326477,\n",
       "  0.07157786935567856,\n",
       "  -0.1479487419128418,\n",
       "  1.1641038656234741,\n",
       "  -0.6551645398139954,\n",
       "  -0.5194012522697449,\n",
       "  -0.06912064552307129,\n",
       "  0.8731905817985535,\n",
       "  -0.1965242475271225,\n",
       "  2.0795769691467285,\n",
       "  1.2166450023651123,\n",
       "  -1.0102674961090088,\n",
       "  0.09187540411949158,\n",
       "  -0.021481765434145927,\n",
       "  0.9156087040901184,\n",
       "  2.0349783897399902,\n",
       "  -0.3756314814090729,\n",
       "  -0.49759501218795776,\n",
       "  0.43153679370880127,\n",
       "  0.37931278347969055,\n",
       "  0.4397813379764557,\n",
       "  -0.674240231513977,\n",
       "  -0.7734977602958679,\n",
       "  -0.23315215110778809,\n",
       "  0.7113113403320312,\n",
       "  0.38654395937919617,\n",
       "  -1.0120822191238403,\n",
       "  -0.3582417368888855,\n",
       "  0.11750047653913498,\n",
       "  -0.8749427795410156,\n",
       "  -0.5587165355682373,\n",
       "  1.0913574695587158,\n",
       "  -0.6690704226493835,\n",
       "  -1.6386194229125977,\n",
       "  0.23791511356830597,\n",
       "  -0.2624889314174652,\n",
       "  0.38699811697006226,\n",
       "  0.7405089139938354,\n",
       "  -0.635432779788971,\n",
       "  1.5774918794631958,\n",
       "  0.12916505336761475,\n",
       "  -0.36098721623420715,\n",
       "  0.7645881772041321,\n",
       "  1.4330428838729858,\n",
       "  -0.20483560860157013,\n",
       "  -0.7683521509170532,\n",
       "  -0.39581018686294556,\n",
       "  0.07555300742387772,\n",
       "  0.17629720270633698,\n",
       "  0.9118668437004089,\n",
       "  1.0963935852050781,\n",
       "  -1.8060108423233032,\n",
       "  -0.498945027589798,\n",
       "  1.0067315101623535,\n",
       "  0.23468761146068573,\n",
       "  1.0018543004989624,\n",
       "  0.01584736816585064,\n",
       "  0.8472015857696533,\n",
       "  1.8299436569213867,\n",
       "  -1.8841127157211304,\n",
       "  -0.764342725276947,\n",
       "  -0.164032980799675,\n",
       "  0.692728579044342,\n",
       "  0.9196455478668213,\n",
       "  0.08042579144239426,\n",
       "  1.295418620109558,\n",
       "  -1.79402756690979,\n",
       "  0.35153234004974365,\n",
       "  -0.1380860060453415,\n",
       "  -0.7910464406013489,\n",
       "  0.7868033051490784,\n",
       "  -0.15179964900016785,\n",
       "  0.9656144380569458,\n",
       "  2.0861549377441406,\n",
       "  -0.9226036667823792,\n",
       "  -0.599155604839325,\n",
       "  0.8124890327453613,\n",
       "  -0.4785442054271698,\n",
       "  0.14224743843078613,\n",
       "  0.13202691078186035,\n",
       "  -0.6970706582069397,\n",
       "  -0.020212553441524506,\n",
       "  0.6595953702926636,\n",
       "  1.0526931285858154,\n",
       "  -0.48665323853492737,\n",
       "  -0.23136046528816223,\n",
       "  -0.2310693860054016,\n",
       "  -1.8835288286209106,\n",
       "  0.12542735040187836,\n",
       "  -0.4382186233997345,\n",
       "  0.2903217077255249,\n",
       "  0.11095844954252243,\n",
       "  -0.710777223110199,\n",
       "  -0.44311490654945374,\n",
       "  0.0709930881857872,\n",
       "  1.1366099119186401,\n",
       "  1.0750868320465088,\n",
       "  -0.5545338988304138,\n",
       "  -1.0137399435043335,\n",
       "  0.15129117667675018,\n",
       "  0.6706896424293518,\n",
       "  -0.1338757574558258,\n",
       "  0.6375172138214111,\n",
       "  0.5359623432159424,\n",
       "  0.6387481093406677,\n",
       "  -0.683908224105835,\n",
       "  -0.2922416031360626,\n",
       "  1.030909538269043,\n",
       "  1.291778802871704,\n",
       "  0.27070051431655884,\n",
       "  -0.5610662698745728,\n",
       "  -0.8687320351600647,\n",
       "  -1.1758683919906616,\n",
       "  0.5365082025527954,\n",
       "  -0.28817594051361084,\n",
       "  0.516899585723877,\n",
       "  0.4390659034252167,\n",
       "  0.7485194206237793,\n",
       "  0.7735916376113892,\n",
       "  -0.10585891455411911,\n",
       "  -0.029941581189632416,\n",
       "  0.41855111718177795,\n",
       "  -0.7146964073181152,\n",
       "  0.46557047963142395,\n",
       "  0.5005373954772949,\n",
       "  -0.15002354979515076,\n",
       "  -0.38405925035476685,\n",
       "  0.7798268795013428,\n",
       "  -1.152783751487732,\n",
       "  0.9554247260093689,\n",
       "  0.36886876821517944,\n",
       "  -1.5152106285095215,\n",
       "  -0.12297407537698746,\n",
       "  -0.37248820066452026,\n",
       "  0.22268927097320557,\n",
       "  -0.29103803634643555,\n",
       "  -0.33088940382003784,\n",
       "  -0.7324842810630798,\n",
       "  0.761879563331604,\n",
       "  -0.6425495147705078,\n",
       "  -1.287527322769165,\n",
       "  0.49500417709350586,\n",
       "  -0.08196656405925751,\n",
       "  -0.14865750074386597,\n",
       "  0.25627022981643677,\n",
       "  0.47415027022361755,\n",
       "  0.06812050193548203,\n",
       "  1.0484251976013184,\n",
       "  -0.15370608866214752,\n",
       "  -0.3041733503341675,\n",
       "  -0.5254188776016235,\n",
       "  -0.22700640559196472,\n",
       "  -1.2729905843734741,\n",
       "  -0.39487358927726746,\n",
       "  1.7435797452926636,\n",
       "  -1.8775973320007324,\n",
       "  -1.5174591541290283,\n",
       "  -0.32414013147354126,\n",
       "  0.564760148525238,\n",
       "  -0.9397574067115784,\n",
       "  0.6349375247955322,\n",
       "  0.4245986342430115,\n",
       "  -0.6264091730117798,\n",
       "  -1.024376392364502,\n",
       "  0.8622399568557739,\n",
       "  0.5878339409828186,\n",
       "  0.4637056291103363,\n",
       "  1.218308448791504,\n",
       "  1.1967827081680298,\n",
       "  -0.3720599412918091,\n",
       "  -0.13077981770038605,\n",
       "  0.1632450670003891,\n",
       "  0.2765491008758545,\n",
       "  -0.44544318318367004,\n",
       "  -0.03270062804222107,\n",
       "  -0.4328274130821228,\n",
       "  -0.2701200246810913,\n",
       "  -0.5783190727233887,\n",
       "  0.08751189708709717,\n",
       "  0.012506292201578617,\n",
       "  -0.17794576287269592,\n",
       "  1.6007460355758667,\n",
       "  -1.1985394954681396,\n",
       "  -0.07381536066532135,\n",
       "  0.08239231258630753,\n",
       "  -0.5306231379508972,\n",
       "  -1.1376845836639404,\n",
       "  0.7251242399215698,\n",
       "  -0.6938712000846863,\n",
       "  0.39113232493400574,\n",
       "  -0.60049968957901,\n",
       "  0.43218350410461426,\n",
       "  0.0071375565603375435,\n",
       "  -0.22118711471557617,\n",
       "  -0.19985567033290863,\n",
       "  -0.6006633043289185,\n",
       "  -0.21711070835590363,\n",
       "  -0.649273157119751,\n",
       "  0.3838343620300293,\n",
       "  0.07844150066375732,\n",
       "  -0.3456592261791229,\n",
       "  -0.8504737615585327,\n",
       "  -0.46470871567726135,\n",
       "  -1.443630337715149,\n",
       "  0.1577368527650833,\n",
       "  0.4715119004249573,\n",
       "  1.5583488941192627,\n",
       "  -1.6464840173721313,\n",
       "  -0.38604167103767395,\n",
       "  1.4023919105529785,\n",
       "  -0.10471536964178085,\n",
       "  -0.6159970760345459,\n",
       "  -0.5510141849517822,\n",
       "  -0.7092422246932983,\n",
       "  0.7276144027709961,\n",
       "  -0.028743965551257133,\n",
       "  -0.5465503334999084,\n",
       "  -0.42607906460762024,\n",
       "  0.9778393507003784,\n",
       "  0.05831615626811981,\n",
       "  1.2725892066955566,\n",
       "  0.697324812412262,\n",
       "  -0.2641623616218567,\n",
       "  -0.11817625164985657,\n",
       "  -0.228709414601326,\n",
       "  -1.0863027572631836,\n",
       "  0.9735797643661499,\n",
       "  -0.4161287844181061,\n",
       "  0.952299952507019,\n",
       "  -0.2978381812572479,\n",
       "  -2.057706117630005,\n",
       "  -0.6619875431060791,\n",
       "  0.24264872074127197,\n",
       "  1.1534454822540283,\n",
       "  -0.884783148765564,\n",
       "  0.9762126207351685,\n",
       "  -1.791325569152832,\n",
       "  -1.4984172582626343,\n",
       "  -0.5375934839248657,\n",
       "  -0.629931628704071,\n",
       "  -1.4194767475128174,\n",
       "  -1.1128894090652466,\n",
       "  -0.34243395924568176,\n",
       "  0.870216429233551,\n",
       "  1.259622573852539,\n",
       "  -0.43627235293388367,\n",
       "  -0.14758558571338654,\n",
       "  0.4165596663951874,\n",
       "  0.03894011676311493,\n",
       "  0.005603776313364506,\n",
       "  1.2452969551086426,\n",
       "  0.7019366025924683,\n",
       "  1.1577118635177612,\n",
       "  -0.9477331042289734,\n",
       "  2.2466511726379395,\n",
       "  1.660119891166687,\n",
       "  -0.40706372261047363,\n",
       "  0.3939093053340912,\n",
       "  1.3679784536361694,\n",
       "  -1.4615727663040161,\n",
       "  0.6436914801597595,\n",
       "  -1.8641868829727173,\n",
       "  -0.6162028908729553,\n",
       "  -0.9968710541725159,\n",
       "  -0.04276501387357712,\n",
       "  -0.7134620547294617,\n",
       "  -0.07681193947792053,\n",
       "  0.514995813369751,\n",
       "  0.30907827615737915,\n",
       "  -0.4127793610095978,\n",
       "  0.34023505449295044,\n",
       "  -0.5584483742713928,\n",
       "  -1.0774493217468262,\n",
       "  -0.1069253534078598,\n",
       "  0.8219823837280273,\n",
       "  0.5627779364585876,\n",
       "  0.7784462571144104,\n",
       "  -0.02260006032884121,\n",
       "  0.25267401337623596,\n",
       "  0.8264483213424683,\n",
       "  -0.09313119202852249,\n",
       "  1.167733073234558,\n",
       "  0.46359193325042725,\n",
       "  -1.5362520217895508,\n",
       "  0.046547550708055496,\n",
       "  -0.9385424852371216,\n",
       "  -1.165169596672058,\n",
       "  -0.07086627930402756,\n",
       "  -0.41476011276245117,\n",
       "  -1.4201099872589111,\n",
       "  1.059219479560852,\n",
       "  -0.9906155467033386,\n",
       "  -0.40455949306488037,\n",
       "  -0.47995609045028687,\n",
       "  0.02229311130940914,\n",
       "  -1.2449365854263306,\n",
       "  0.9563578963279724,\n",
       "  -0.26429998874664307,\n",
       "  -0.7607954144477844,\n",
       "  -0.5799292325973511,\n",
       "  0.1733117550611496,\n",
       "  -0.07181470096111298,\n",
       "  0.09323462843894958,\n",
       "  1.5738991498947144,\n",
       "  0.24332286417484283,\n",
       "  0.9944661855697632,\n",
       "  0.40117383003234863,\n",
       "  0.5818399786949158,\n",
       "  -0.7213674187660217,\n",
       "  -1.4949895143508911,\n",
       "  -0.003305322490632534,\n",
       "  -0.07167787104845047,\n",
       "  -0.8126658201217651,\n",
       "  -0.3715140223503113,\n",
       "  0.17947782576084137,\n",
       "  1.6125702857971191,\n",
       "  0.02338242158293724,\n",
       "  0.21330079436302185,\n",
       "  0.6061869859695435,\n",
       "  0.5184757709503174,\n",
       "  -0.573918342590332,\n",
       "  0.3538607656955719,\n",
       "  -0.40031662583351135,\n",
       "  0.532241940498352,\n",
       "  0.4983147978782654,\n",
       "  -0.0490444041788578,\n",
       "  -1.5972028970718384,\n",
       "  -0.44662272930145264,\n",
       "  -0.01762719638645649,\n",
       "  -0.38371098041534424,\n",
       "  0.7917308211326599,\n",
       "  -0.3001037836074829,\n",
       "  1.4227688312530518,\n",
       "  0.23816856741905212,\n",
       "  -0.037762511521577835,\n",
       "  0.7501430511474609,\n",
       "  -1.3761910200119019,\n",
       "  0.5356625914573669,\n",
       "  -0.0021052968222647905,\n",
       "  0.20223841071128845,\n",
       "  -0.7869229912757874,\n",
       "  -0.06099448353052139,\n",
       "  -0.40970727801322937,\n",
       "  -0.2703251242637634,\n",
       "  -0.6483051180839539,\n",
       "  0.04393310844898224,\n",
       "  0.13650880753993988,\n",
       "  -0.021647984161973,\n",
       "  -0.4388214945793152,\n",
       "  -0.6657382845878601,\n",
       "  -0.4338303506374359,\n",
       "  -0.202556774020195,\n",
       "  0.5768231153488159,\n",
       "  0.19250573217868805,\n",
       "  -0.12024237215518951,\n",
       "  0.10487272590398788,\n",
       "  -1.0335361957550049,\n",
       "  -0.3242493271827698,\n",
       "  -0.44424834847450256,\n",
       "  0.06914693117141724,\n",
       "  -0.8314264416694641,\n",
       "  2.3469016551971436,\n",
       "  0.4294325113296509,\n",
       "  0.13899381458759308,\n",
       "  0.903292179107666,\n",
       "  -0.2651185095310211,\n",
       "  1.4734960794448853,\n",
       "  -0.8999943137168884,\n",
       "  -1.0070809125900269,\n",
       "  -1.0136793851852417,\n",
       "  -1.133154034614563,\n",
       "  -0.012828817591071129],\n",
       " [0.5105383396148682,\n",
       "  1.3752578496932983,\n",
       "  -3.4325971603393555,\n",
       "  -0.9706447124481201,\n",
       "  0.20265847444534302,\n",
       "  0.2716697156429291,\n",
       "  1.3474847078323364,\n",
       "  0.105655737221241,\n",
       "  -1.6053335666656494,\n",
       "  -0.23773923516273499,\n",
       "  -0.08341661840677261,\n",
       "  1.4840657711029053,\n",
       "  0.7200313210487366,\n",
       "  1.0463334321975708,\n",
       "  -0.120165154337883,\n",
       "  0.32194799184799194,\n",
       "  0.2506813704967499,\n",
       "  -0.5380688309669495,\n",
       "  0.3000168204307556,\n",
       "  0.9482163190841675,\n",
       "  0.5724181532859802,\n",
       "  -0.980958878993988,\n",
       "  -1.5783207416534424,\n",
       "  0.23625345528125763,\n",
       "  2.8679604530334473,\n",
       "  1.0325438976287842,\n",
       "  0.095655158162117,\n",
       "  -0.055943965911865234,\n",
       "  -1.0645948648452759,\n",
       "  -0.23465658724308014,\n",
       "  1.4131418466567993,\n",
       "  -0.5669636130332947,\n",
       "  0.02757437713444233,\n",
       "  -0.7055858373641968,\n",
       "  -2.3620269298553467,\n",
       "  -1.8770084381103516,\n",
       "  0.2921012341976166,\n",
       "  0.30524951219558716,\n",
       "  -0.3221437633037567,\n",
       "  1.0418344736099243,\n",
       "  0.8847312331199646,\n",
       "  -0.47599589824676514,\n",
       "  -0.2857835292816162,\n",
       "  -0.7452163696289062,\n",
       "  1.0341132879257202,\n",
       "  0.8260596990585327,\n",
       "  -0.2797149419784546,\n",
       "  -1.5384716987609863,\n",
       "  0.7368186116218567,\n",
       "  -0.7000340819358826,\n",
       "  0.9312517642974854,\n",
       "  -0.8056110739707947,\n",
       "  0.2110673487186432,\n",
       "  -1.1237070560455322,\n",
       "  0.9507207274436951,\n",
       "  1.1569864749908447,\n",
       "  0.06596999615430832,\n",
       "  0.5475965738296509,\n",
       "  -0.10062865912914276,\n",
       "  -0.3366190791130066,\n",
       "  2.4942402839660645,\n",
       "  1.8479527235031128,\n",
       "  0.0007562027312815189,\n",
       "  1.569445252418518,\n",
       "  1.667184829711914,\n",
       "  -0.7836428284645081,\n",
       "  0.5820566415786743,\n",
       "  1.9224601984024048,\n",
       "  -0.8703009486198425,\n",
       "  0.21173757314682007,\n",
       "  1.1933767795562744,\n",
       "  -0.360479474067688,\n",
       "  0.923413097858429,\n",
       "  -0.9237878918647766,\n",
       "  -0.06144382804632187,\n",
       "  -1.2400561571121216,\n",
       "  -1.3230886459350586,\n",
       "  -0.8920378088951111,\n",
       "  0.37436044216156006,\n",
       "  1.3220747709274292,\n",
       "  -0.06744566559791565,\n",
       "  0.3499799370765686,\n",
       "  1.8132925033569336,\n",
       "  -0.2317245602607727,\n",
       "  0.9242118000984192,\n",
       "  0.4730722904205322,\n",
       "  -0.5889033079147339,\n",
       "  -0.8392823338508606,\n",
       "  -0.25900915265083313,\n",
       "  0.52247154712677,\n",
       "  -0.7855512499809265,\n",
       "  0.815535843372345,\n",
       "  0.8428214192390442,\n",
       "  0.25005286931991577,\n",
       "  0.5291638374328613,\n",
       "  -0.10575058311223984,\n",
       "  0.7223858833312988,\n",
       "  0.4118056893348694,\n",
       "  -0.6912664771080017,\n",
       "  -1.760960340499878,\n",
       "  0.05274350196123123,\n",
       "  -0.5674536228179932,\n",
       "  0.4177868366241455,\n",
       "  -0.34234124422073364,\n",
       "  1.0222541093826294,\n",
       "  1.4773856401443481,\n",
       "  -0.26911085844039917,\n",
       "  -0.13480757176876068,\n",
       "  -1.1944340467453003,\n",
       "  0.20700548589229584,\n",
       "  0.1703098565340042,\n",
       "  0.31255295872688293,\n",
       "  0.04685431718826294,\n",
       "  -1.2844570875167847,\n",
       "  0.632432758808136,\n",
       "  0.4150158166885376,\n",
       "  1.8856996297836304,\n",
       "  -0.7652059197425842,\n",
       "  0.5898734331130981,\n",
       "  0.9407964944839478,\n",
       "  -1.343901515007019,\n",
       "  -0.2077295035123825,\n",
       "  -0.23904556035995483,\n",
       "  1.005678415298462,\n",
       "  1.2386821508407593,\n",
       "  1.0789425373077393,\n",
       "  -1.77426278591156,\n",
       "  0.06655429303646088,\n",
       "  -0.030048495158553123,\n",
       "  0.2197807878255844,\n",
       "  0.5540170669555664,\n",
       "  -0.6983027458190918,\n",
       "  -0.8517918586730957,\n",
       "  0.6088617444038391,\n",
       "  0.21817277371883392,\n",
       "  0.24247197806835175,\n",
       "  -0.2609819769859314,\n",
       "  -0.9275295734405518,\n",
       "  0.21757984161376953,\n",
       "  0.7087240219116211,\n",
       "  0.33827459812164307,\n",
       "  -0.5474690198898315,\n",
       "  -0.1993597000837326,\n",
       "  -0.736987829208374,\n",
       "  0.11470243334770203,\n",
       "  -0.6014731526374817,\n",
       "  1.3925716876983643,\n",
       "  -0.06587452441453934,\n",
       "  0.08224278688430786,\n",
       "  -0.7970892190933228,\n",
       "  -1.0481562614440918,\n",
       "  1.110256314277649,\n",
       "  -0.07954417914152145,\n",
       "  0.7959055304527283,\n",
       "  0.6804941296577454,\n",
       "  -0.6457386612892151,\n",
       "  0.5740222334861755,\n",
       "  -0.05808142200112343,\n",
       "  -0.2444533109664917,\n",
       "  1.3289567232131958,\n",
       "  1.3839974403381348,\n",
       "  -0.3031793236732483,\n",
       "  -0.8491060733795166,\n",
       "  1.4640796184539795,\n",
       "  -1.153325080871582,\n",
       "  -1.289239764213562,\n",
       "  0.34624969959259033,\n",
       "  0.7205833792686462,\n",
       "  1.0738211870193481,\n",
       "  0.8190290331840515,\n",
       "  -0.4932197034358978,\n",
       "  -1.1906378269195557,\n",
       "  -1.258433222770691,\n",
       "  -0.28764021396636963,\n",
       "  -0.3272245228290558,\n",
       "  -0.3150402903556824,\n",
       "  0.2528265416622162,\n",
       "  -1.019771933555603,\n",
       "  0.8182318210601807,\n",
       "  -0.9380451440811157,\n",
       "  -0.12288229167461395,\n",
       "  -0.36804211139678955,\n",
       "  0.943307638168335,\n",
       "  1.057314395904541,\n",
       "  -0.5493959188461304,\n",
       "  -0.8294624090194702,\n",
       "  -0.6379357576370239,\n",
       "  0.5208480358123779,\n",
       "  -0.5480058193206787,\n",
       "  -0.0718972235918045,\n",
       "  -1.6087814569473267,\n",
       "  0.9019330739974976,\n",
       "  -1.0996127128601074,\n",
       "  -1.0178844928741455,\n",
       "  -1.0841648578643799,\n",
       "  -0.6143607497215271,\n",
       "  1.061528205871582,\n",
       "  -0.3521832823753357,\n",
       "  0.39535582065582275,\n",
       "  -1.007751226425171,\n",
       "  -0.6979573965072632,\n",
       "  -0.2412874549627304,\n",
       "  -1.4521043300628662,\n",
       "  0.010311547666788101,\n",
       "  -0.9802883267402649,\n",
       "  0.27446767687797546,\n",
       "  -0.4715355634689331,\n",
       "  0.542241096496582,\n",
       "  -0.6942560076713562,\n",
       "  0.994605302810669,\n",
       "  1.4983552694320679,\n",
       "  0.7487748861312866,\n",
       "  -0.5195649266242981,\n",
       "  -0.18887700140476227,\n",
       "  0.4504780173301697,\n",
       "  -1.6578189134597778,\n",
       "  -0.34528428316116333,\n",
       "  -1.1471080780029297,\n",
       "  -0.7562881112098694,\n",
       "  0.6138152480125427,\n",
       "  1.184726595878601,\n",
       "  -1.0132306814193726,\n",
       "  1.1633732318878174,\n",
       "  -0.47162413597106934,\n",
       "  -0.13950346410274506,\n",
       "  0.15485148131847382,\n",
       "  -0.8169605731964111,\n",
       "  -0.3597128093242645,\n",
       "  -1.5556203126907349,\n",
       "  0.3007020652294159,\n",
       "  -1.0756961107254028,\n",
       "  -1.322450041770935,\n",
       "  0.323982834815979,\n",
       "  1.0963082313537598,\n",
       "  -0.35114845633506775,\n",
       "  0.050451721996068954,\n",
       "  -0.0441659651696682,\n",
       "  0.709748387336731,\n",
       "  0.7110635042190552,\n",
       "  1.1355994939804077,\n",
       "  0.38361185789108276,\n",
       "  1.29017972946167,\n",
       "  -0.9552237391471863,\n",
       "  -0.9939910173416138,\n",
       "  -1.375942349433899,\n",
       "  0.45295506715774536,\n",
       "  0.08102114498615265,\n",
       "  -0.14522339403629303,\n",
       "  0.22651921212673187,\n",
       "  0.9243015646934509,\n",
       "  0.4322635531425476,\n",
       "  -0.9581992030143738,\n",
       "  0.2974911630153656,\n",
       "  0.7230510711669922,\n",
       "  0.23094229400157928,\n",
       "  -1.4027621746063232,\n",
       "  0.23746822774410248,\n",
       "  -0.5421631336212158,\n",
       "  -0.07541979104280472,\n",
       "  0.1414325088262558,\n",
       "  0.5248588919639587,\n",
       "  -1.4658970832824707,\n",
       "  0.397582083940506,\n",
       "  -0.371489942073822,\n",
       "  0.5732792019844055,\n",
       "  -0.13220781087875366,\n",
       "  0.3351260721683502,\n",
       "  -0.201833114027977,\n",
       "  0.5790624022483826,\n",
       "  0.3238201439380646,\n",
       "  0.2536458373069763,\n",
       "  0.4355979263782501,\n",
       "  0.23462674021720886,\n",
       "  1.1598013639450073,\n",
       "  0.4570460319519043,\n",
       "  -1.3660873174667358,\n",
       "  0.5169962644577026,\n",
       "  0.5268750786781311,\n",
       "  -0.059140659868717194,\n",
       "  0.7699823379516602,\n",
       "  -0.6696375608444214,\n",
       "  -1.4187936782836914,\n",
       "  -0.8315146565437317,\n",
       "  -0.8095812797546387,\n",
       "  0.33367305994033813,\n",
       "  0.1399475783109665,\n",
       "  1.0451428890228271,\n",
       "  0.8663779497146606,\n",
       "  0.22940537333488464,\n",
       "  -0.1418641060590744,\n",
       "  0.6536663174629211,\n",
       "  -0.5696428418159485,\n",
       "  -0.7686097025871277,\n",
       "  0.7804906964302063,\n",
       "  0.6360096335411072,\n",
       "  0.5716860890388489,\n",
       "  1.6231293678283691,\n",
       "  -0.24943439662456512,\n",
       "  0.7336416840553284,\n",
       "  -0.8300354480743408,\n",
       "  0.34683266282081604,\n",
       "  0.6156578660011292,\n",
       "  0.6090651750564575,\n",
       "  0.7539504170417786,\n",
       "  -1.275510549545288,\n",
       "  -0.530902624130249,\n",
       "  -0.22931325435638428,\n",
       "  -0.7812637686729431,\n",
       "  0.15026523172855377,\n",
       "  -0.9969882965087891,\n",
       "  -1.057904601097107,\n",
       "  -0.9402199983596802,\n",
       "  0.6914350390434265,\n",
       "  -0.2088802009820938,\n",
       "  -0.780604898929596,\n",
       "  1.1145066022872925,\n",
       "  -0.8014050126075745,\n",
       "  0.7336364984512329,\n",
       "  0.07940641790628433,\n",
       "  0.48220714926719666,\n",
       "  -0.8919311165809631,\n",
       "  -1.0506272315979004,\n",
       "  0.24821944534778595,\n",
       "  -1.0017677545547485,\n",
       "  -0.24118493497371674,\n",
       "  0.3425118029117584,\n",
       "  -0.75948566198349,\n",
       "  1.0297622680664062,\n",
       "  0.1340649127960205,\n",
       "  -0.6944918036460876,\n",
       "  -0.040665797889232635,\n",
       "  0.4330246150493622,\n",
       "  -0.029062118381261826,\n",
       "  -0.624273955821991,\n",
       "  -0.4500344395637512,\n",
       "  0.047052618116140366,\n",
       "  0.01882600039243698,\n",
       "  0.1043626219034195,\n",
       "  0.1752823442220688,\n",
       "  -0.054525986313819885,\n",
       "  2.2622246742248535,\n",
       "  0.04744524508714676,\n",
       "  -0.18797667324543,\n",
       "  -0.5633718371391296,\n",
       "  1.1197686195373535,\n",
       "  -0.6477279663085938,\n",
       "  -0.8826648592948914,\n",
       "  0.042047251015901566,\n",
       "  0.6393876075744629,\n",
       "  0.36359304189682007,\n",
       "  -1.0983870029449463,\n",
       "  -0.6742797493934631,\n",
       "  -0.8037424087524414,\n",
       "  0.23993822932243347,\n",
       "  0.23927466571331024,\n",
       "  0.3885505497455597,\n",
       "  -0.053299058228731155,\n",
       "  0.7902604341506958,\n",
       "  0.44734424352645874,\n",
       "  0.2579583525657654,\n",
       "  0.8831261396408081,\n",
       "  -1.0845633745193481,\n",
       "  0.8166059255599976,\n",
       "  -0.42180705070495605,\n",
       "  -0.2897551953792572,\n",
       "  0.965914785861969,\n",
       "  0.7611865401268005,\n",
       "  0.9066900610923767,\n",
       "  0.2672029733657837,\n",
       "  0.024074522778391838,\n",
       "  -0.6971426606178284,\n",
       "  -0.6486845016479492,\n",
       "  0.42620834708213806,\n",
       "  0.3055298924446106,\n",
       "  0.9792828559875488,\n",
       "  -0.8025882244110107,\n",
       "  -0.938288152217865,\n",
       "  -1.6935019493103027,\n",
       "  0.5280264616012573,\n",
       "  0.4571952521800995,\n",
       "  -0.5717823505401611,\n",
       "  -0.8182039856910706,\n",
       "  0.19403916597366333,\n",
       "  0.07934687286615372,\n",
       "  1.2557952404022217,\n",
       "  -1.2252789735794067,\n",
       "  -1.0671080350875854,\n",
       "  -0.03752921149134636,\n",
       "  0.060225438326597214,\n",
       "  0.9673741459846497,\n",
       "  -0.36353930830955505,\n",
       "  -0.8648173809051514,\n",
       "  -1.1527761220932007,\n",
       "  0.47831785678863525,\n",
       "  -0.10459922254085541,\n",
       "  -0.19914446771144867,\n",
       "  -0.35371077060699463,\n",
       "  0.1262010633945465,\n",
       "  0.2928689122200012,\n",
       "  0.3232802152633667,\n",
       "  -0.6260697841644287,\n",
       "  -0.6448107361793518,\n",
       "  0.3625977635383606,\n",
       "  0.1863585263490677,\n",
       "  0.6230900883674622,\n",
       "  1.7531439065933228,\n",
       "  0.9096660614013672,\n",
       "  -1.2196263074874878,\n",
       "  0.9330182671546936,\n",
       "  0.3972351551055908,\n",
       "  0.13418540358543396,\n",
       "  0.6319370269775391,\n",
       "  0.0799451395869255,\n",
       "  -1.440878987312317,\n",
       "  0.16352704167366028,\n",
       "  0.8257232308387756,\n",
       "  0.7048187255859375,\n",
       "  0.8115642070770264,\n",
       "  0.0841231718659401,\n",
       "  -0.06572892516851425,\n",
       "  0.6860679388046265,\n",
       "  0.553753137588501,\n",
       "  -0.712915301322937,\n",
       "  0.13474838435649872,\n",
       "  -0.26625481247901917,\n",
       "  0.007566304411739111,\n",
       "  -0.18723760545253754,\n",
       "  1.0350953340530396,\n",
       "  -1.0257760286331177,\n",
       "  -1.3860702514648438,\n",
       "  -0.603937029838562,\n",
       "  0.6993285417556763,\n",
       "  1.177722454071045,\n",
       "  1.270344614982605,\n",
       "  -0.23152491450309753,\n",
       "  0.9938835501670837,\n",
       "  0.5015689730644226,\n",
       "  0.23452778160572052,\n",
       "  0.5799625515937805,\n",
       "  1.6793999671936035,\n",
       "  0.31877216696739197,\n",
       "  -0.8305190801620483,\n",
       "  -0.831412672996521,\n",
       "  -0.9349801540374756,\n",
       "  0.39428403973579407,\n",
       "  2.8933749198913574,\n",
       "  1.324001431465149,\n",
       "  -1.7861416339874268,\n",
       "  -1.026829719543457,\n",
       "  1.079353928565979,\n",
       "  -0.04919658601284027,\n",
       "  1.410830020904541,\n",
       "  0.07751991599798203,\n",
       "  1.3816808462142944,\n",
       "  1.2535537481307983,\n",
       "  -1.5157253742218018,\n",
       "  -0.7934852242469788,\n",
       "  0.30355677008628845,\n",
       "  1.0753815174102783,\n",
       "  0.5518547892570496,\n",
       "  -0.7859189510345459,\n",
       "  0.7349361181259155,\n",
       "  -1.6338183879852295,\n",
       "  0.7379584908485413,\n",
       "  -0.11898685246706009,\n",
       "  0.03769523277878761,\n",
       "  0.8064020872116089,\n",
       "  -0.07518372684717178,\n",
       "  0.5859365463256836,\n",
       "  1.9285017251968384,\n",
       "  0.3731980621814728,\n",
       "  0.7879129648208618,\n",
       "  0.5157390832901001,\n",
       "  -1.0209343433380127,\n",
       "  0.26330995559692383,\n",
       "  0.953271746635437,\n",
       "  -0.6465689539909363,\n",
       "  -0.46198758482933044,\n",
       "  -0.46764662861824036,\n",
       "  1.792670488357544,\n",
       "  -0.49066486954689026,\n",
       "  0.053708478808403015,\n",
       "  -0.32817989587783813,\n",
       "  -0.9962676763534546,\n",
       "  0.18072116374969482,\n",
       "  0.10949093103408813,\n",
       "  0.03956383094191551,\n",
       "  0.5451825261116028,\n",
       "  -0.6183737516403198,\n",
       "  0.3442608714103699,\n",
       "  0.2599838972091675,\n",
       "  0.6913420557975769,\n",
       "  -0.1277487576007843,\n",
       "  -0.035123180598020554,\n",
       "  -0.42372843623161316,\n",
       "  -0.03661995753645897,\n",
       "  -0.1696135401725769,\n",
       "  0.528337836265564,\n",
       "  0.9876734614372253,\n",
       "  0.9041765332221985,\n",
       "  0.6680241823196411,\n",
       "  0.28612658381462097,\n",
       "  0.11149592697620392,\n",
       "  0.42997685074806213,\n",
       "  0.740227460861206,\n",
       "  -0.4810728430747986,\n",
       "  -0.29047536849975586,\n",
       "  -1.1261197328567505,\n",
       "  -1.7617712020874023,\n",
       "  0.31144917011260986,\n",
       "  -0.6385918259620667,\n",
       "  0.708411455154419,\n",
       "  0.14691506326198578,\n",
       "  1.895387887954712,\n",
       "  1.0292973518371582,\n",
       "  -0.41808992624282837,\n",
       "  0.29942962527275085,\n",
       "  0.5970648527145386,\n",
       "  -1.01493501663208,\n",
       "  0.2908271551132202,\n",
       "  0.61263108253479,\n",
       "  -0.3097953200340271,\n",
       "  -0.4846242368221283,\n",
       "  0.642512857913971,\n",
       "  -2.020505428314209,\n",
       "  0.42053285241127014,\n",
       "  0.6467677354812622,\n",
       "  -1.37385094165802,\n",
       "  0.9104928970336914,\n",
       "  -0.018616752699017525,\n",
       "  0.9519191384315491,\n",
       "  1.183582067489624,\n",
       "  -1.6832026243209839,\n",
       "  -0.5913077592849731,\n",
       "  -0.006123492028564215,\n",
       "  -1.093716025352478,\n",
       "  -1.6326457262039185,\n",
       "  -0.32543113827705383,\n",
       "  0.713843047618866,\n",
       "  0.8056944012641907,\n",
       "  -0.5928955674171448,\n",
       "  0.10912376642227173,\n",
       "  0.11075103282928467,\n",
       "  1.1367216110229492,\n",
       "  0.24446798861026764,\n",
       "  0.12860757112503052,\n",
       "  -0.3868533670902252,\n",
       "  0.6841300129890442,\n",
       "  -0.951410710811615,\n",
       "  -1.2617955207824707,\n",
       "  1.0442109107971191,\n",
       "  -1.5775558948516846,\n",
       "  -0.4952632784843445,\n",
       "  0.33766016364097595,\n",
       "  0.4561936557292938,\n",
       "  -1.1328855752944946,\n",
       "  1.0946844816207886,\n",
       "  0.11700106412172318,\n",
       "  -0.2207847386598587,\n",
       "  -0.3927450180053711,\n",
       "  0.32321470975875854,\n",
       "  0.15673285722732544,\n",
       "  1.146580457687378,\n",
       "  0.3632136285305023,\n",
       "  0.04811866208910942,\n",
       "  -1.339094638824463,\n",
       "  0.5401177406311035,\n",
       "  -0.2546174228191376,\n",
       "  -0.023073414340615273,\n",
       "  0.07961009442806244,\n",
       "  0.11733628809452057,\n",
       "  -1.0993282794952393,\n",
       "  -0.3324454128742218,\n",
       "  -0.26716148853302,\n",
       "  -0.16657771170139313,\n",
       "  -0.03687119111418724,\n",
       "  0.18457794189453125,\n",
       "  -0.47877243161201477,\n",
       "  -1.684828758239746,\n",
       "  -1.1267427206039429,\n",
       "  -0.9159397482872009,\n",
       "  -1.3064916133880615,\n",
       "  0.5078231692314148,\n",
       "  0.4047040641307831,\n",
       "  0.565837025642395,\n",
       "  0.16619296371936798,\n",
       "  -1.3764861822128296,\n",
       "  1.0799742937088013,\n",
       "  0.5579820871353149,\n",
       "  -0.7912842631340027,\n",
       "  -0.8388918042182922,\n",
       "  -0.2647817134857178,\n",
       "  0.07263641059398651,\n",
       "  -0.6646730303764343,\n",
       "  -0.38262301683425903,\n",
       "  0.7929781079292297,\n",
       "  -0.47460901737213135,\n",
       "  -0.8722904324531555,\n",
       "  -0.2940467298030853,\n",
       "  -0.5423420071601868,\n",
       "  -0.47799453139305115,\n",
       "  1.1892402172088623,\n",
       "  1.1802091598510742,\n",
       "  -1.170440673828125,\n",
       "  -0.15704703330993652,\n",
       "  0.6390060186386108,\n",
       "  -0.3848024606704712,\n",
       "  -0.7241174578666687,\n",
       "  -0.001561766373924911,\n",
       "  -2.108603000640869,\n",
       "  0.9104975461959839,\n",
       "  0.16243396699428558,\n",
       "  1.0736079216003418,\n",
       "  -0.17357483506202698,\n",
       "  1.474103331565857,\n",
       "  -0.175553098320961,\n",
       "  0.9922734498977661,\n",
       "  -1.3593618869781494,\n",
       "  0.14902515709400177,\n",
       "  -0.4360128939151764,\n",
       "  0.09112803637981415,\n",
       "  -1.296221375465393,\n",
       "  1.156523585319519,\n",
       "  -1.525037407875061,\n",
       "  1.4963622093200684,\n",
       "  0.06459368765354156,\n",
       "  -0.8474940657615662,\n",
       "  0.6019827723503113,\n",
       "  1.3181239366531372,\n",
       "  1.7506341934204102,\n",
       "  -0.7677643895149231,\n",
       "  0.4444141685962677,\n",
       "  -1.3343803882598877,\n",
       "  -1.1754851341247559,\n",
       "  0.31944987177848816,\n",
       "  0.040527425706386566,\n",
       "  -0.8638177514076233,\n",
       "  -0.8372789621353149,\n",
       "  0.07137223333120346,\n",
       "  0.9614095687866211,\n",
       "  0.8604186773300171,\n",
       "  -1.1623353958129883,\n",
       "  -0.17892126739025116,\n",
       "  -0.865800678730011,\n",
       "  0.6124404668807983,\n",
       "  -0.8991873860359192,\n",
       "  1.191772699356079,\n",
       "  -0.20832517743110657,\n",
       "  0.7804754376411438,\n",
       "  -1.0129270553588867,\n",
       "  1.3300341367721558,\n",
       "  1.723989486694336,\n",
       "  0.08179830759763718,\n",
       "  0.143788143992424,\n",
       "  0.4266550540924072,\n",
       "  -0.8053454756736755,\n",
       "  -0.029291760176420212,\n",
       "  -1.0100302696228027,\n",
       "  -0.3124352991580963,\n",
       "  -1.523851990699768,\n",
       "  -0.011754389852285385,\n",
       "  -0.21915355324745178,\n",
       "  -0.08201263844966888,\n",
       "  -0.44619104266166687,\n",
       "  0.36717742681503296,\n",
       "  -0.32752296328544617,\n",
       "  -0.5600002408027649,\n",
       "  0.03970307484269142,\n",
       "  -1.1271361112594604,\n",
       "  -0.6023520827293396,\n",
       "  0.09520751237869263,\n",
       "  0.8126767873764038,\n",
       "  0.9142878651618958,\n",
       "  0.556162416934967,\n",
       "  0.14630256593227386,\n",
       "  1.4312222003936768,\n",
       "  0.032918643206357956,\n",
       "  0.26762232184410095,\n",
       "  -1.4532042741775513,\n",
       "  -1.2839667797088623,\n",
       "  -0.39127373695373535,\n",
       "  -1.1245040893554688,\n",
       "  0.2889409363269806,\n",
       "  0.2447788119316101,\n",
       "  0.8118202090263367,\n",
       "  -1.1502763032913208,\n",
       "  0.48408418893814087,\n",
       "  -0.4369272291660309,\n",
       "  -0.11372774839401245,\n",
       "  -0.41540271043777466,\n",
       "  0.5843859314918518,\n",
       "  -1.8056761026382446,\n",
       "  0.48003143072128296,\n",
       "  -0.9617745280265808,\n",
       "  -0.48083189129829407,\n",
       "  0.343551903963089,\n",
       "  -0.8885239958763123,\n",
       "  -0.40986111760139465,\n",
       "  -0.42085835337638855,\n",
       "  1.7480107545852661,\n",
       "  -0.18396858870983124,\n",
       "  0.9788273572921753,\n",
       "  0.4638931453227997,\n",
       "  1.5235174894332886,\n",
       "  -1.2375093698501587,\n",
       "  -0.09855412691831589,\n",
       "  -0.7911772727966309,\n",
       "  0.15712566673755646,\n",
       "  -0.20668435096740723,\n",
       "  0.18101179599761963,\n",
       "  -0.05379021167755127,\n",
       "  -0.07731148600578308,\n",
       "  0.1966310441493988,\n",
       "  0.5256878137588501,\n",
       "  0.8005873560905457,\n",
       "  0.6637232899665833,\n",
       "  0.052750322967767715,\n",
       "  -1.204704999923706,\n",
       "  -0.8993051052093506,\n",
       "  0.5511264204978943,\n",
       "  1.4366930723190308,\n",
       "  -0.3107830584049225,\n",
       "  -1.3447322845458984,\n",
       "  -0.5564500689506531,\n",
       "  0.1945781707763672,\n",
       "  -0.7203722596168518,\n",
       "  1.055024266242981,\n",
       "  -0.35584428906440735,\n",
       "  1.5851185321807861,\n",
       "  0.257184773683548,\n",
       "  0.1985032856464386,\n",
       "  -0.5680220723152161,\n",
       "  -0.8303921222686768,\n",
       "  1.1436575651168823,\n",
       "  -0.9057115316390991,\n",
       "  0.10073085874319077,\n",
       "  -2.236480474472046,\n",
       "  -0.20200996100902557,\n",
       "  -0.6722332239151001,\n",
       "  -1.0566513538360596,\n",
       "  -0.6468158960342407,\n",
       "  -0.385358065366745,\n",
       "  0.016542350873351097,\n",
       "  0.31220704317092896,\n",
       "  -0.02423389069736004,\n",
       "  -0.46573227643966675,\n",
       "  -1.1841611862182617,\n",
       "  -0.7922247052192688,\n",
       "  1.0637390613555908,\n",
       "  -0.701212465763092,\n",
       "  0.9605400562286377,\n",
       "  -1.1456300020217896,\n",
       "  -1.2353969812393188,\n",
       "  -0.3396967947483063,\n",
       "  0.6558908820152283,\n",
       "  0.7282720804214478,\n",
       "  0.07206319272518158,\n",
       "  0.9552679657936096,\n",
       "  1.3208866119384766,\n",
       "  0.5782951712608337,\n",
       "  0.11812737584114075,\n",
       "  -0.30912137031555176,\n",
       "  1.5846385955810547,\n",
       "  0.3823232650756836,\n",
       "  -0.1514091193675995,\n",
       "  -0.44077473878860474,\n",
       "  -0.4786544144153595,\n",
       "  0.12495912611484528],\n",
       " [0.35475778579711914,\n",
       "  0.5637201070785522,\n",
       "  -3.884230613708496,\n",
       "  -1.5681341886520386,\n",
       "  0.9161431789398193,\n",
       "  0.8284855484962463,\n",
       "  -0.504990816116333,\n",
       "  0.7257483005523682,\n",
       "  -1.5883064270019531,\n",
       "  -0.8939196467399597,\n",
       "  -0.24560242891311646,\n",
       "  1.4676017761230469,\n",
       "  1.3233314752578735,\n",
       "  -0.10629329830408096,\n",
       "  0.6328519582748413,\n",
       "  -0.731476366519928,\n",
       "  1.714982271194458,\n",
       "  -1.6759790182113647,\n",
       "  1.2137724161148071,\n",
       "  0.4280719459056854,\n",
       "  -0.16919776797294617,\n",
       "  1.6997325420379639,\n",
       "  1.0390863418579102,\n",
       "  1.0083261728286743,\n",
       "  3.8077943325042725,\n",
       "  0.822836697101593,\n",
       "  -0.09407301992177963,\n",
       "  1.0032564401626587,\n",
       "  -0.7315153479576111,\n",
       "  0.6447138786315918,\n",
       "  0.030183909460902214,\n",
       "  0.01241248194128275,\n",
       "  -0.4994271993637085,\n",
       "  0.13136738538742065,\n",
       "  -0.9757622480392456,\n",
       "  -0.5265620946884155,\n",
       "  1.5599077939987183,\n",
       "  0.9166251420974731,\n",
       "  0.5691351294517517,\n",
       "  0.11167466640472412,\n",
       "  1.0870541334152222,\n",
       "  0.038880351930856705,\n",
       "  -0.02012820728123188,\n",
       "  -0.06421591341495514,\n",
       "  0.6138461232185364,\n",
       "  -0.629375159740448,\n",
       "  1.3110637664794922,\n",
       "  -0.9088719487190247,\n",
       "  0.34282588958740234,\n",
       "  -0.16520704329013824,\n",
       "  0.6847936511039734,\n",
       "  0.3732105791568756,\n",
       "  0.11088565737009048,\n",
       "  -0.8490850329399109,\n",
       "  1.5305140018463135,\n",
       "  0.9894859790802002,\n",
       "  1.312988042831421,\n",
       "  -0.88657146692276,\n",
       "  -0.6355196833610535,\n",
       "  -0.09727977961301804,\n",
       "  1.8852474689483643,\n",
       "  1.1402431726455688,\n",
       "  -1.1019542217254639,\n",
       "  0.6416919827461243,\n",
       "  1.5660755634307861,\n",
       "  -1.8427163362503052,\n",
       "  -0.18289285898208618,\n",
       "  1.4156744480133057,\n",
       "  -0.3661561906337738,\n",
       "  0.11576400697231293,\n",
       "  2.3156521320343018,\n",
       "  -0.51253741979599,\n",
       "  0.6060761213302612,\n",
       "  0.007703613955527544,\n",
       "  -0.1002742350101471,\n",
       "  -1.0956554412841797,\n",
       "  -0.44626012444496155,\n",
       "  -0.05463273450732231,\n",
       "  0.3418160080909729,\n",
       "  0.516499400138855,\n",
       "  0.37071940302848816,\n",
       "  0.7810840010643005,\n",
       "  1.3611711263656616,\n",
       "  0.4246062934398651,\n",
       "  1.3607670068740845,\n",
       "  -0.5447375178337097,\n",
       "  -0.41679367423057556,\n",
       "  -0.6547034382820129,\n",
       "  -1.3070192337036133,\n",
       "  0.6389153003692627,\n",
       "  -0.3563247323036194,\n",
       "  0.21331828832626343,\n",
       "  0.6088975667953491,\n",
       "  -0.3251814842224121,\n",
       "  -0.8553903698921204,\n",
       "  -0.1009933352470398,\n",
       "  -1.0274438858032227,\n",
       "  0.39890986680984497,\n",
       "  -0.4231797158718109,\n",
       "  -1.1386818885803223,\n",
       "  -1.3399802446365356,\n",
       "  -0.6245468854904175,\n",
       "  0.38322436809539795,\n",
       "  -0.1127224937081337,\n",
       "  0.704589307308197,\n",
       "  2.1022701263427734,\n",
       "  0.30379340052604675,\n",
       "  0.3891933560371399,\n",
       "  -0.6432387232780457,\n",
       "  -0.40303924679756165,\n",
       "  -1.431648850440979,\n",
       "  0.6674575209617615,\n",
       "  0.42866382002830505,\n",
       "  -0.6255362033843994,\n",
       "  0.3835790455341339,\n",
       "  0.35972848534584045,\n",
       "  1.832118272781372,\n",
       "  -0.15604235231876373,\n",
       "  0.4043363332748413,\n",
       "  1.4126555919647217,\n",
       "  -0.6182058453559875,\n",
       "  -0.0032991773914545774,\n",
       "  0.5551474690437317,\n",
       "  1.4919853210449219,\n",
       "  0.0583329051733017,\n",
       "  0.4396830201148987,\n",
       "  -1.008970022201538,\n",
       "  0.415902316570282,\n",
       "  -0.07319806516170502,\n",
       "  0.0961974635720253,\n",
       "  0.0247582346200943,\n",
       "  -0.3273027837276459,\n",
       "  0.09451627731323242,\n",
       "  -0.04064152017235756,\n",
       "  0.5966154336929321,\n",
       "  0.922709047794342,\n",
       "  -0.363610178232193,\n",
       "  -0.852757453918457,\n",
       "  0.3492778241634369,\n",
       "  0.7027414441108704,\n",
       "  0.9627162218093872,\n",
       "  1.0711537599563599,\n",
       "  0.22147080302238464,\n",
       "  -0.08893799781799316,\n",
       "  -0.7065942883491516,\n",
       "  -0.732231080532074,\n",
       "  1.373901605606079,\n",
       "  -1.1888703107833862,\n",
       "  0.0962342694401741,\n",
       "  -0.3025898337364197,\n",
       "  0.08464942872524261,\n",
       "  1.133257269859314,\n",
       "  -0.34410110116004944,\n",
       "  1.591058373451233,\n",
       "  0.9558537602424622,\n",
       "  -0.5263260006904602,\n",
       "  0.8103281259536743,\n",
       "  0.729546844959259,\n",
       "  -0.4813486933708191,\n",
       "  0.8451835513114929,\n",
       "  1.3056648969650269,\n",
       "  -0.18779879808425903,\n",
       "  -0.5603923797607422,\n",
       "  0.5877307653427124,\n",
       "  -0.4113020598888397,\n",
       "  -0.7190792560577393,\n",
       "  0.38639047741889954,\n",
       "  0.8871753811836243,\n",
       "  0.6409270167350769,\n",
       "  1.8559021949768066,\n",
       "  0.1747441589832306,\n",
       "  -1.2450188398361206,\n",
       "  -0.47360530495643616,\n",
       "  0.5195199251174927,\n",
       "  0.03234408050775528,\n",
       "  -0.5516611337661743,\n",
       "  0.60297030210495,\n",
       "  -1.4048539400100708,\n",
       "  -0.821907639503479,\n",
       "  -1.214438557624817,\n",
       "  1.2818832397460938,\n",
       "  -1.144702434539795,\n",
       "  0.6476529240608215,\n",
       "  1.1067017316818237,\n",
       "  -0.171000137925148,\n",
       "  -0.5555739402770996,\n",
       "  0.002193909604102373,\n",
       "  -0.3732447624206543,\n",
       "  -0.48143959045410156,\n",
       "  -1.297765851020813,\n",
       "  -2.227161169052124,\n",
       "  0.9529320001602173,\n",
       "  -0.531606912612915,\n",
       "  -0.7910411357879639,\n",
       "  -1.4011560678482056,\n",
       "  -0.3203166425228119,\n",
       "  0.3118114471435547,\n",
       "  -1.2654143571853638,\n",
       "  -0.1397700309753418,\n",
       "  -1.183782696723938,\n",
       "  0.31335604190826416,\n",
       "  -0.28278017044067383,\n",
       "  -1.9306141138076782,\n",
       "  0.011697264388203621,\n",
       "  -2.1282103061676025,\n",
       "  -0.3950818181037903,\n",
       "  -1.2756409645080566,\n",
       "  0.32816314697265625,\n",
       "  -0.2361757904291153,\n",
       "  0.6146042943000793,\n",
       "  2.0177364349365234,\n",
       "  -0.201043501496315,\n",
       "  -1.3849836587905884,\n",
       "  0.12202106416225433,\n",
       "  -0.3581167459487915,\n",
       "  -0.6859491467475891,\n",
       "  -0.259561151266098,\n",
       "  -0.5716795325279236,\n",
       "  -0.47356486320495605,\n",
       "  0.5052899122238159,\n",
       "  1.0315406322479248,\n",
       "  0.4586515724658966,\n",
       "  -0.1975569725036621,\n",
       "  -1.1970282793045044,\n",
       "  0.7510539889335632,\n",
       "  0.22497661411762238,\n",
       "  -0.016852062195539474,\n",
       "  -0.6446712017059326,\n",
       "  -1.3437645435333252,\n",
       "  0.3544486165046692,\n",
       "  -0.7691466212272644,\n",
       "  -0.5010278224945068,\n",
       "  0.7286182045936584,\n",
       "  -0.1494663655757904,\n",
       "  0.05520922690629959,\n",
       "  0.6941447854042053,\n",
       "  1.7483528852462769,\n",
       "  1.0724835395812988,\n",
       "  -0.29290276765823364,\n",
       "  -0.21684066951274872,\n",
       "  0.7920249700546265,\n",
       "  0.6669213175773621,\n",
       "  -1.1899447441101074,\n",
       "  -0.5696448683738708,\n",
       "  -0.8819370269775391,\n",
       "  1.3322439193725586,\n",
       "  0.4906840920448303,\n",
       "  -0.9804784059524536,\n",
       "  0.8653998374938965,\n",
       "  1.6719017028808594,\n",
       "  -0.4035242199897766,\n",
       "  -0.3594774603843689,\n",
       "  1.6003530025482178,\n",
       "  0.4113948345184326,\n",
       "  0.4510785639286041,\n",
       "  -1.3944603204727173,\n",
       "  -0.2848297953605652,\n",
       "  -0.5843981504440308,\n",
       "  -0.12243182212114334,\n",
       "  0.6923010945320129,\n",
       "  0.4919957220554352,\n",
       "  -0.9572163224220276,\n",
       "  0.9127964377403259,\n",
       "  -1.1320428848266602,\n",
       "  -0.9408490657806396,\n",
       "  -0.6671188473701477,\n",
       "  0.0028904853388667107,\n",
       "  0.9514382481575012,\n",
       "  0.5172134637832642,\n",
       "  -0.9804638624191284,\n",
       "  0.9831364154815674,\n",
       "  0.3366073668003082,\n",
       "  -0.6688900589942932,\n",
       "  -0.22102729976177216,\n",
       "  -0.27072012424468994,\n",
       "  -0.2428804337978363,\n",
       "  -0.42171019315719604,\n",
       "  0.1411140263080597,\n",
       "  -0.14551730453968048,\n",
       "  -0.034275468438863754,\n",
       "  0.7025639414787292,\n",
       "  -0.8545458316802979,\n",
       "  -1.1921099424362183,\n",
       "  -0.475334495306015,\n",
       "  -0.345081627368927,\n",
       "  0.19061064720153809,\n",
       "  0.8010258674621582,\n",
       "  0.8948745131492615,\n",
       "  0.5787580013275146,\n",
       "  -0.3297763466835022,\n",
       "  0.30622926354408264,\n",
       "  -0.0518777072429657,\n",
       "  -0.5403957366943359,\n",
       "  2.0517735481262207,\n",
       "  0.5759737491607666,\n",
       "  0.506102979183197,\n",
       "  2.3833441734313965,\n",
       "  0.40433427691459656,\n",
       "  0.5839784145355225,\n",
       "  -1.0290361642837524,\n",
       "  0.33733364939689636,\n",
       "  -0.11121660470962524,\n",
       "  0.036101147532463074,\n",
       "  0.12554903328418732,\n",
       "  -0.0955507829785347,\n",
       "  0.3788377642631531,\n",
       "  1.4412147998809814,\n",
       "  -0.27440357208251953,\n",
       "  1.0239977836608887,\n",
       "  -0.436544269323349,\n",
       "  -1.5473003387451172,\n",
       "  -0.8912095427513123,\n",
       "  -0.0865086242556572,\n",
       "  0.48633190989494324,\n",
       "  -1.9452670812606812,\n",
       "  0.7133665084838867,\n",
       "  -1.2399451732635498,\n",
       "  0.23550748825073242,\n",
       "  1.1019083261489868,\n",
       "  -0.2064293622970581,\n",
       "  0.13285280764102936,\n",
       "  -0.9058158993721008,\n",
       "  0.9564481377601624,\n",
       "  -0.7765880227088928,\n",
       "  -0.011016297154128551,\n",
       "  0.3272022008895874,\n",
       "  -1.4400027990341187,\n",
       "  0.9512280821800232,\n",
       "  -0.20263274013996124,\n",
       "  -1.0906867980957031,\n",
       "  -0.07482045888900757,\n",
       "  1.0576319694519043,\n",
       "  0.652133047580719,\n",
       "  -1.0051792860031128,\n",
       "  -0.7318978309631348,\n",
       "  0.6530517935752869,\n",
       "  0.46394115686416626,\n",
       "  0.060400769114494324,\n",
       "  -1.197543978691101,\n",
       "  0.4145498275756836,\n",
       "  1.4513837099075317,\n",
       "  -1.3661162853240967,\n",
       "  0.5255602598190308,\n",
       "  -1.1281089782714844,\n",
       "  0.5859745144844055,\n",
       "  -1.2266254425048828,\n",
       "  -0.4046606719493866,\n",
       "  -0.31083837151527405,\n",
       "  0.37140658497810364,\n",
       "  0.045138221234083176,\n",
       "  -1.469336986541748,\n",
       "  0.15775300562381744,\n",
       "  -0.5297372341156006,\n",
       "  0.2583106458187103,\n",
       "  0.17012052237987518,\n",
       "  -0.2884591519832611,\n",
       "  0.8635023832321167,\n",
       "  0.3285696804523468,\n",
       "  -0.9669808745384216,\n",
       "  -0.4402823746204376,\n",
       "  0.9988057017326355,\n",
       "  -1.3315908908843994,\n",
       "  0.5323963165283203,\n",
       "  -0.36174169182777405,\n",
       "  1.2517521381378174,\n",
       "  0.6563014984130859,\n",
       "  0.9625159502029419,\n",
       "  0.24855898320674896,\n",
       "  1.0401172637939453,\n",
       "  0.7457097172737122,\n",
       "  -0.3615637421607971,\n",
       "  -0.34423157572746277,\n",
       "  -0.09923975169658661,\n",
       "  0.19688214361667633,\n",
       "  1.6006919145584106,\n",
       "  -0.46191707253456116,\n",
       "  -1.6053208112716675,\n",
       "  0.0315171480178833,\n",
       "  -1.0570616722106934,\n",
       "  0.03745979443192482,\n",
       "  -0.13109081983566284,\n",
       "  0.30126893520355225,\n",
       "  0.2838076651096344,\n",
       "  0.1365334689617157,\n",
       "  0.33746081590652466,\n",
       "  -0.42600399255752563,\n",
       "  -0.47105684876441956,\n",
       "  -0.5158219337463379,\n",
       "  0.2223135232925415,\n",
       "  0.8343257308006287,\n",
       "  -0.5328518152236938,\n",
       "  -0.5278983116149902,\n",
       "  -1.4294922351837158,\n",
       "  -0.4285529851913452,\n",
       "  0.46536535024642944,\n",
       "  -1.0041030645370483,\n",
       "  1.1897015571594238,\n",
       "  0.03184099495410919,\n",
       "  -0.06788571923971176,\n",
       "  1.104892611503601,\n",
       "  -0.5959690809249878,\n",
       "  -0.5396496057510376,\n",
       "  -0.08816646039485931,\n",
       "  0.7340991497039795,\n",
       "  -0.16472601890563965,\n",
       "  1.9898741245269775,\n",
       "  0.9823452830314636,\n",
       "  -1.056932806968689,\n",
       "  0.23361271619796753,\n",
       "  0.12415719777345657,\n",
       "  0.5437313914299011,\n",
       "  1.7948616743087769,\n",
       "  -0.32701489329338074,\n",
       "  -0.7485261559486389,\n",
       "  -0.30409884452819824,\n",
       "  0.35850173234939575,\n",
       "  0.5726432204246521,\n",
       "  -0.13591112196445465,\n",
       "  -0.8162773847579956,\n",
       "  -0.3812115788459778,\n",
       "  0.7845274806022644,\n",
       "  0.5025718808174133,\n",
       "  -1.1307634115219116,\n",
       "  -0.04252856969833374,\n",
       "  -0.32027459144592285,\n",
       "  -0.5090148448944092,\n",
       "  -0.6414567828178406,\n",
       "  0.8604727387428284,\n",
       "  -0.3552606701850891,\n",
       "  -1.4597867727279663,\n",
       "  0.3043346405029297,\n",
       "  -0.08725962787866592,\n",
       "  0.3813934326171875,\n",
       "  0.7859547734260559,\n",
       "  -0.6434991955757141,\n",
       "  1.456185221672058,\n",
       "  -0.12415921688079834,\n",
       "  -0.17241936922073364,\n",
       "  1.217812418937683,\n",
       "  1.085871696472168,\n",
       "  0.10084442794322968,\n",
       "  -1.0229454040527344,\n",
       "  -0.40100738406181335,\n",
       "  -0.3780153691768646,\n",
       "  0.39417436718940735,\n",
       "  1.1881386041641235,\n",
       "  1.542353868484497,\n",
       "  -1.9725686311721802,\n",
       "  -0.5203942060470581,\n",
       "  1.1160944700241089,\n",
       "  -0.014395506121218204,\n",
       "  0.7230808138847351,\n",
       "  -0.11082858592271805,\n",
       "  1.0363773107528687,\n",
       "  1.8468562364578247,\n",
       "  -2.0043156147003174,\n",
       "  -0.857660174369812,\n",
       "  -0.016947176307439804,\n",
       "  0.9268367886543274,\n",
       "  0.43811312317848206,\n",
       "  0.03879019618034363,\n",
       "  1.5003983974456787,\n",
       "  -1.9666718244552612,\n",
       "  0.24025940895080566,\n",
       "  -0.1281508356332779,\n",
       "  -0.4565701186656952,\n",
       "  0.9136591553688049,\n",
       "  0.13354016840457916,\n",
       "  1.4720755815505981,\n",
       "  2.2242579460144043,\n",
       "  -0.9771332144737244,\n",
       "  -0.2118615359067917,\n",
       "  0.42171016335487366,\n",
       "  -0.3062329888343811,\n",
       "  -0.08225347101688385,\n",
       "  -0.14035509526729584,\n",
       "  -0.44873225688934326,\n",
       "  -0.1342362016439438,\n",
       "  0.8969573378562927,\n",
       "  0.9649704098701477,\n",
       "  -0.3184075355529785,\n",
       "  0.05100765451788902,\n",
       "  -0.3010237514972687,\n",
       "  -1.994753122329712,\n",
       "  0.23152372241020203,\n",
       "  -0.43320539593696594,\n",
       "  0.30013665556907654,\n",
       "  0.3593301773071289,\n",
       "  -0.49544548988342285,\n",
       "  -0.2677685022354126,\n",
       "  -0.32895347476005554,\n",
       "  0.47677841782569885,\n",
       "  0.5957240462303162,\n",
       "  -0.5214465260505676,\n",
       "  -0.7509101033210754,\n",
       "  -0.5308319926261902,\n",
       "  0.4380829632282257,\n",
       "  -0.3486383855342865,\n",
       "  0.8670448064804077,\n",
       "  0.49849584698677063,\n",
       "  0.35085511207580566,\n",
       "  -0.3497740626335144,\n",
       "  -0.12181560695171356,\n",
       "  0.9101688265800476,\n",
       "  1.4270000457763672,\n",
       "  0.1688191443681717,\n",
       "  -0.5369781851768494,\n",
       "  -1.298940658569336,\n",
       "  -1.2320137023925781,\n",
       "  0.6238635778427124,\n",
       "  -0.305776447057724,\n",
       "  0.3326358199119568,\n",
       "  0.20119649171829224,\n",
       "  0.7106612920761108,\n",
       "  0.612585723400116,\n",
       "  -0.2824658155441284,\n",
       "  0.31141382455825806,\n",
       "  0.017915556207299232,\n",
       "  -0.7348000407218933,\n",
       "  0.5519070029258728,\n",
       "  0.9619629383087158,\n",
       "  -0.24329659342765808,\n",
       "  -0.35985398292541504,\n",
       "  0.42393243312835693,\n",
       "  -0.9171541333198547,\n",
       "  0.7874794006347656,\n",
       "  0.4591333866119385,\n",
       "  -1.2163174152374268,\n",
       "  -0.19382549822330475,\n",
       "  -0.2279851734638214,\n",
       "  0.09523838013410568,\n",
       "  -0.09776803851127625,\n",
       "  -0.7298553586006165,\n",
       "  -0.6937829852104187,\n",
       "  0.06570646911859512,\n",
       "  -0.9908565878868103,\n",
       "  -1.137206792831421,\n",
       "  0.5305777788162231,\n",
       "  0.14013360440731049,\n",
       "  -0.5639883875846863,\n",
       "  0.5132665634155273,\n",
       "  0.4876028001308441,\n",
       "  -0.03626338019967079,\n",
       "  0.5123088359832764,\n",
       "  0.04086695611476898,\n",
       "  -0.3464132845401764,\n",
       "  -1.2529419660568237,\n",
       "  -0.11896364390850067,\n",
       "  -1.0780384540557861,\n",
       "  -0.7252869606018066,\n",
       "  1.2735633850097656,\n",
       "  -1.770756483078003,\n",
       "  -1.3559248447418213,\n",
       "  -0.4425646960735321,\n",
       "  -0.07050430029630661,\n",
       "  -1.3163882493972778,\n",
       "  0.1992529183626175,\n",
       "  0.5986555218696594,\n",
       "  -0.4449828863143921,\n",
       "  -1.2407692670822144,\n",
       "  0.7635737657546997,\n",
       "  0.9723789691925049,\n",
       "  0.6091117262840271,\n",
       "  0.8403080701828003,\n",
       "  0.6270805597305298,\n",
       "  -0.3162863850593567,\n",
       "  -0.13352656364440918,\n",
       "  -0.0922563448548317,\n",
       "  0.35156863927841187,\n",
       "  -0.7110291719436646,\n",
       "  -0.2205553948879242,\n",
       "  -0.18776461482048035,\n",
       "  0.10886421799659729,\n",
       "  -0.5138785243034363,\n",
       "  0.20376111567020416,\n",
       "  0.16185283660888672,\n",
       "  0.02073831297457218,\n",
       "  1.003756046295166,\n",
       "  -1.5112593173980713,\n",
       "  -0.4924792945384979,\n",
       "  0.4064434766769409,\n",
       "  -1.1391249895095825,\n",
       "  -1.2264302968978882,\n",
       "  0.6491557359695435,\n",
       "  -0.3732842803001404,\n",
       "  0.5134333968162537,\n",
       "  -0.4194371998310089,\n",
       "  -0.1425277292728424,\n",
       "  0.48593059182167053,\n",
       "  0.007722914218902588,\n",
       "  0.20749589800834656,\n",
       "  -0.32297611236572266,\n",
       "  -0.2871229648590088,\n",
       "  -0.5917553901672363,\n",
       "  0.08187642693519592,\n",
       "  -0.036566171795129776,\n",
       "  -0.33058735728263855,\n",
       "  -1.1234263181686401,\n",
       "  -0.43397262692451477,\n",
       "  -0.6944589614868164,\n",
       "  0.26784831285476685,\n",
       "  0.3025170862674713,\n",
       "  1.5088883638381958,\n",
       "  -1.6363383531570435,\n",
       "  -0.20570097863674164,\n",
       "  1.5923376083374023,\n",
       "  -0.18439941108226776,\n",
       "  -0.30326956510543823,\n",
       "  -0.27180808782577515,\n",
       "  -1.0245373249053955,\n",
       "  0.6121546030044556,\n",
       "  -0.19086244702339172,\n",
       "  -0.23219208419322968,\n",
       "  -0.02657068707048893,\n",
       "  0.5410881042480469,\n",
       "  0.2793097198009491,\n",
       "  1.311288595199585,\n",
       "  0.11528853327035904,\n",
       "  -0.2937442362308502,\n",
       "  -0.6176654100418091,\n",
       "  -0.4125719964504242,\n",
       "  -1.2376269102096558,\n",
       "  0.9006844758987427,\n",
       "  -0.575075626373291,\n",
       "  1.0611597299575806,\n",
       "  -0.6528575420379639,\n",
       "  -2.2196102142333984,\n",
       "  -0.2538857161998749,\n",
       "  0.4516369104385376,\n",
       "  1.3173598051071167,\n",
       "  -0.8558019399642944,\n",
       "  0.9558899402618408,\n",
       "  -1.778191089630127,\n",
       "  -1.4735815525054932,\n",
       "  -0.42438986897468567,\n",
       "  -0.631700336933136,\n",
       "  -0.8254136443138123,\n",
       "  -0.5254575610160828,\n",
       "  -0.22158248722553253,\n",
       "  0.9046706557273865,\n",
       "  0.4769757091999054,\n",
       "  -0.2724475860595703,\n",
       "  -0.14533206820487976,\n",
       "  0.41141462326049805,\n",
       "  0.32732781767845154,\n",
       "  -0.665069043636322,\n",
       "  1.1854168176651,\n",
       "  0.6615901589393616,\n",
       "  0.8470917344093323,\n",
       "  -1.2924093008041382,\n",
       "  1.8585574626922607,\n",
       "  1.9868868589401245,\n",
       "  -0.16062957048416138,\n",
       "  0.201873779296875,\n",
       "  0.9513229131698608,\n",
       "  -1.0418353080749512,\n",
       "  0.6644391417503357,\n",
       "  -1.745572566986084,\n",
       "  -0.8698028922080994,\n",
       "  -0.7074482440948486,\n",
       "  -0.1921924352645874,\n",
       "  -0.45231732726097107,\n",
       "  -0.537926435470581,\n",
       "  0.5713998079299927,\n",
       "  0.35358452796936035,\n",
       "  -0.5050451159477234,\n",
       "  0.2874166965484619,\n",
       "  -0.8551613092422485,\n",
       "  -1.1664677858352661,\n",
       "  -0.007082620169967413,\n",
       "  1.1009587049484253,\n",
       "  0.5655152201652527,\n",
       "  0.6524333357810974,\n",
       "  0.43570753931999207,\n",
       "  0.1539478302001953,\n",
       "  0.8178704977035522,\n",
       "  0.01660430245101452,\n",
       "  1.2007057666778564,\n",
       "  0.7326721549034119,\n",
       "  -1.7113200426101685,\n",
       "  0.41457781195640564,\n",
       "  -0.28453385829925537,\n",
       "  -0.4241360127925873,\n",
       "  -0.20378921926021576,\n",
       "  -0.37923768162727356,\n",
       "  -1.9972379207611084,\n",
       "  0.9599770903587341,\n",
       "  -1.0005782842636108,\n",
       "  0.0019000580068677664,\n",
       "  -0.7989634275436401,\n",
       "  0.2873186469078064,\n",
       "  -0.9045395255088806,\n",
       "  0.6488743424415588,\n",
       "  -0.5509166121482849,\n",
       "  -0.473300576210022,\n",
       "  -0.7173073291778564,\n",
       "  0.17363525927066803,\n",
       "  0.0818098708987236,\n",
       "  -0.13603700697422028,\n",
       "  1.732576847076416,\n",
       "  0.09819991141557693,\n",
       "  1.0219606161117554,\n",
       "  0.09969967603683472,\n",
       "  0.6729124784469604,\n",
       "  -0.643262505531311,\n",
       "  -1.5545017719268799,\n",
       "  0.11030621826648712,\n",
       "  0.19128607213497162,\n",
       "  -0.8465402126312256,\n",
       "  -0.3420805037021637,\n",
       "  0.06047574430704117,\n",
       "  1.5501629114151,\n",
       "  -0.07090883702039719,\n",
       "  0.4265688955783844,\n",
       "  0.7685563564300537,\n",
       "  -0.0021534976549446583,\n",
       "  -0.43066298961639404,\n",
       "  0.13246037065982819,\n",
       "  -0.5926840305328369,\n",
       "  0.9210754036903381,\n",
       "  0.5539515614509583,\n",
       "  -0.10692299902439117,\n",
       "  -1.0262304544448853,\n",
       "  -0.5247345566749573,\n",
       "  -0.25825807452201843,\n",
       "  -0.5827562212944031,\n",
       "  0.7864335179328918,\n",
       "  -0.7950692772865295,\n",
       "  1.3766059875488281,\n",
       "  0.16910450160503387,\n",
       "  0.3173970580101013,\n",
       "  0.2932294011116028,\n",
       "  -0.9604978561401367,\n",
       "  0.7939589619636536,\n",
       "  0.05670551583170891,\n",
       "  -0.017920177429914474,\n",
       "  -1.0769374370574951,\n",
       "  0.17467965185642242,\n",
       "  -0.39154863357543945,\n",
       "  -0.34224796295166016,\n",
       "  -0.9155281186103821,\n",
       "  0.13091076910495758,\n",
       "  0.22796478867530823,\n",
       "  -0.14910179376602173,\n",
       "  -0.3024307191371918,\n",
       "  -0.7869777679443359,\n",
       "  -0.5933096408843994,\n",
       "  0.22534820437431335,\n",
       "  0.6333368420600891,\n",
       "  -0.0023393300361931324,\n",
       "  0.30079931020736694,\n",
       "  -0.166265070438385,\n",
       "  -1.1152641773223877,\n",
       "  -0.4978061616420746,\n",
       "  -0.07934486865997314,\n",
       "  0.5410964488983154,\n",
       "  -0.9518009424209595,\n",
       "  1.7615876197814941,\n",
       "  0.599899411201477,\n",
       "  0.4490099251270294,\n",
       "  1.1143608093261719,\n",
       "  0.14927901327610016,\n",
       "  1.4841676950454712,\n",
       "  -0.6822470426559448,\n",
       "  -0.9599718451499939,\n",
       "  -1.1886441707611084,\n",
       "  -1.2840125560760498,\n",
       "  -0.2297176718711853]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba8c558-3832-469f-942b-07f5615d337f",
   "metadata": {},
   "source": [
    "We can do arithmetic between these embeddings to calculate distances between them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171b4bf5-c638-4280-8564-ef45268a60a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "X = np.array(doc_vectors)\n",
    "dists = squareform(pdist(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e73d64-9d04-45de-809a-0d50c5299a11",
   "metadata": {},
   "source": [
    "This gives us the Euclidean distances between our words as a square matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37fa987-aba4-4521-ac37-083a566954af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b98b7_row0_col0, #T_b98b7_row1_col1, #T_b98b7_row2_col2, #T_b98b7_row3_col3 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b98b7_row0_col1 {\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b98b7_row0_col2 {\n",
       "  background-color: #d1493f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b98b7_row0_col3 {\n",
       "  background-color: #f7ad90;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b98b7_row1_col0 {\n",
       "  background-color: #e9785d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b98b7_row1_col2, #T_b98b7_row2_col0, #T_b98b7_row2_col1, #T_b98b7_row2_col3 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b98b7_row1_col3 {\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b98b7_row3_col0 {\n",
       "  background-color: #f59d7e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b98b7_row3_col1 {\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b98b7_row3_col2 {\n",
       "  background-color: #be242e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b98b7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b98b7_level0_col0\" class=\"col_heading level0 col0\" >cat</th>\n",
       "      <th id=\"T_b98b7_level0_col1\" class=\"col_heading level0 col1\" >dog</th>\n",
       "      <th id=\"T_b98b7_level0_col2\" class=\"col_heading level0 col2\" >computer</th>\n",
       "      <th id=\"T_b98b7_level0_col3\" class=\"col_heading level0 col3\" >animal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b98b7_level0_row0\" class=\"row_heading level0 row0\" >cat</th>\n",
       "      <td id=\"T_b98b7_row0_col0\" class=\"data row0 col0\" >0.000000</td>\n",
       "      <td id=\"T_b98b7_row0_col1\" class=\"data row0 col1\" >14.640208</td>\n",
       "      <td id=\"T_b98b7_row0_col2\" class=\"data row0 col2\" >17.752331</td>\n",
       "      <td id=\"T_b98b7_row0_col3\" class=\"data row0 col3\" >13.146150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b98b7_level0_row1\" class=\"row_heading level0 row1\" >dog</th>\n",
       "      <td id=\"T_b98b7_row1_col0\" class=\"data row1 col0\" >14.640208</td>\n",
       "      <td id=\"T_b98b7_row1_col1\" class=\"data row1 col1\" >0.000000</td>\n",
       "      <td id=\"T_b98b7_row1_col2\" class=\"data row1 col2\" >19.349403</td>\n",
       "      <td id=\"T_b98b7_row1_col3\" class=\"data row1 col3\" >7.541415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b98b7_level0_row2\" class=\"row_heading level0 row2\" >computer</th>\n",
       "      <td id=\"T_b98b7_row2_col0\" class=\"data row2 col0\" >17.752331</td>\n",
       "      <td id=\"T_b98b7_row2_col1\" class=\"data row2 col1\" >19.349403</td>\n",
       "      <td id=\"T_b98b7_row2_col2\" class=\"data row2 col2\" >0.000000</td>\n",
       "      <td id=\"T_b98b7_row2_col3\" class=\"data row2 col3\" >18.804777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b98b7_level0_row3\" class=\"row_heading level0 row3\" >animal</th>\n",
       "      <td id=\"T_b98b7_row3_col0\" class=\"data row3 col0\" >13.146150</td>\n",
       "      <td id=\"T_b98b7_row3_col1\" class=\"data row3 col1\" >7.541415</td>\n",
       "      <td id=\"T_b98b7_row3_col2\" class=\"data row3 col2\" >18.804777</td>\n",
       "      <td id=\"T_b98b7_row3_col3\" class=\"data row3 col3\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x73431e1a9ca0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=dists,\n",
    "    index=words,\n",
    "    columns=words\n",
    ")\n",
    "df.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8d2a93-0435-488d-980d-b1d57a47f15c",
   "metadata": {},
   "source": [
    "Concept in RAG\n",
    "1. Indexing organizes vectors to optimize retrieval, structuring them so that vectors can be retrieval quickly. There are different algorithms like k-d trees or Annoy for this.\n",
    "2. Vector libraries provide functions for vector operations like dot product and vector indexing.\n",
    "3. Vector databases like Milvus or Pinecone are designed to store, manage, and retrieve larget sets of vectors. They use indexing mechanism to facilitate efficient similarity searches on these vvectorsl."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6855b362-26b2-4ae1-bc0c-a4973fd408bc",
   "metadata": {},
   "source": [
    "### Chroma\n",
    "Vector store optimized for storing and querying vectors using Chroma as a backend. Chroma takes over for encoding and comparing vectors based on their angular similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c850b299-228a-463f-9e4f-bdfdc3d9141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af78d6e7-5e75-4eb6-8db6-36fb80d1e0b2",
   "metadata": {},
   "source": [
    "Create an instance of Chroma and provide the documents (splits) and the embedding method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e640ae9e-3eac-42c6-b7c4-3138e21a7278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m88 packages\u001b[0m \u001b[2min 669ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m16 packages\u001b[0m \u001b[2min 471ms\u001b[0m\u001b[0m                                            \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m41 packages\u001b[0m \u001b[2min 22ms\u001b[0m\u001b[0m                               \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1masgiref\u001b[0m\u001b[2m==3.8.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbackoff\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbcrypt\u001b[0m\u001b[2m==4.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mchroma-hnswlib\u001b[0m\u001b[2m==0.7.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mchromadb\u001b[0m\u001b[2m==0.6.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdeprecated\u001b[0m\u001b[2m==1.2.18\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdurationpy\u001b[0m\u001b[2m==0.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfastapi\u001b[0m\u001b[2m==0.115.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-auth\u001b[0m\u001b[2m==2.38.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogleapis-common-protos\u001b[0m\u001b[2m==1.67.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgrpcio\u001b[0m\u001b[2m==1.70.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttptools\u001b[0m\u001b[2m==0.6.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mimportlib-metadata\u001b[0m\u001b[2m==8.5.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mimportlib-resources\u001b[0m\u001b[2m==6.5.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mkubernetes\u001b[0m\u001b[2m==32.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmonotonic\u001b[0m\u001b[2m==1.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1moauthlib\u001b[0m\u001b[2m==3.2.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-api\u001b[0m\u001b[2m==1.30.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-exporter-otlp-proto-common\u001b[0m\u001b[2m==1.30.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-exporter-otlp-proto-grpc\u001b[0m\u001b[2m==1.30.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-instrumentation\u001b[0m\u001b[2m==0.51b0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-instrumentation-asgi\u001b[0m\u001b[2m==0.51b0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-instrumentation-fastapi\u001b[0m\u001b[2m==0.51b0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-proto\u001b[0m\u001b[2m==1.30.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-sdk\u001b[0m\u001b[2m==1.30.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-semantic-conventions\u001b[0m\u001b[2m==0.51b0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-util-http\u001b[0m\u001b[2m==0.51b0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mposthog\u001b[0m\u001b[2m==3.14.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyasn1\u001b[0m\u001b[2m==0.6.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyasn1-modules\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpypika\u001b[0m\u001b[2m==0.48.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrequests-oauthlib\u001b[0m\u001b[2m==2.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrsa\u001b[0m\u001b[2m==4.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mstarlette\u001b[0m\u001b[2m==0.45.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyper\u001b[0m\u001b[2m==0.15.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1muvicorn\u001b[0m\u001b[2m==0.34.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1muvloop\u001b[0m\u001b[2m==0.21.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwatchfiles\u001b[0m\u001b[2m==1.0.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwebsockets\u001b[0m\u001b[2m==15.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwrapt\u001b[0m\u001b[2m==1.17.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mzipp\u001b[0m\u001b[2m==3.21.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! uv pip install pymupdf chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd43000-50db-4775-87e5-810e4dc886a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 9ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! uv pip install langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0c4066-ec7a-4246-92e3-b86a84482975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import ArxivLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "loader = ArxivLoader(query=\"2310.06825\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3318c7eb-5dda-404c-8739-dbf7d2e0f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    ")\n",
    "vectorstore = Chroma.from_documents(documents=docs, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e262606-9e87-4df3-955e-f959fdae11fa",
   "metadata": {},
   "source": [
    "# Evaluating LLMS\n",
    "## Comparing two outputs\n",
    "1. Create the evaluator: Load the evaluator using the `load_evaluator()` function, specifying the type of evaluator (in this case, pairwise_string).\n",
    "2. Select the dataset: Load a dataset of inputs using the `load_dataset()` function.\n",
    "3. Define models to compare: Initialize the LLMs, chains, or agents to compare using the necessary configurations. This involves initializing the language model and any additional tools or agents required.\n",
    "4. Generate responses: Generate outputs for each of the models before evaluating them. This is typically done in batches to improve efficiency.\n",
    "5. Evaluate pairs: Evaluate the results by comparing the outputs of different models for each input. This is done using a random selection order to reduce positional bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43db90ed-3d56-486c-b993-e555644dcdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! seed is not default parameter.\n",
      "                    seed was transferred to model_kwargs.\n",
      "                    Please confirm that seed is what you intended.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Evaluation with the <class 'langchain.evaluation.comparison.eval_chain.LabeledPairwiseStringEvalChain'> requires a language model to function. Failed to create the default 'gpt-4' model. Please manually provide an evaluation LLM or check your openai credentials.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain/evaluation/loading.py:150\u001b[0m, in \u001b[0;36mload_evaluator\u001b[0;34m(evaluator, llm, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    143\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import langchain_openai or fallback onto \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlangchain_community. Please install langchain_openai \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecify a language model explicitly.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m             )\n\u001b[0;32m--> 150\u001b[0m     llm \u001b[38;5;241m=\u001b[39m llm \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-arg]\u001b[39;49;00m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:214\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m     emit_warning()\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain_core/load/serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/pydantic/main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ChatOpenAI\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'temperature': 0, 'model...ne, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_evaluator\n\u001b[1;32m      2\u001b[0m embedding_function \u001b[38;5;241m=\u001b[39m OllamaEmbeddings(\n\u001b[1;32m      3\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnomic-embed-text\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m )\n\u001b[0;32m----> 6\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m \u001b[43mload_evaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabeled_pairwise_string\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mevaluate_string_pairs(\n\u001b[1;32m      8\u001b[0m     prediction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthere are three dogs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     prediction_b\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhow many dogs are in the park?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     refeerence\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfour\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain/evaluation/loading.py:154\u001b[0m, in \u001b[0;36mload_evaluator\u001b[0;34m(evaluator, llm, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         llm \u001b[38;5;241m=\u001b[39m llm \u001b[38;5;129;01mor\u001b[39;00m ChatOpenAI(  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m    151\u001b[0m             model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m\"\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    152\u001b[0m         )\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 154\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    155\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation with the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevaluator_cls\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage model to function.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Failed to create the default \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m model.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please manually provide an evaluation LLM\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or check your openai credentials.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m evaluator_cls\u001b[38;5;241m.\u001b[39mfrom_llm(llm\u001b[38;5;241m=\u001b[39mllm, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Evaluation with the <class 'langchain.evaluation.comparison.eval_chain.LabeledPairwiseStringEvalChain'> requires a language model to function. Failed to create the default 'gpt-4' model. Please manually provide an evaluation LLM or check your openai credentials."
     ]
    }
   ],
   "source": [
    "from langchain.evaluation import load_evaluator\n",
    "embedding_function = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    ")\n",
    "\n",
    "evaluator = load_evaluator(\"labeled_pairwise_string\", embeddings=embedding_function)\n",
    "evaluator.evaluate_string_pairs(\n",
    "    prediction=\"there are three dogs\",\n",
    "    prediction_b=\"4\",\n",
    "    input=\"how many dogs are in the park?\",\n",
    "    refeerence=\"four\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192fa082-a3f6-4b40-815a-f588e6072537",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for LabeledPairwiseStringEvalChain\nprompt\n  Field required [type=missing, input_value={'evaluation_llm': ChatOl...phi3', temperature=0.0)}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\nllm\n  Field required [type=missing, input_value={'evaluation_llm': ChatOl...phi3', temperature=0.0)}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Provide your chosen Ollama model for evaluation\u001b[39;00m\n\u001b[1;32m      5\u001b[0m evaluation_llm \u001b[38;5;241m=\u001b[39m ChatOllama(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphi3\u001b[39m\u001b[38;5;124m\"\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m eval_chain \u001b[38;5;241m=\u001b[39m \u001b[43mLabeledPairwiseStringEvalChain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluation_llm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluation_llm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:214\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     emit_warning()\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain_core/load/serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/pydantic/main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    216\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    220\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    221\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 2 validation errors for LabeledPairwiseStringEvalChain\nprompt\n  Field required [type=missing, input_value={'evaluation_llm': ChatOl...phi3', temperature=0.0)}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\nllm\n  Field required [type=missing, input_value={'evaluation_llm': ChatOl...phi3', temperature=0.0)}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing"
     ]
    }
   ],
   "source": [
    "from langchain.evaluation.comparison.eval_chain import LabeledPairwiseStringEvalChain\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Provide your chosen Ollama model for evaluation\n",
    "evaluation_llm = ChatOllama(model=\"phi3\", temperature=0)\n",
    "\n",
    "eval_chain = LabeledPairwiseStringEvalChain(evaluation_llm=evaluation_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b90fed-2f9c-4e48-9065-21cae610dc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.comparison.eval_chain import LabeledPairwiseStringEvalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Initialize your local Ollama model (or any other model)\n",
    "evaluation_llm = ChatOllama(model=\"phi3\", temperature=0)\n",
    "\n",
    "# Define a prompt template for evaluation\n",
    "eval_prompt = PromptTemplate(\n",
    "    template=(\n",
    "        \"You are an expert evaluator. Compare the following two outputs and decide which is better. \"\n",
    "        \"Output A: {output_a}\\nOutput B: {output_b}\\n\"\n",
    "        \"Provide a brief explanation for your choice.\"\n",
    "    ),\n",
    "    input_variables=[\"output_a\", \"output_b\"]\n",
    ")\n",
    "\n",
    "# Now instantiate the evaluation chain by providing both llm and prompt.\n",
    "eval_chain = LabeledPairwiseStringEvalChain(\n",
    "    llm=evaluation_llm,         # This is the main LLM to use\n",
    "    prompt=eval_prompt,         # The prompt instructing how to compare outputs\n",
    "    evaluation_llm=evaluation_llm  # You can use the same model for evaluation, or a different one\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4fb37e-e64e-43d3-8db6-d719b5cf8164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.comparison.eval_chain import LabeledPairwiseStringEvalChain\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "evaluation_llm = ChatOllama(model=\"phi3\", temperature=0)\n",
    "\n",
    "eval_chain = LabeledPairwiseStringEvalChain(\n",
    "    llm=evaluation_llm,\n",
    "    prompt=custom_eval_prompt,\n",
    "    evaluation_llm=evaluation_llm\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e948534d-d71b-44df-a029-07008433ec79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output_a': 'there are three dogs', 'output_b': '4', 'input': 'how many dogs are in the park?', 'reference': 'four', 'results': {'reasoning': '[[B]]', 'value': 'B', 'score': 0}}\n"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"output_a\": \"there are three dogs\",\n",
    "    \"output_b\": \"4\",\n",
    "    \"input\": \"how many dogs are in the park?\",\n",
    "    \"reference\": \"four\"\n",
    "}\n",
    "\n",
    "result = eval_chain.invoke(inputs)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2256cefb-8065-4277-a644-2ad1431382c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing some input keys: {'output_b', 'output_a'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43meval_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_string_pairs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthere are three dogs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m \u001b[49m\u001b[43mprediction_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m \u001b[49m\u001b[43mreference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfour\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43moutput_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkk\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43moutput_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjjj\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain/evaluation/schema.py:324\u001b[0m, in \u001b[0;36mPairwiseStringEvaluator.evaluate_string_pairs\u001b[0;34m(self, prediction, prediction_b, reference, input, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate the output string pairs.\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;124;03m    dict: A dictionary containing the preference, scores, and/or other information.\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_evaluation_args(reference\u001b[38;5;241m=\u001b[39mreference, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_string_pairs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprediction_b\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain/evaluation/comparison/eval_chain.py:342\u001b[0m, in \u001b[0;36mPairwiseStringEvalChain._evaluate_string_pairs\u001b[0;34m(self, prediction, prediction_b, input, reference, callbacks, tags, metadata, include_run_info, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate whether output A is preferred to output B.\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    339\u001b[0m \n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    341\u001b[0m input_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(prediction, prediction_b, \u001b[38;5;28minput\u001b[39m, reference)\n\u001b[0;32m--> 342\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_output(result)\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:181\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     emit_warning()\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain/chains/base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    387\u001b[0m }\n\u001b[0;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain/chains/base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain/chains/base.py:158\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    153\u001b[0m     inputs,\n\u001b[1;32m    154\u001b[0m     run_id,\n\u001b[1;32m    155\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[1;32m    156\u001b[0m )\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    167\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain/chains/base.py:290\u001b[0m, in \u001b[0;36mChain._validate_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    288\u001b[0m missing_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_keys)\u001b[38;5;241m.\u001b[39mdifference(inputs)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_keys:\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing some input keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Missing some input keys: {'output_b', 'output_a'}"
     ]
    }
   ],
   "source": [
    "eval_chain.evaluate_string_pairs(\n",
    "    prediction=\"there are three dogs\",\n",
    " prediction_b=\"4\",\n",
    "    input=inputs,\n",
    " reference=\"four\",\n",
    "output_a=\"kk\",\n",
    "output_b=\"jjj\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ab502c-b990-43f4-a0dc-7b02723a2a7b",
   "metadata": {},
   "source": [
    "# Tool\n",
    "Tools are wrappers that allow your LLM to interact with the world. These are essentially functions that hake some sort of input and output something based on it.\n",
    "\n",
    "The tool abstraction in LangChain associates a Python function with a schema that defines the function's name, description and expected arguments.\n",
    "\n",
    "Tools can be passed to chat models that support tool calling allowing the model to request the execution of a specific function with specific inputs.\n",
    "\n",
    "Key concepts\n",
    "- Tools are a way to encapsulate a function and its schema in a way that can be passed to a chat model.\n",
    "- Create tools using the @tool decorator, which simplifies the process of tool creation, supporting the following:\n",
    "- - Automatically infer the tool's name, description and expected arguments, while also supporting customization.\n",
    "- - Defining tools that return artifacts (e.g. images, dataframes, etc.)\n",
    "- - Hiding input arguments from the schema (and hence from the model) using injected tool arguments.\n",
    " \n",
    "The tool interface is defined in the BaseTool class which is a subclass of the Runnable Interface.\n",
    "\n",
    "Parameters for BaseTool:\n",
    "- tool_input\n",
    "- verbose\n",
    "- start_color\n",
    "- color\n",
    "- callbacks\n",
    "- tags\n",
    "- metadata\n",
    "- run_name\n",
    "- run_id\n",
    "\n",
    "Key attributes to the tool's schema\n",
    "- name: name of the tool\n",
    "- description: a description of what the tool does\n",
    "- args: property that returns the JSON echmea for the tool's arguments\n",
    "\n",
    "Key methods\n",
    "- inboke: invokes the tool with the given arguments\n",
    "- ainvoke: invokes the tool with the given argument asynchronously\n",
    "\n",
    "Prebuilt tools in LangChain:\n",
    "- Search tools\n",
    "- Bash script tools\n",
    "- Youtube tools\n",
    "- Python REPl\n",
    "\n",
    "\n",
    "#### Building a Custom Tool\n",
    "Create tools using the @tool decorator\n",
    "\n",
    "Within LangChain framework, you have the BaseTool class, which is your blueprint to building a tool.\n",
    "\n",
    "The main components of this blueprint are as follows:\n",
    "- Name\n",
    "- Description\n",
    "- _run function: Default function that runs when tool is called\n",
    "- _arun function: Function if you want async running\n",
    "\n",
    "The name and description are required fields.\n",
    "\n",
    "Best practices for description field\n",
    "- Clearly state when to use the tool.\n",
    "- State how (especially if it's a more complicated tool).\n",
    "- State when to not use the tool.\n",
    "- - This is very useful when using multiple tools inside of an agetn. By being clear on when to not use the tool, you can really assist your LLM in becoming more accurate, as LLMs have the tendency to also just use a tool if they're not sure exeactly which one to use or if there isn't one that best matches its need.\n",
    "- - - Provide some examples of uing the tool.\n",
    "- - This one is great fro helping your LLM reason by seeing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9a7190-d869-4792-9abd-9f249e10d0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b:int) -> int:\n",
    "    \"\"\"Multiply two numbers\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eef4582-2c40-47f3-abaf-a93b4af78740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.invoke({\"a\": 2, \"b\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6c0070-c3ec-4277-a280-5e4d651b0605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "Multiply two numbers\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "print(multiply.name) # multiply\n",
    "print(multiply.description) # Multiply two numbers.\n",
    "print(multiply.args) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3b5eb2-e7e3-455d-9fae-c72e33d87307",
   "metadata": {},
   "source": [
    "Tools, has parameter \"response_format\"\n",
    "\n",
    "response_format: The tool response format. If \"content\" then the output of the tool is interpreted as the contents of a ToolMessage. If \"content_and_artifact\" then the output is expected to be a two-tuple corresponding to the (content, artifact) of a ToolMessage. Defaults to \"content\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafb2150-6650-45de-b9b3-195c8b78c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List, Tuple\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def generate_random_ints(min: int, max: int, size: int) -> Tuple[str, List[int]]:\n",
    "    \"\"\"Generate size random ints in the range [min, max].\"\"\"\n",
    "    array = [random.randint(min, max) for _ in range(size)]\n",
    "    content = f\"Successfully generated array of {size} random ints in [{min}, {max}].\"\n",
    "    return content, array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7395127-6ddb-4667-a749-f52e42006eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Successfully generated array of 10 random ints in [0, 9].'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_random_ints.invoke({\"min\": 0, \"max\": 9, \"size\": 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980045e2-a719-4df5-ab8c-78ff825156fd",
   "metadata": {},
   "source": [
    "In order to get back both the content and the artifacft, we need to invoke our model with a ToolCall (which is just aa dictionary with \"name\", \"args\", \"id\" and \"type\" keys), which has additional info needed to generate a ToolMessage like the tool call ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074e4519-1336-4edf-a297-ad5cf411cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = generate_random_ints.invoke(\n",
    "    {\n",
    "        \"name\": \"generate_random_ints\",\n",
    "        \"args\": {\"min\": 0, \"max\": 9, \"size\": 10},\n",
    "        \"id\": \"123\",  # required\n",
    "        \"type\": \"tool_call\",  # required\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc37511-38ac-4cd3-bdab-23e45bc88f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 9, 2, 8, 3, 9, 5, 0, 9]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f438d740-2e3f-4c32-a3e3-fa918a62283d",
   "metadata": {},
   "source": [
    "Tool calling with llm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7b08a8-68ad-4813-9794-e4ecf0eff6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"qwen2.5-coder:14b\", model_provider=\"ollama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbe025d-b260-49ba-a1a8-51e5c9b48c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'generate_random_ints',\n",
       "  'args': {'max': 24, 'min': 1, 'size': 6},\n",
       "  'id': '0fd71454-4578-48d4-b8dc-e65f081d3d3a',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools = llm.bind_tools([generate_random_ints])\n",
    "\n",
    "ai_msg = llm_with_tools.invoke(\"generate 6 positive ints less than 25\")\n",
    "ai_msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8c8e33-5ca9-48eb-9502-9c901f87de40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='Successfully generated array of 6 random ints in [1, 24].', name='generate_random_ints', tool_call_id='0d648ac0-0a93-425f-98a1-38e85c08b44c', artifact=[24, 15, 7, 20, 13, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_random_ints.invoke(ai_msg.tool_calls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5de59e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "\n",
    "class StringReverseTool(BaseTool):\n",
    "    name: str = \"String Reversal Tool\"\n",
    "    description: str = \"use this tool when you need to reverse a string\"\n",
    "\n",
    "    def _run(self, word: str) -> str:\n",
    "        return word[::-1]\n",
    "    \n",
    "    def _arun(self, word: str) -> str:\n",
    "        raise NotImplementedError(\"Async not supported by StringReverseTool\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9016b316-ca65-4418-8559-070d589fafcd",
   "metadata": {},
   "source": [
    "Tool call using a chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f748b0e2-85d9-4843-bcd6-a38072628317",
   "metadata": {},
   "source": [
    "# LangChain Expression Language (LCEL)\n",
    "LCEL takes declarative approach to building new Runnables from existing Runnables.\n",
    "\n",
    "This means you describe what should happen, rather than how it should happen, allowing Langchain to optimize the run-time execution of the chains.\n",
    "\n",
    "a chain is runnable, and it implements the full runnable interface\n",
    "\n",
    "\n",
    "the pipe operator in langchain | , means that the operands a run in sequence\n",
    "\n",
    "a | b, a then b, and the result of a is the input of b\n",
    "\n",
    " In LangChain, the pipe operator (|) is overloaded for runnables so that when you write a | b, it creates a sequence where:\n",
    "\n",
    "- a is executed first.\n",
    "- The output of a is passed as the input to b.\n",
    "This operator essentially composes two runnables into a pipeline, enabling you to build complex workflows by chaining simple components together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3f2b46-2d17-4fe2-b519-b60b0fc75c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolMessage(content='Successfully generated array of 1 random ints in [1, 5].', name='generate_random_ints', tool_call_id='7569e5cb-de1a-4087-8bc1-3ed3ad5e9912', artifact=[4])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import attrgetter\n",
    "\n",
    "\n",
    "chain.invoke(\"give me a random number between 1 and 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a828394d-1959-4a74-82de-fcc20702e2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from operator import attrgetter\n",
    "\n",
    "import langsmith\n",
    "from langchain_core.tracers.context import tracing_v2_enabled\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "langsmith_client = langsmith.Client(\n",
    " api_key=os.environ.get(\"LANGSMITH_API_KEY\"),\n",
    " api_url='https://api.smith.langchain.com'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4415bdf2-58fe-4587-a52f-632b67018fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "chain = llm_with_tools | attrgetter(\"tool_calls\") | generate_random_ints.map()\n",
    "\n",
    "with tracing_v2_enabled(client=langsmith_client, project_name=\"chaining\"):\n",
    "    chain.invoke(\"give me a random number between 1 and 5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8588b0c0-ed16-4d19-9397-608398e87cf5",
   "metadata": {},
   "source": [
    "### How to chain runnables\n",
    "One point of LCEL is that any 2 runnables can be chained together into sequences. the output of the previous runnabls `.invoke()` call is passed as input to the next runnable. this can be done using the pipe operator `|` or more explicit `.pipe()` mehod.\n",
    "\n",
    "### | operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bcc960-b335-4734-bde1-a4b800254865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"qwen2.5-coder:14b\", model_provider=\"ollama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b26d47e-c86c-4eaf-bc49-1eaa33296f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "with tracing_v2_enabled(client=langsmith_client, project_name=\"pipe\"):\n",
    "    chain.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d55ce81-6100-4522-886b-b5daf3f4e276",
   "metadata": {},
   "source": [
    "#### Coercion\n",
    "Combine this chain with more runnables to create another chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c8df55-ced9-4046-bb56-e9ccdba4055e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, that is indeed a funny joke! It plays on the stereotypes of bears being slow and cheetahs being fast, with a clever punchline that suggests the bear doesn't want to play poker because there are too many \"cheetahs\" (cheaters). The humor comes from the unexpected comparison and the wordplay.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "analysis_prompt = ChatPromptTemplate.from_template(\"is this a funny joke? {joke}\")\n",
    "\n",
    "composed_chain = {\"joke\": chain} | analysis_prompt | model | StrOutputParser()\n",
    "\n",
    "with tracing_v2_enabled(client=langsmith_client, project_name=\"coercion\"):\n",
    "    result = composed_chain.invoke({\"topic\": \"bears\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549a0a99-fb72-41b5-98f3-31dd7134d59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translate {input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "with tracing_v2_enabled(client=langsmith_client, project_name=\"chaining\"):\n",
    "    result = chain.invoke(\n",
    "        {\n",
    "            \"input_language\": \"English\",\n",
    "            \"output_language\": \"German\",\n",
    "            \"input\": \"I love programming.\",\n",
    "        }\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7209220-a320-4f03-a11d-c67204c81105",
   "metadata": {},
   "source": [
    "### Tool calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2850c3c3-493b-45a9-9aeb-d692e30a5542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'validate_user', 'args': {'addresses': ['123 Fake St, Boston, MA', '234 Pretend Blvd, Houston, TX'], 'user_id': 123}, 'id': 'e464de9c-437b-439c-84f2-80929ad871e3', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "@tool\n",
    "def validate_user(user_id: int, addresses: List[str]) -> bool:\n",
    "    \"\"\" Validate user using historical addresses.\n",
    "\n",
    "    Args:\n",
    "        user_id (int): the user ID.\n",
    "        addresses list[str]): Previous addresses as a list of strings.\n",
    "    \"\"\"\n",
    "    return True\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"qwen2.5-coder:14b\",\n",
    "    temperature=0,\n",
    ").bind_tools([validate_user])\n",
    "\n",
    "with tracing_v2_enabled(client=langsmith_client, project_name=\"chaining\"):\n",
    "    result = llm.invoke(\n",
    "        \"Could you validate user 123? They previously lived at \"\n",
    "        \"123 Fake St in boston MA and 234 Pretend Blvd in \"\n",
    "        \"Houston Tx.\"\n",
    "    )\n",
    "print(result.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334e406e-e871-4f54-a280-7fe6c710af93",
   "metadata": {},
   "source": [
    "# Agents\n",
    "Agents are systems that use LLMs as reasoning engines to determine which actions to take and the inputs necessary to perform the action. After executing actions, the reqults can be fed back into the LLM to determine whether more actions are needed, or whether it is okay to finish. this is often achieved via tool-calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b88a68-b2ed-4a29-9959-208b8043b828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m28 packages\u001b[0m \u001b[2min 567ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 105ms\u001b[0m\u001b[0m                                             \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 13ms\u001b[0m\u001b[0m=2.0.16                         \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlanggraph\u001b[0m\u001b[2m==0.2.74\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlanggraph-checkpoint\u001b[0m\u001b[2m==2.0.16\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlanggraph-sdk\u001b[0m\u001b[2m==0.1.53\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! uv pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b687fb-3e8f-4a5b-9033-3efc32956fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
    "  os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter API key for tavily: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7468957c-dc93-44bd-b05d-707eea4948e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Create the agent\n",
    "memory = MemorySaver()\n",
    "model = ChatOllama(model=\"qwen2.5-coder:14b\")\n",
    "search = TavilySearchResults(max_results=2)\n",
    "tools = [search]\n",
    "agent_executor = create_react_agent(model, tools, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ee3915-1d13-4e7c-b0d2-be43c3ce20ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi im bob! and i live in sf\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Bob! It's nice to meet you. How can I assist you today? If you have any questions or need information, feel free to let me know.\n"
     ]
    }
   ],
   "source": [
    "# Use the agent\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "with tracing_v2_enabled(client=langsmith_client, project_name=\"agent\"):\n",
    "    for step in agent_executor.stream(\n",
    "        {\"messages\": [HumanMessage(content=\"hi im bob! and i live in sf\")]},\n",
    "        config,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d645d623-a46b-4745-98ac-83b1eada2824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "whats the weather where I live?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (cf3935f6-06d7-4530-a8eb-75ef67ab9540)\n",
      " Call ID: cf3935f6-06d7-4530-a8eb-75ef67ab9540\n",
      "  Args:\n",
      "    query: current weather in San Francisco\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.775, 'lon': -122.4183, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1740102873, 'localtime': '2025-02-20 17:54'}, 'current': {'last_updated_epoch': 1740102300, 'last_updated': '2025-02-20 17:45', 'temp_c': 15.2, 'temp_f': 59.4, 'is_day': 1, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/day/116.png', 'code': 1003}, 'wind_mph': 6.0, 'wind_kph': 9.7, 'wind_degree': 284, 'wind_dir': 'WNW', 'pressure_mb': 1020.0, 'pressure_in': 30.11, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 67, 'cloud': 75, 'feelslike_c': 15.2, 'feelslike_f': 59.4, 'windchill_c': 11.8, 'windchill_f': 53.2, 'heatindex_c': 12.4, 'heatindex_f': 54.4, 'dewpoint_c': 10.8, 'dewpoint_f': 51.4, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 0.1, 'gust_mph': 9.3, 'gust_kph': 14.9}}\"}, {\"url\": \"https://world-weather.info/forecast/usa/san_francisco/february-2025/\", \"content\": \"Weather in San Francisco in February 2025 (California) - Detailed Weather Forecast for a Month Weather World Weather in San Francisco Weather in San Francisco in February 2025 San Francisco Weather Forecast for February 2025, is based on previous years' statistical data. +59°+50° +59°+52° +59°+50° +61°+52° +59°+50° +61°+50° +61°+52° +63°+52° +61°+52° +61°+50° +61°+50° +61°+50° +59°+50° +59°+50° +61°+50° +61°+52° +59°+50° +59°+48° +57°+48° +59°+50° +59°+48° +59°+50° +57°+46° +61°+50° +61°+50° +59°+50° +59°+48° +59°+50° Extended weather forecast in San Francisco HourlyWeek10-Day14-Day30-DayYear Weather in large and nearby cities Weather in Washington, D.C.+41° Sacramento+55° Pleasanton+55° Redwood City+55° San Leandro+55° San Mateo+54° San Rafael+52° San Ramon+52° South San Francisco+54° Vallejo+50° Palo Alto+55° Pacifica+55° Berkeley+54° Castro Valley+55° Concord+52° Daly City+54° Noverd+52° Sign Hill+54° world's temperature today day day Temperature units\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for providing that information. Based on the data from WeatherAPI.com, here is a summary of the current weather in San Francisco:\n",
      "\n",
      "- **Location**: San Francisco, California, United States of America\n",
      "- **Local Time**: February 20, 2025, at 17:54 (Pacific Standard Time)\n",
      "- **Temperature**: 15.2°C or 59.4°F\n",
      "- **Condition**: Partly cloudy\n",
      "- **Wind Speed**: 6.0 mph or 9.7 kph from the WNW direction\n",
      "- **Pressure**: 1020.0 mb or 30.11 inHg\n",
      "- **Precipitation**: 0.0 mm or 0.0 inches\n",
      "- **Humidity**: 67%\n",
      "- **Cloud Cover**: 75%\n",
      "\n",
      "If you need more detailed information or forecasts, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "with tracing_v2_enabled(client=langsmith_client, project_name=\"agent\"):\n",
    "    for step in agent_executor.stream(\n",
    "        {\"messages\": [HumanMessage(content=\"whats the weather where I live?\")]},\n",
    "        config,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d94e12",
   "metadata": {},
   "source": [
    "# Memory\n",
    "There are 4 types of memory in langchain\n",
    "\n",
    "1. ConversationBufferWindowMemory\n",
    "2. ConversationSummaryMemory\n",
    "3. ConversationSummaryBufferMemory\n",
    "4. ConversationTokenBufferMemory\n",
    "\n",
    "## ConversationBufferMemory\n",
    "A flexible memory buffer for chat conversation. It allows you to access the chat history in  formats:\n",
    "1. As a string (`buffer_as_str`)\n",
    "2. As a list of message objects (`buffer_as_messages`)\n",
    "\n",
    "The class provides a `load_memory_variables` method that returns the chat history based on a chosen format. This output can then be used as context to your LLM, thereby rpoviding it info on the previous parts of the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df5bf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 6ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! uv pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec04486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'Human: What is the capital of the UK\\nAI: London'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "llm: OllamaLLM = OllamaLLM(model=\"qwen2.5-coder:14b\")\n",
    "\n",
    "memory: ConversationBufferMemory = ConversationBufferMemory()\n",
    "\n",
    "memory.save_context(\n",
    "    {\"input\": \"What is the capital of the UK\"},\n",
    "    {\"output\": \"London\"},\n",
    ")\n",
    "\n",
    "print(memory.load_memory_variables({}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5b000e",
   "metadata": {},
   "source": [
    "Here you are adding some history into your memory buffer. Right now, nothing is being passed into an LLM, but you can see the output of what would be passed to the LLM.\n",
    "\n",
    "The prompt would include the \"history\", the \"Human\" and \"AI\" conversation thereby giving the LLM context into the conversation.\n",
    "\n",
    "In other words, ConversationBufferMemory is a simle way of representing historical context as a string that can be parsed and passed into a prompt.\n",
    "\n",
    "Notice that the ConversationBufferMemory automatically formatted your input and output into the format of Human and AI conversation. This is the default, but you can change it using these variables:\n",
    "\n",
    "`human_prefix` and `ai_prefix`\n",
    "\n",
    "Ex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fc8c002f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'Aarushi: What is the capital of the UK\\nHermione: London'}\n"
     ]
    }
   ],
   "source": [
    "memory: ConversationBufferMemory = ConversationBufferMemory(\n",
    "    human_prefix=\"Aarushi\",\n",
    "    ai_prefix=\"Hermione\"\n",
    ")\n",
    "\n",
    "memory.save_context(\n",
    "    {\"input\": \"What is the capital of the UK\"},\n",
    "    {\"output\": \"London\"},\n",
    ")\n",
    "\n",
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57df4533",
   "metadata": {},
   "source": [
    "LangChain has built-in chain for chaining prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "98b70954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: What is the largest city in the UK by population?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Aarushi: What is the largest city in the UK by population?\n",
      "Hermione: The largest city in the United Kingdom by population is London. As of the latest data available, the estimated population of London is approximately 9 million people.\n",
      "Human: And second?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Aarushi: What is the largest city in the UK by population?\n",
      "Hermione: The largest city in the United Kingdom by population is London. As of the latest data available, the estimated population of London is approximately 9 million people.\n",
      "Aarushi: And second?\n",
      "Hermione: The second-largest city in the United Kingdom by population is Birmingham, with an estimated population of around 2.6 million people.\n",
      "Human: What about in Germany?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Aarushi: What is the largest city in the UK by population?\n",
      "Hermione: The largest city in the United Kingdom by population is London. As of the latest data available, the estimated population of London is approximately 9 million people.\n",
      "Aarushi: And second?\n",
      "Hermione: The second-largest city in the United Kingdom by population is Birmingham, with an estimated population of around 2.6 million people.\n",
      "Aarushi: What about in Germany?\n",
      "Hermione: The largest city in Germany by population is Berlin, with an estimated population of around 3.7 million people as of the latest data available. The second-largest city in Germany is Hamburg, which has an estimated population of approximately 1.9 million people.\n",
      "Human: \n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today? If you have any questions or need information on a specific topic, feel free to ask!'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "llm: OllamaLLM = OllamaLLM(model=\"qwen2.5-coder:14b\")\n",
    "conversation: ConversationChain = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferMemory(\n",
    "        human_prefix=\"Aarushi\",\n",
    "        ai_prefix=\"Hermione\"\n",
    "    )\n",
    ")\n",
    "\n",
    "conversation.predict(input=\"What is the largest city in the UK by population?\")\n",
    "\n",
    "conversation.predict(input=\"And second?\")\n",
    "\n",
    "conversation.predict(input=\"What about in Germany?\")\n",
    "\n",
    "# just ot run one more time\n",
    "conversation.predict(input=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278aa85d",
   "metadata": {},
   "source": [
    "Conditions about history as memory\n",
    "1. Generally, LLMs have a maximum context length - meaning you can only really send a prompt of a certain size.\n",
    "2. The larger your history or prompt, LLMs tend to start ignoring or missing older pieces of information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e507fac3",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory\n",
    "Is a variant of ConversationBuffer; it also keeps a history of your interactions, but only up to k number. This is a number you can decide on for your own needs - in my expereience, I have found that for most use cases a larger number is actually detrimental and the model ends up hallucinating more ofteehan than not. I would recommend you experiment and find a balance of short but informational queries combined with a smaller window (k).\n",
    "\n",
    "\n",
    "## ConversationSummaryMemory\n",
    "Is a type of memory that condenses down your conversation into a sumamry that can be passed into your LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fe31841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: How are you Hermione?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Aarushi inquires about Hermione's wellbeing. Hermione responds that as a computer program, she lacks emotions but is available to assist with any inquiries or tasks.\n",
      "Human: What is the third planet from the sun?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Aarushi inquires about Hermione's wellbeing. Hermione responds that as a computer program, she lacks emotions but is available to assist with any inquiries or tasks. Aarushi then asks what the third planet from the sun is, and Hermione correctly identifies it as Earth, describing its significance as home to various life forms.\n",
      "Human: second?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Aarushi inquires about Hermione's wellbeing, to which Hermione, being a computer program, responds that she lacks emotions but is available for assistance with inquiries or tasks. Aarushi then asks about the third planet from the sun, which Hermione correctly identifies as Earth, describing it as home to various life forms. When asked about the second planet from the sun, Hermione identifies it as Venus and explains its similarities to Earth while noting the differences in atmospheric composition and surface temperatures due to the greenhouse effect.\n",
      "Human: fifth?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Aarushi inquires about Hermione's wellbeing, to which Hermione, being a computer program, responds that she lacks emotions but is available for assistance with inquiries or tasks. Aarushi then asks about the third planet from the sun, which Hermione correctly identifies as Earth, describing it as home to various life forms. When asked about the second planet from the sun, Hermione identifies it as Venus and explains its similarities to Earth while noting the differences in atmospheric composition and surface temperatures due to the greenhouse effect. Aarushi then asks about the fifth planet from the sun, which Hermione correctly identifies as Jupiter, describing it as a gas giant with a prominent Great Red Spot and at least 79 moons, including the Galilean moons Io, Europa, Ganymede, and Callisto.\n",
      "Human: \n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AI: Hello! How can I assist you today? If you have any questions or need information on various topics, feel free to ask!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "llm: OllamaLLM = OllamaLLM(model=\"qwen2.5-coder:14b\")\n",
    "conversation_with_summary: ConversationChain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=ConversationSummaryMemory(\n",
    "        llm=llm,\n",
    "        human_prefix=\"Aarushi\",\n",
    "        ai_prefix=\"Hermione\"\n",
    "    ),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "conversation_with_summary.predict(input=\"How are you Hermione?\")\n",
    "conversation_with_summary.predict(input=\"What is the third planet from the sun?\")\n",
    "conversation_with_summary.predict(input=\"second?\")\n",
    "conversation_with_summary.predict(input=\"fifth?\")\n",
    "conversation_with_summary.predict(input=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4af802",
   "metadata": {},
   "source": [
    "### ConversationSummaryBufferMemory\n",
    "Combines both summaries and buffer, keep summary of previous interactions.\n",
    "Instead of keeping only the summary or previous interactions, it keeps interactions in a bufer as well as a summary. \n",
    "It keeps more recent interactions in a buffer and older ones as a summary (once the buffer hit. a certeain token length you can tune.\n",
    "\n",
    "### ConversationTokenBufferMemory\n",
    "Similar to ConversationBufferWindowMemory but instead maintains a buffer of x tokens length rather than x number of interactions length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d08996f",
   "metadata": {},
   "source": [
    "## Retrieval\n",
    "Retrieval is a way of giving an LLM more specefic, niche knowledge. It involves fetching data from sone external source and passing it into your chosen LLM.\n",
    "\n",
    "The end-to-end flow of fetching info, passing it into an LLM, and the LLM generating a response is known as Retrieval Augmented Generation (RAG).\n",
    "\n",
    "### RAG\n",
    "Since we're generally dealing with natural language and often unstructured and messy data, the most popular (for good reason) storage system is a vector store. This is essentially involves taking all of your niche data, creating a vector embedding, and storing in a vector database.\n",
    "\n",
    "#### Embedding\n",
    "Embeddings is a way of representing data (eg., text, audio, images etc) as numbers. All ML models are basically math equations so they don't actually understand or perceive words or images or anything else the way humans can with our 5 senses, they only understand numbers. \n",
    "\n",
    "That is why to deal with language, we need to convert words and senstense into a numerical representation that ML models can understand. The term \"embeddings\" is a general term for taking one type of data and representing it in numbers. Embeddings comes in different types, such as graph embeddings, tensor embeddings and many more.\n",
    "\n",
    "In the context of LLMs, we're talking about vector embeddings and you'll see vector embeddings and embeddings used interchangeably.\n",
    "\n",
    "##### Vector Embeddings\n",
    "Vector embeddings are a specific type of embedding where the representation is in the form of a vector. This means that the data, regardless of its original form is translated into a fixed length list of numbers.\n",
    "Vector embeddings are commonly used in natural languate processing where words or phrases are represented as vectors.\n",
    "\n",
    "Benefits of vectors\n",
    "- ability to be represented in high dimensions\n",
    "- use geometric relationship between vectors to model semantic or functional relationships\n",
    "\n",
    "Benefits of vectors is the ability to be represented in high dimensional spaces, which means that a vast number of features or espects of language can be captured. Each dimension can potentially represent some facet of meanings, allowing the vector to encapsulate a rich set of semantic information.\n",
    "\n",
    "And because vectors are basically long list of numbers, we can do mathematical computations on data that normally wouldn't be possible.\n",
    "\n",
    "For example:\n",
    "\n",
    "\\begin{align}\n",
    "vector(Germany) - vector(Berlin) + vector(France) &= vector(Paris)  \n",
    "\\end{align}\n",
    "\n",
    "This shows that the difference between a country and its capital can be consistently represented in the vector space. So by knowing the capital of Germany and applying this relationship to France, we can deduce the capital of France.\n",
    "\n",
    "\n",
    "Another benefit of vector embedding embeddings is that we can use geometric relationships between vectors to model semantic or functional relationships. Eg. in word embeddings, the vector difference between \"dolphin\" and \"ocean\" might be similar to the difference between \"camel\" and \"desert\", reflecting habitat relationships.\n",
    "\n",
    "We can use vector embeddings to model intricate adn complex semantic meanings and relationships between words and text.\n",
    "\n",
    "To embed text/words you need embedding models\n",
    "\n",
    "List of embedding models\n",
    "- OpenAIs `text-embedding-ada-002`\n",
    "- Cohere's embedding models\n",
    "- `bge-large`\n",
    "- `nomic-embed-text`\n",
    "- `llama3`\n",
    "\n",
    "Steps for taking unstructured raw data and converting to an embedding\n",
    "\n",
    "User data -> Embedding Model -> Vector Embedding `[0.23, 0.11, -1.3, 2, ....]`\n",
    "\n",
    "Now you have these embeddings - you will need to store it somewhere so your LLM can search for the data as an external data sources.\n",
    "\n",
    "### Vector Stores\n",
    "Lists of VectorDBs\n",
    "- Weaviate\n",
    "- Pinecone\n",
    "- Chroma\n",
    "- Qdrant\n",
    "- Traditional DBs that support vecto embeddings\n",
    "\n",
    "List of VectorDBs that langchain supports\n",
    "https://python.langchain.com/docs/integrations/vectorstores/\n",
    "\n",
    "Vector DBs are designed to store high dimensional data like embeddings and allow for fast querying and lookups. They have the capabilities of traditional databases, while being optimized to handle the complexity of vector embeddings.\n",
    "\n",
    "When you create + store an embedding, a reference to the original data is stored. Then you make a query to the DB, the query is converted to an embedding (using the same model), and this embedding is sued to find the most similar content and return it to you.\n",
    "\n",
    "Search\n",
    "\n",
    "Query -> Emvedding Model -> Original Content `[0.23, 0.11, -1.3, 2, ....]` ->\n",
    " User -> Query\n",
    "\n",
    " Unlike traditional databases that are optimized to search for exact values - a number, string, or some single dimensional exact value, vector databases are optimized to search ofr vectors (high dimensional data) that are most similar, not exact to another query vector.\n",
    "\n",
    "To do this, vector databases store your data in structures taht allow for fast querying - called indexes. These indexes are created using a variety of algorithms. Example of algorithms:\n",
    "- Random Projection\n",
    "- Product Quantization\n",
    "- Local-Sensitive Hashing\n",
    "- Hierarchical Navigable Small World\n",
    "\n",
    "When the query comes in, these DBs make use of various algirithms to do an Approximate Nearest Neightbor (ANN) search to get the most similar matches based on some similarity metrics, such as cosine similarity, dot product, Euclidean distance, or Hamming distance."
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f079b45",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# save as docker-compose.yml\n",
    "# run `sudo docker compose up`\n",
    "---\n",
    "services:\n",
    "  weaviate:\n",
    "    command:\n",
    "    - --host\n",
    "    - 0.0.0.0\n",
    "    - --port\n",
    "    - '8089'\n",
    "    - --scheme\n",
    "    - http\n",
    "    image: cr.weaviate.io/semitechnologies/weaviate:1.29.1\n",
    "    ports:\n",
    "    - 8089:8089\n",
    "    - 50051:50051\n",
    "    volumes:\n",
    "    - weaviate_data:/var/lib/weaviate\n",
    "    restart: on-failure:0\n",
    "    environment:\n",
    "      QUERY_DEFAULTS_LIMIT: 25\n",
    "      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n",
    "      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n",
    "      ENABLE_API_BASED_MODULES: 'true'\n",
    "      ENABLE_MODULES: 'text2vec-ollama,generative-ollama'\n",
    "      CLUSTER_HOSTNAME: 'node1'\n",
    "volumes:\n",
    "  weaviate_data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4accc708",
   "metadata": {},
   "outputs": [],
   "source": [
    "! uv pip install weaviate weaviate-client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260b68e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from weaviate import Client as WeaviateClient\n",
    "\n",
    "with weaviate.connect_to_local(port=8089) as client:\n",
    "    # Perform operations with the client\n",
    "    print(client.is_ready())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
