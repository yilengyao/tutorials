{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ced042c-e352-44cb-b52d-ab30e4fd1ad4",
   "metadata": {},
   "source": [
    "# Architecture\n",
    "- langchain-core: Base abstraction for chat models and other components\n",
    "- Integration packages (eg. langchain-openai, langchain-anthropic, etc.): Important integrations have been split into lightweight packages that are co-maintained by the Langchain team and the integration developers.\n",
    "- langchain: Chains, agents and retrieval strategies that make up an application's cognitive architecture.\n",
    "- langchain-community: Third-party integration that are community maintained.\n",
    "- langgraph: Orchestration framework for combining Langchain components into production ready applications with persistence streaming and other key featues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785ea8f4-cd62-4485-b73b-e10824b886ea",
   "metadata": {},
   "source": [
    "### BaseChatModel\n",
    "Base class for chat models\n",
    "\n",
    "Method|Input|Output|Description|\n",
    "|--|--|--|--|\n",
    "|invoke|str List[dict tuple BaseMessage] PromptValue|BaseMessage|A single chat model call.|\n",
    "|ainvoke|\"|BaseMessage|Defaults to running invoke in an async executor|\n",
    "|stream|‘’’|Iterator[BaseMessageChunk]|Defaults to yielding output of invoke.|\n",
    "|astream|‘’’|AsyncIterator[BaseMessageChunk]|Defaults to yielding output of ainvoke.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16be87d9-c0ca-4cf6-954f-2cb2e4d1539b",
   "metadata": {},
   "source": [
    "RunnableLambda converts python callable into a runnable.\n",
    "\n",
    "Callable is any object called like a function, eg. Functions, Methods, Classes, Instances with method `__call__`.\n",
    "\n",
    "Runnable is a interface that has invoke method.\n",
    "\n",
    "So we add the invoke method to the callable when we convert to RunnableLambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef3b0d85-e63e-4406-99f0-d635c79a209a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a RunnableLambda\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def add_one(x: int) -> int:\n",
    "    return x + 1\n",
    "\n",
    "runnable = RunnableLambda(add_one)\n",
    "\n",
    "runnable.invoke(1) # returns 2\n",
    "runnable.batch([1, 2, 3]) # returns [2, 3, 4]\n",
    "\n",
    "# Async is supported by default by delegating to the sync implementation\n",
    "await runnable.ainvoke(1) # returns 2\n",
    "await runnable.abatch([1, 2, 3]) # returns [2, 3, 4]\n",
    "\n",
    "async def add_one_async(x: int) -> int:\n",
    "    return x + 1\n",
    "\n",
    "runnable = RunnableLambda(add_one, afunc=add_one_async)\n",
    "runnable.invoke(1) # Uses add_one\n",
    "await runnable.ainvoke(1) # Uses add_one_async"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11675e58-c657-4ead-a655-e591ea2bbf14",
   "metadata": {},
   "source": [
    "#### format_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c555810-5ae4-4a17-94ad-6287a8e5855e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.schema import Document \n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def format_docs(docs: List[Document]) -> str:\n",
    "    '''Format the docs.'''\n",
    "    return \", \".join([doc.page_content for doc in docs])\n",
    "\n",
    "format_docs = RunnableLambda(format_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d35542-75b4-41e6-b9eb-dd8fad111ca0",
   "metadata": {},
   "source": [
    "#### some_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce9f96bd-da81-46bd-8381-1abcd9733bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def some_tool(x: int, y: str) -> dict:\n",
    "    '''Some_tool.'''\n",
    "    return {\"x\": x, \"y\": y}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be70c69-ec57-4d95-8ff9-9f5b2876eb01",
   "metadata": {},
   "source": [
    "#### prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28292ff9-a1db-4efb-870b-8ac8aca0cc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"You are Cat Agent 007\"), (\"human\", \"{question}\")]\n",
    ").with_config({\"run_name\": \"my_template\", \"tags\": [\"my_template\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16e48861-9205-4631-8a8f-702cdaee855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "async def reverse(s: str) -> str:\n",
    "    return s[::-1]\n",
    "\n",
    "chain = RunnableLambda(func=reverse)\n",
    "\n",
    "events = [\n",
    "    event async for event in chain.astream_events(\"hello\", version=\"v2\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23bc59ba-48cb-4dd5-bf66-4ec94aa60b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'event': 'on_chain_start',\n",
       "  'data': {'input': 'hello'},\n",
       "  'name': 'reverse',\n",
       "  'tags': [],\n",
       "  'run_id': 'f6e7e0f2-20db-4354-a7c1-c1e06f2408a6',\n",
       "  'metadata': {},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chain_stream',\n",
       "  'run_id': 'f6e7e0f2-20db-4354-a7c1-c1e06f2408a6',\n",
       "  'name': 'reverse',\n",
       "  'tags': [],\n",
       "  'metadata': {},\n",
       "  'data': {'chunk': 'olleh'},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chain_end',\n",
       "  'data': {'output': 'olleh'},\n",
       "  'run_id': 'f6e7e0f2-20db-4354-a7c1-c1e06f2408a6',\n",
       "  'name': 'reverse',\n",
       "  'tags': [],\n",
       "  'metadata': {},\n",
       "  'parent_ids': []}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726c88df-77be-4902-8a25-e5008b5dfd77",
   "metadata": {},
   "source": [
    "## Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c6bfb62-99ae-4119-89f7-ce28c4289180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"LANGSMITH_API_KEY\"):\n",
    "  os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter API key for LangSmith: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9350c1f2-03f8-48ae-9235-abb0c8a1ce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"pr-overcooked-push-81\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48c7a799-26c6-4eb6-b4b5-10ced0798c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langsmith\n",
    "from langchain_core.tracers.context import tracing_v2_enabled\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "langsmith_client = langsmith.Client(\n",
    " api_key=os.environ.get(\"LANGSMITH_API_KEY\"),\n",
    " api_url='https://api.smith.langchain.com'\n",
    ")\n",
    "with tracing_v2_enabled(client=langsmith_client, project_name=\"default\"):\n",
    "    model = init_chat_model(\"qwen2.5-coder:14b\", model_provider=\"ollama\")\n",
    "    model.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d3d3f7c-fcb6-4f70-bc3e-de6ff03f40e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={'model': 'qwen2.5-coder:14b', 'created_at': '2025-02-20T09:07:13.435388468Z', 'done': True, 'done_reason': 'stop', 'total_duration': 196595805, 'load_duration': 8046258, 'prompt_eval_count': 33, 'prompt_eval_duration': 24000000, 'eval_count': 10, 'eval_duration': 161000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-9ed2fd74-af36-41e6-9109-c53ad43b0b61-0', usage_metadata={'input_tokens': 33, 'output_tokens': 10, 'total_tokens': 43})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"qwen2.5-coder:14b\", model_provider=\"ollama\")\n",
    "model.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36809918-71a1-4bdf-9163-6fef697bcc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'aime programmer.\", additional_kwargs={}, response_metadata={'model': 'qwen2.5-coder:14b', 'created_at': '2025-02-20T20:48:27.384708338Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1888507642, 'load_duration': 1476506744, 'prompt_eval_count': 33, 'prompt_eval_duration': 98000000, 'eval_count': 6, 'eval_duration': 89000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-9dc166ca-0432-451c-a23b-2a3f6be96ba4-0', usage_metadata={'input_tokens': 33, 'output_tokens': 6, 'total_tokens': 39})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "import langsmith\n",
    "from langchain_core.tracers.context import tracing_v2_enabled\n",
    "langsmith_client = langsmith.Client(\n",
    " api_key='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',\n",
    " api_url='https://api.smith.langchain.com'\n",
    ")\n",
    "llm = ChatOllama(\n",
    "    model=\"qwen2.5-coder:14b\",\n",
    "    temperature=0,\n",
    "    # other params...\n",
    ")\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "with tracing_v2_enabled(client=langsmith_client, project_name=\"default\"):\n",
    "    ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab13ddcd-89e3-411e-bb2d-9dd144244a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b2e3eb7-bf30-4c4c-a148-d43fb3c4d9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 10ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m26 packages\u001b[0m \u001b[2min 297ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2mAudited \u001b[1m26 packages\u001b[0m \u001b[2min 0.16ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install langchain\n",
    "!uv pip install -U langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c230216f-c610-469e-8a79-7f45d12e030e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nAlright, I\\'m trying to figure out what LangChain is. I\\'ve heard the term before in the context of AI and machine learning, but I\\'m not exactly sure what it entails. Let me start by breaking down the name itself—LangChain. It sounds like a combination of \"language\" and something else, maybe related to chaining or processes.\\n\\nI remember that in AI, especially with large language models (LLMs), there\\'s been a lot of talk about chaining different tasks together to make them more efficient or powerful. So perhaps LangChain is a framework that helps in creating these chains of operations? I think I\\'ve heard it mentioned alongside tools like Chains, Agents, and something called the LangChain API.\\n\\nLet me consider what each part could mean. \"Chains\" in this context might refer to sequences of steps where an AI model interacts with other models or external tools. For example, maybe a chain involves first using one model for text generation and then another for image processing. Or perhaps it\\'s about how the system handles different tasks in sequence.\\n\\nI\\'ve also come across terms like Agents within LangChain. I believe agents are supposed to be more advanced than simple chains because they can make decisions on which steps to take next. So an agent might analyze a problem, decide what tools to use (like calling another model or accessing external data), and then proceed accordingly. This would make the system more dynamic and capable of handling complex tasks.\\n\\nThen there\\'s the LangChain API. APIs are application programming interfaces that allow different software components to communicate. So the LangChain API might be a set of tools that lets developers integrate various AI models and services into their applications, making it easier to build sophisticated workflows without having to code everything from scratch.\\n\\nPutting this together, LangChain seems like a comprehensive framework designed to help developers build complex AI applications by providing tools for chaining operations, creating intelligent agents, and integrating with APIs. It\\'s probably used in scenarios where you need more than just simple text generation—like when you want an AI system to perform multiple steps, access external data, or interact with other services.\\n\\nI should also consider the use cases. Maybe LangChain is useful for things like chatbots that can do more than just respond to messages; they could look up information online, analyze data, or even control other systems. It might be applied in customer service, healthcare (for example, analyzing patient data and recommending treatments), or any field where AI needs to perform a series of tasks in sequence.\\n\\nI wonder how LangChain differs from other AI frameworks like TensorFlow or PyTorch. I think those are more about the underlying models and computations, whereas LangChain is higher-level, focusing on orchestrating different models and tools together. So while TensorFlow might handle the training of an individual model, LangChain would manage how that model interacts with others in a chain or agent setup.\\n\\nAnother aspect could be extensibility. With LangChain, developers can plug in various AI services and models as needed. This modular approach allows for flexibility—adding new tools without rewriting everything from the ground up. It also supports scalability, meaning you can handle more complex tasks as your needs grow.\\n\\nI\\'m trying to think if there are any limitations or challenges with using LangChain. One potential issue might be complexity—since it\\'s a framework that connects multiple components, managing all those parts could become complicated, especially for large-scale applications. Additionally, setting up the chains and agents correctly might require a good understanding of how each component interacts and how to optimize their performance together.\\n\\nI should also consider documentation and community support. If LangChain is well-documented with active community contributions, it would make adoption easier. Conversely, if there\\'s a lack of resources or updates, that could be a barrier for developers looking to implement it in their projects.\\n\\nIn summary, my understanding is that LangChain is a framework designed to facilitate the creation of complex AI workflows by enabling the chaining of different models and tools, allowing for more intelligent and dynamic applications. It provides components like Chains and Agents, along with an API for integration, making it a versatile tool for developers working on sophisticated AI projects.\\n</think>\\n\\nLangChain is a comprehensive framework designed to enable developers to build complex AI applications by orchestrating various models and tools. Here\\'s a detailed overview:\\n\\n1. **Core Components**:\\n   - **Chains**: These are sequences of operations where AI models interact with each other or external tools, allowing for multi-step problem-solving.\\n   - **Agents**: More advanced than chains, agents can make decisions on which steps to take next, enabling dynamic handling of complex tasks by choosing appropriate tools or models.\\n\\n2. **Functionality**:\\n   - LangChain provides a higher-level abstraction compared to frameworks like TensorFlow or PyTorch, focusing on orchestrating different AI components rather than just model training.\\n   - The framework includes an API that facilitates integration with various AI services and external data sources, allowing for the creation of sophisticated workflows.\\n\\n3. **Use Cases**:\\n   - Ideal for applications requiring multi-step operations, such as chatbots that perform online lookups or healthcare systems analyzing patient data.\\n   - Suitable for customer service, healthcare, and other fields where dynamic task sequences are necessary.\\n\\n4. **Advantages**:\\n   - Extensibility: Allows developers to integrate various AI services and models easily.\\n   - Scalability: Supports growing complexity in applications as needs expand.\\n\\n5. **Considerations**:\\n   - Potential complexity in managing multiple components, especially for large-scale applications.\\n   - Requires a good understanding of component interactions and optimization for effective implementation.\\n\\n6. **Community and Documentation**:\\n   - The success of LangChain depends on its documentation and community support, which are crucial for adoption and troubleshooting.\\n\\nIn essence, LangChain is a versatile tool that empowers developers to create intelligent, dynamic AI applications by integrating diverse models and tools into efficient workflows.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "deepseek_model = OllamaLLM(model=\"deepseek-r1:14b\")\n",
    "\n",
    "deepseek_chain = prompt | deepseek_model\n",
    "\n",
    "deepseek_chain.invoke({\"question\": \"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "860b23db-5020-4265-85c0-6606e8ca7195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain is an open-source framework designed to simplify the development of language models and applications built on them. Here’s how we can break down its key features and components:\\n\\n1. **Modularity**: LangChain emphasizes modularity, allowing developers to easily integrate different components such as data connectors, text processing tools, and machine learning models.\\n\\n2. **Ease of Use**: It provides a user-friendly interface that abstracts the complexities of language model development, making it accessible for both beginners and experienced developers.\\n\\n3. **Scalability**: The framework is designed to scale efficiently, supporting large datasets and high traffic loads by leveraging cloud resources and distributed computing.\\n\\n4. **Integration with Existing Tools**: LangChain can integrate seamlessly with existing tools and platforms, enhancing the capabilities of pre-existing applications without significant overhauls.\\n\\n5. **Community Support**: Being open-source, LangChain benefits from a vibrant community that contributes to its development, providing support through forums, documentation, and regular updates.\\n\\n6. **Flexibility**: Users can customize the framework according to their specific needs, tailoring it to fit particular use cases or projects.\\n\\nIn summary, LangChain is a versatile and powerful toolset for developers looking to work with language models, offering both ease of integration and advanced capabilities for building sophisticated applications.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "qwen_model = OllamaLLM(model=\"qwen2.5-coder:14b\")\n",
    "\n",
    "qwen_chain = prompt | qwen_model\n",
    "\n",
    "qwen_chain.invoke({\"question\": \"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf78c3c6-c196-4437-947b-3c1a1dda3c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Step 1: Understand the problem.\\nThe question is asking for the product of 5 and 5.\\n\\nStep 2: Recall multiplication basics.\\nMultiplication is essentially repeated addition. When we multiply 5 by 5, it means adding 5 to itself 5 times.\\n\\nStep 3: Perform the calculation.\\nLet's add 5 to itself 5 times:\\n5 + 5 = 10\\n10 + 5 = 15\\n15 + 5 = 20\\n20 + 5 = 25\\n\\nStep 4: Verify the result.\\nWe can double-check our answer by using a different method, such as multiplying in reverse (5 * 5 is the same as 5 * 5).\\n\\nAnswer: The product of 5 and 5 is 25.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwen_chain.invoke({\"question\": \"What is 5*5?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30cb1c45-6166-48ba-bd75-b086d95d76a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nFirst, I need to identify the two numbers that are being multiplied in the expression 5 times 5.\\n\\nNext, I will perform the multiplication operation by multiplying these two numbers together.\\n</think>\\n\\n**Solution:**\\n\\nTo find the product of \\\\(5 \\\\times 5\\\\), follow these simple steps:\\n\\n1. **Identify the Numbers:**\\n   - The first number is **5**.\\n   - The second number is also **5**.\\n\\n2. **Multiply the Two Numbers:**\\n   \\n   \\\\[\\n   5 \\\\times 5 = 25\\n   \\\\]\\n\\n3. **Final Answer:**\\n\\n   \\\\[\\n   \\\\boxed{25}\\n   \\\\]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepseek_chain.invoke({\"question\": \"What is 5*5?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0acacd0-c804-48cf-b844-04f508076681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To calculate \\\\(2555 \\\\times 2555\\\\), we can break down the multiplication into simpler steps using the distributive property of multiplication over addition.\\n\\nFirst, let's express 2555 as a sum of more manageable numbers:\\n\\\\[ 2555 = 2000 + 500 + 50 + 5 \\\\]\\n\\nNow, we can use the distributive property to multiply each part by itself:\\n\\n1. \\\\(2000 \\\\times 2000\\\\)\\n2. \\\\(2000 \\\\times 500\\\\)\\n3. \\\\(2000 \\\\times 50\\\\)\\n4. \\\\(2000 \\\\times 5\\\\)\\n\\nAnd repeat for the second part:\\n\\n1. \\\\(500 \\\\times 2000\\\\)\\n2. \\\\(500 \\\\times 500\\\\)\\n3. \\\\(500 \\\\times 50\\\\)\\n4. \\\\(500 \\\\times 5\\\\)\\n\\nAnd so on, but since multiplication is commutative (\\\\(a \\\\times b = b \\\\times a\\\\)), we only need to calculate each unique pair once.\\n\\nLet's calculate them step by step:\\n\\n1. \\\\(2000 \\\\times 2000 = 4,000,000\\\\)\\n2. \\\\(2000 \\\\times 500 = 1,000,000\\\\)\\n3. \\\\(2000 \\\\times 50 = 100,000\\\\)\\n4. \\\\(2000 \\\\times 5 = 10,000\\\\)\\n\\nNow, add these results together:\\n\\\\[ 4,000,000 + 1,000,000 + 100,000 + 10,000 = 5,110,000 \\\\]\\n\\nNext, we need to account for the other half of the distribution:\\n\\n1. \\\\(500 \\\\times 500 = 250,000\\\\)\\n2. \\\\(500 \\\\times 50 = 25,000\\\\)\\n3. \\\\(500 \\\\times 5 = 2,500\\\\)\\n\\nAnd:\\n\\n1. \\\\(50 \\\\times 50 = 2,500\\\\)\\n2. \\\\(50 \\\\times 5 = 250\\\\)\\n\\nAnd:\\n\\n1. \\\\(5 \\\\times 5 = 25\\\\)\\n\\nNow, add all these results together:\\n\\\\[ 4,000,000 + 1,000,000 + 100,000 + 10,000 + 250,000 + 25,000 + 2,500 + 2,500 + 250 + 25 = 6,537,775 \\\\]\\n\\nTherefore, \\\\(2555 \\\\times 2555 = 6,537,775\\\\).\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qwen_chain.invoke({\"question\": \"What is 2555*2555?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f871186-82d1-4c46-9bbc-331a1252f627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<think>\\nTo calculate \\\\(2555 \\\\times 2555\\\\), I recognize that squaring a number can be done using the formula \\\\((a + b)^2 = a^2 + 2ab + b^2\\\\). \\n\\nFirst, I'll break down 2555 into 2500 and 55. So, \\\\(2555 = 2500 + 55\\\\).\\n\\nNext, I'll square each part separately:\\n- Squaring 2500 gives me \\\\(2500^2 = 6,250,000\\\\).\\n- Squaring 55 gives me \\\\(55^2 = 3,025\\\\).\\n\\nThen, I'll calculate the cross term: \\\\(2 \\\\times 2500 \\\\times 55 = 275,000\\\\).\\n\\nFinally, I'll add all these results together:\\n\\\\(6,250,000 + 275,000 + 3,025 = 6,528,025\\\\).\\n</think>\\n\\n**Solution:**\\n\\nTo find \\\\(2555 \\\\times 2555\\\\), we can use the formula for squaring a number:\\n\\n\\\\[\\n(a + b)^2 = a^2 + 2ab + b^2\\n\\\\]\\n\\nLet's break down \\\\(2555\\\\) into two parts for easier calculation.\\n\\n1. **Decompose the Number:**\\n   \\n   \\\\[\\n   2555 = 2500 + 55\\n   \\\\]\\n\\n2. **Apply the Squaring Formula:**\\n   \\n   \\\\[\\n   (2500 + 55)^2 = 2500^2 + 2 \\\\times 2500 \\\\times 55 + 55^2\\n   \\\\]\\n   \\n3. **Calculate Each Part Separately:**\\n   \\n   - **Square of 2500:**\\n     \\n     \\\\[\\n     2500^2 = 6,250,000\\n     \\\\]\\n     \\n   - **Twice the Product of 2500 and 55:**\\n     \\n     \\\\[\\n     2 \\\\times 2500 \\\\times 55 = 275,000\\n     \\\\]\\n     \\n   - **Square of 55:**\\n     \\n     \\\\[\\n     55^2 = 3,025\\n     \\\\]\\n\\n4. **Add All the Parts Together:**\\n   \\n   \\\\[\\n   6,250,000 + 275,000 + 3,025 = 6,528,025\\n   \\\\]\\n   \\n5. **Final Answer:**\\n\\n\\\\[\\n\\\\boxed{6,\\\\!528,\\\\!025}\\n\\\\]\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepseek_chain.invoke({\"question\": \"What is 2555*2555?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "220509e2-93b2-423a-8771-ada607bb9487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6528025"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2555*2555"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811f1585-0d78-4dc6-a0a3-709bd7a6a013",
   "metadata": {},
   "source": [
    "## Techniques to mitigate LLM limitations\n",
    "limitations: outdated knowledge, inability to take action, lack of context, hallucination risks, biases and discrimination, lack of transparency, lack of context\n",
    "\n",
    "Mitigation techniques:\n",
    "- Retrieval augmenation: This technique accesses knowledge bases to supplement an LLM's outdated training data, providing external context and reducing hallucination risk.\n",
    "- Chaining: This technique integrates action like searches and calculations.\n",
    "- Prompt engineering: This involves the careful crafting of prompts by providing critical context the guides appropriate responses.\n",
    "- Monitoring, filtering, and review: This involves ongoing and effective oversight of emerging issues regarding the application's input and output to detect issues. Both manual reviews and automated filters then correct potential problems with the output. This includes the following:\n",
    "- - Filters, like block lists, sensitivity classifiers, and banned word filters, can automatically flag issues.\n",
    "  - Constitutional principles monitor and filter unethical and inappropriate content.\n",
    "  - Human reviews provide insight into model behaviour and output.\n",
    "- Memory: Retains conversation context by persisting conversation data and context across interactions.\n",
    "- Fine-tuning: Training and tuning the LLM on more appropriate data for the application domain and principles. This adapts the model's behaviour for its specific purpose.\n",
    "\n",
    "### LLM App\n",
    "LLM apps typically have the following components:\n",
    "- A client layer to collect user input as text queries or decisions.\n",
    "- A prompt engineering layer to construct prompts that guide the LLM.\n",
    "- An LLM backend to analyze prompts and produce relevant text responses.\n",
    "- An output parsing layer to interpret LLM responses for the application interface.\n",
    "- Optional integration with external services via function APIs, knwoledge bases, and reasoning algorithms to augment the LLM's capabilities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a302a8-5c3b-4b71-9f0c-6adf6faec874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 6ms\u001b[0m\u001b[0m\n",
      "[sudo] password for yi: "
     ]
    }
   ],
   "source": [
    "!uv pip install graphviz\n",
    "# !sudo apt-get install graphviz -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98e44ede-8d62-4039-817b-eb4284a01f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "from IPython.display import Image\n",
    "\n",
    "def create_llm_flow():\n",
    "    # Create a new directed graph\n",
    "    dot = Digraph(comment='LLM Processing Flow')\n",
    "    \n",
    "    # Configure graph attributes\n",
    "    dot.attr(rankdir='LR')  # Left to right layout\n",
    "    dot.attr('node', shape='box', style='rounded')\n",
    "    \n",
    "    # Add nodes\n",
    "    dot.node('client', 'Client')\n",
    "    dot.node('prompt', 'Prompt')\n",
    "    dot.node('llm', 'LLM')\n",
    "    dot.node('parser', 'Output Parser')\n",
    "    \n",
    "    # Add edges with arrows\n",
    "    dot.edge('client', 'prompt')\n",
    "    dot.edge('prompt', 'llm')\n",
    "    dot.edge('llm', 'parser')\n",
    "    \n",
    "    return dot\n",
    "\n",
    "# Create and save the graph\n",
    "flow = create_llm_flow()\n",
    "flow.render('llm_flow', format='png', cleanup=False)\n",
    "Image(\"./llm_flow.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1337fe62-893c-476a-a493-fe243131c0f6",
   "metadata": {},
   "source": [
    "LLM apps can integrate external services via:\n",
    "- Function APIs to access web tools and databases.\n",
    "- Advanced reasoning algorithms for complex logic chains.\n",
    "- Retrieval augmented generation via knowledge bases.\n",
    "\n",
    "Retrieval augmented generation (RAG), enhances the LLM with external knowledge. These extensions expand the capabilities of LLM apps beyond the LLM's knowledge alone. For instance:\n",
    "- Function calling allows parameterized API requests.\n",
    "- SQL functions enable conversational database queries.\n",
    "- Reasoning algorithms linke chain-of-though fcilitate multi-step logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd4c21de-5bc2-46f8-b496-4623d33b0413",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m g\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madvance_llm_flow.dot\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     39\u001b[0m g\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madvance_llm_flow\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m'\u001b[39m, cleanup\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 40\u001b[0m \u001b[43mImage\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./advance_llm_flow.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def create_llm_flow():\n",
    "    dot = Digraph()\n",
    "    \n",
    "    # Basic left-to-right layout\n",
    "    dot.attr(rankdir='LR')\n",
    "    \n",
    "    # Simple boxes for nodes\n",
    "    dot.attr('node', shape='box')\n",
    "    \n",
    "    # Add nodes\n",
    "    dot.node('client', 'Client')\n",
    "    dot.node('frontend', 'Frontend')\n",
    "    dot.node('prompt', 'Prompt\\nEngineering')\n",
    "    dot.node('llm', 'LLM')\n",
    "    dot.node('parser', 'Output\\nParsing')\n",
    "    dot.node('ext', 'External Knowledge')\n",
    "    \n",
    "    # Main flow edges (solid)\n",
    "    dot.edge('client', 'frontend')\n",
    "    dot.edge('frontend', 'prompt')\n",
    "    dot.edge('prompt', 'llm')\n",
    "    dot.edge('llm', 'parser')\n",
    "    dot.edge('parser', 'frontend')\n",
    "    \n",
    "    # Dotted connections\n",
    "    dot.edge('ext', 'prompt', style='dotted')\n",
    "    dot.edge('parser', 'ext', style='dotted')\n",
    "    \n",
    "    # LLM self-loop\n",
    "    dot.edge('llm', 'llm', style='dashed', label='loop')\n",
    "    \n",
    "    return dot\n",
    "\n",
    "# Generate the diagram\n",
    "g = create_llm_flow()\n",
    "g.save('advance_llm_flow.dot')\n",
    "g.render('advance_llm_flow', format='png', cleanup=False)\n",
    "Image(\"./advance_llm_flow.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbb1868-6ccc-463d-b0f0-52d0f8abb324",
   "metadata": {},
   "source": [
    "# Key Components of LangChain\n",
    "- Chains\n",
    "- Agent\n",
    "- Memory\n",
    "- Tools\n",
    "\n",
    "### Chains\n",
    "Chains: a sequence of calls to components, which include other chains.\n",
    "\n",
    "Chains enables composing modular components into reusable pipelines.\n",
    "\n",
    "Eg. put together multiple LLM calls and other components in a swquence to create complex applicaitons.\n",
    "\n",
    "Prompt chaining: a technique that can be used to improve the performance of LangChain applicaitons, which involves chaining together multiple prompts to autocomplete a more complex response. More complex chains integrate models with tools like LLMMath, or SQLDatbaseChain. theese are called utility chains because they combine language models with specific tools.\n",
    "\n",
    "Benefits that Chains deliver\n",
    "- Modularity: Logic is divided into reusable components.\n",
    "- Composability: Components can be sequenced flexibly.\n",
    "- Readability: Each step in a pipeline is clear.\n",
    "- Maintainability: Steps can be added, removed and swapped.\n",
    "- Reusability: Common pilelines becomes configurable chains.\n",
    "- Tool integration: Easily incoporate LLMs, databases, APIs, etc.\n",
    "- Productivitiy: Quickly build prototypes of configurable chains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e710529-96c6-401a-817e-8ff6a3cf1ce6",
   "metadata": {},
   "source": [
    "# Agents\n",
    "Agent is an autonomous software entity that is capable of taking actions to accomplish goals and tasks.\n",
    "\n",
    "Both chains and agents is about the composiblity of LLMs and other components to work together.\n",
    "\n",
    "Difference between agents and chains\n",
    "- Agents do so by orchestrating chains while chains compose lower-level modules. While chains define reusable logic by sequencing components, agents leverage chains to take goal-driven actions.\n",
    "\n",
    "Action combine and orchestrate chains. Agents obeserves the environment, decides which chain to execute based on that observation, takes the chain's specified action and repeats.\n",
    "\n",
    "Agents decide which actions to take using LLMs as reasoning engines. The LLM is prompted with available tools, user input, and previous steps. It then selects the next action or final response.\n",
    "\n",
    "Tools are functions the agent calls to take real-world actions. Providing the right tools and effectively describing them is critical for action to accomplish goals.\n",
    "\n",
    "The agent executor runtime orchestrates the loop of querying the agent, executing tool actions, and feeding observations back. This handles lower-level complexities like error handling, logging, and parsing.\n",
    "\n",
    "Agents provide several key benefits:\n",
    "- Goal-oriented execution: Agents plan chains of logic targeting specific goals.\n",
    "- Dynamic responses: Observing environment changes lets agent react and adapt.\n",
    "- Statefulness: Agents can maintain memory and context across interactions.\n",
    "- Robustness: Errors can be handled by catching exceptions and trying alternative chains.\n",
    "- Composition: Agent logic combines reusable component chains.\n",
    "\n",
    "Together, this enables agent to handle complex, multi-step workflows and continuously interactive applications like chatbots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "262e9391-5d27-48fa-85df-f2135a9cad4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m37 packages\u001b[0m \u001b[2min 418ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m21 packages\u001b[0m \u001b[2min 342ms\u001b[0m\u001b[0m                                            \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m25 packages\u001b[0m \u001b[2min 36ms\u001b[0m\u001b[0m                               \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbuild\u001b[0m\u001b[2m==1.2.2.post1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcachecontrol\u001b[0m\u001b[2m==0.14.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcleo\u001b[0m\u001b[2m==2.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcrashtest\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcryptography\u001b[0m\u001b[2m==44.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdistlib\u001b[0m\u001b[2m==0.3.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdulwich\u001b[0m\u001b[2m==0.22.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1minstaller\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjaraco-classes\u001b[0m\u001b[2m==3.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjaraco-context\u001b[0m\u001b[2m==6.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjaraco-functools\u001b[0m\u001b[2m==4.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjeepney\u001b[0m\u001b[2m==0.8.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mkeyring\u001b[0m\u001b[2m==25.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmore-itertools\u001b[0m\u001b[2m==10.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmsgpack\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpkginfo\u001b[0m\u001b[2m==1.12.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpoetry\u001b[0m\u001b[2m==2.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpoetry-core\u001b[0m\u001b[2m==2.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyproject-hooks\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrapidfuzz\u001b[0m\u001b[2m==3.12.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msecretstorage\u001b[0m\u001b[2m==3.3.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mshellingham\u001b[0m\u001b[2m==1.5.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtomlkit\u001b[0m\u001b[2m==0.13.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtrove-classifiers\u001b[0m\u001b[2m==2025.1.15.22\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mvirtualenv\u001b[0m\u001b[2m==20.29.2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Installing Poetry\n",
    "!uv pip install poetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f73a320c-64c5-45f7-8962-f0d8a018ab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<your token>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bc034b3-32f6-463d-8691-4056cdeac71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<your token>\n"
     ]
    }
   ],
   "source": [
    "!echo $OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26b5d7fe-788a-4553-99f3-3a63509f2708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.py\n",
    "import os\n",
    "OPENAI_API_KEY = \"... \"\n",
    "\n",
    "# I'm omitting all other keys\n",
    "def set_environment():\n",
    "    variable_dict = globals().items()\n",
    "    for key, value in variable_dict:\n",
    "        if \"API\" in key or \"ID\" in key:\n",
    "             os.environ[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc0c51c9-ffdb-44a4-9c6f-8c8939339c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    }
   ],
   "source": [
    "!echo $OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d80a6bd1-2cbf-4138-adb1-13451ed76888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable_dict = globals().items()\n",
    "# for key, value in variable_dict:\n",
    "#     if key:\n",
    "#         print(f'key: {key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5edb6d19-76d0-4559-a65e-76a9319ae6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "environment = os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88e7269-6ca4-488e-8b8b-dafacc4ab2c8",
   "metadata": {},
   "source": [
    "## Fake LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e4fee7c2-89de-47c3-8de0-d2ee38f253dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m5 packages\u001b[0m \u001b[2min 21ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! uv pip install langchain-community langchain-core langchain-llm langchain-experimental langchain[docarray]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6b29f472-7a4b-4316-aea3-8d719209ee1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: Python_REPL\n",
      "Action Input: print(2 + 2)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m4\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: 4\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms.fake import FakeListLLM\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "tools = [PythonREPLTool()]\n",
    "responses = [\"Action: Python_REPL\\nAction Input: print(2 + 2)\", \"Final Answer: 4\"]\n",
    "llm = FakeListLLM(responses=responses)\n",
    "agent = initialize_agent(\n",
    " tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "agent.run(\"whats 2 + 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d4524f09-fd47-4f45-a860-732e09fd6334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.base import BaseTool\n",
    "from langchain.pydantic_v1 import BaseModel, Field, root_validator\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "class PythonREPLTool(BaseTool):\n",
    "    \"\"\"A tool for running python code in a REPL.\"\"\"\n",
    "\n",
    "    name: str = \"Python_REPL\"\n",
    "    description: str = (\n",
    "        \"A Python shell. Use this to execute python commands. \"\n",
    "        \"Input should be a valid python command. \"\n",
    "        \"If you want to see the output of a value, you should print it out \"\n",
    "        \"with `print(...)`.\"\n",
    "    )\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10d500d-0d11-428d-92ad-7b89aad3a4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8ff2f06d-f4bb-4c96-b5c8-d5ca2cbeac3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo calculate 4 + 4, I will use Python's addition operator.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: print(4 + 4)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m8\n",
      "\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: 4 + 4 equals 8.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4 + 4 equals 8.'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "tools = [PythonREPLTool()]\n",
    "qwen_llm = OllamaLLM(temperature=0., model=\"qwen2.5-coder:14b\")\n",
    "\n",
    "agent = initialize_agent(\n",
    " tools, qwen_llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "agent.run(\"whats 4 + 4\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e12f03-88dd-4049-83c3-a64279b2c5b1",
   "metadata": {},
   "source": [
    "## Hugging Face\n",
    "Hugging Face provides Hugging Face Hub, a platform for hosting Git-based code repositories, machine learnning models, dtasets and web applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6536201f-5d11-4677-a046-9619bf8cff98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m61 packages\u001b[0m \u001b[2min 566ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 72ms\u001b[0m\u001b[0m                                              \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 15ms\u001b[0m\u001b[0m==3.4.1                         \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-huggingface\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msentence-transformers\u001b[0m\u001b[2m==3.4.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "560b1cc0-1b3f-4a3f-a153-ea797b1c1279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f524823df81e46aabe46cca97be0ab21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "/home/yi/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In which country is Tokyo?\\n\\n# Answer\\nTokyo is the capital city of Japan. It is located on the eastern coast of the main island Honshu and is the political, economic, and cultural center of the country. Tokyo is known for its modernity, blending traditional Japanese culture with cutting-edge technology and fashion. It is also one of the most populous metropolitan areas in the world.'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\n",
    "        \"max_new_tokens\": 100,\n",
    "        \"top_k\": 50,\n",
    "        \"temperature\": 0.1,\n",
    "    },\n",
    ")\n",
    "llm.invoke(\"In which country is Tokyo?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "653fd5c2-91e7-4fff-8146-529ea41fc2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import list_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2eac9c82-2aff-41ab-9caf-d58f0ffe1bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-encoder/ms-marco-MiniLM-L-6-v2, 10485603\n",
      "\n",
      "distilbert/distilbert-base-uncased-finetuned-sst-2-english, 7730948\n",
      "\n",
      "papluca/xlm-roberta-base-language-detection, 4986307\n",
      "\n",
      "laurievb/OpenLID-v2, 4836437\n",
      "\n",
      "yiyanghkust/finbert-tone, 4324232\n",
      "\n",
      "facebook/bart-large-mnli, 3258391\n",
      "\n",
      "cardiffnlp/twitter-roberta-base-sentiment-latest, 2431001\n",
      "\n",
      "mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis, 2391929\n",
      "\n",
      "cardiffnlp/twitter-xlm-roberta-base-sentiment, 2060421\n",
      "\n",
      "cardiffnlp/twitter-roberta-base-sentiment, 2056152\n",
      "\n",
      "facebook/roberta-hate-speech-dynabench-r4-target, 1953988\n",
      "\n",
      "lxyuan/distilbert-base-multilingual-cased-sentiments-student, 1920043\n",
      "\n",
      "nlptown/bert-base-multilingual-uncased-sentiment, 1486629\n",
      "\n",
      "lucadiliello/BLEURT-20-D12, 1214117\n",
      "\n",
      "BAAI/bge-reranker-large, 1173427\n",
      "\n",
      "ProsusAI/finbert, 1131377\n",
      "\n",
      "cardiffnlp/twitter-roberta-base-emotion, 1110092\n",
      "\n",
      "pysentimiento/robertuito-sentiment-analysis, 1099897\n",
      "\n",
      "cross-encoder/ms-marco-TinyBERT-L-2-v2, 1052639\n",
      "\n",
      "cross-encoder/ms-marco-MiniLM-L-4-v2, 1040183\n",
      "\n",
      "mangoapps/fb_zeroshot_mnli_onnx, 995486\n",
      "\n",
      "BAAI/bge-reranker-v2-m3, 992853\n",
      "\n",
      "microsoft/deberta-large-mnli, 985217\n",
      "\n",
      "BAAI/bge-reranker-base, 942175\n",
      "\n",
      "GleghornLab/SYNTERACT, 924203\n",
      "\n",
      "cardiffnlp/twitter-xlm-roberta-base-sentiment-multilingual, 860989\n",
      "\n",
      "bunsenfeng/FactKB, 837576\n",
      "\n",
      "michellejieli/emotion_text_classifier, 808753\n",
      "\n",
      "cross-encoder/ms-marco-MiniLM-L-12-v2, 755954\n",
      "\n",
      "j-hartmann/emotion-english-distilroberta-base, 732801\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def list_most_popular(task: str):\n",
    "     for rank, model in enumerate(\n",
    "         list_models(filter=task, sort=\"downloads\", direction=-1)\n",
    "      ):\n",
    "         if rank == 30:\n",
    "             break\n",
    "         print(f\"{model.id}, {model.downloads}\\n\")\n",
    "list_most_popular(\"text-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12b5bb75-c0b2-4315-9043-b7b1080e5f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.7691410779953003}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "customer_email = \"\"\"\n",
    "I am writing to pour my heart out about the recent unfortunate experience\n",
    "I had with one of your coffee machines that arrived broken. I anxiously\n",
    "unwrapped the box containing my highly anticipated coffee machine.\n",
    "However, what I discovered within broke not only my spirit but also any\n",
    "semblance of confidence I had placed in your brand.\n",
    "Its once elegant exterior was marred by the scars of travel, resembling a\n",
    "war-torn soldier who had fought valiantly on the fields of some espresso\n",
    "battlefield. This heartbreaking display of negligence shattered my dreams\n",
    "of indulging in daily coffee perfection, leaving me emotionally distraught\n",
    "and inconsolable\n",
    "\"\"\"\n",
    "sentiment_model = pipeline(\n",
    " task=\"sentiment-analysis\",\n",
    " model=\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    ")\n",
    "print(sentiment_model(customer_email))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eb21a2d-cd31-4b4b-9059-e44b9bb40bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_2', 'score': 0.9900000691413879}]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_model(\"I am very super happy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9d8e8ac-76e4-4f08-9ea5-f505cc2e433d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.9214368462562561}]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_model(\"Recently my cat has died\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47117ace-c100-4a27-8a15-b2f364fd8c8e",
   "metadata": {},
   "source": [
    "## Mitigating hallucinations throught fact-checking\n",
    "fact checking is verifying claims made by LLM's aggains evidence from external sources.\n",
    "\n",
    "Fact-checking 3 main stages:\n",
    "1. Claim detection: Identifying parts needing verification.\n",
    "2. Evidence retrieval: Find sources supporing or refuting the claim.\n",
    "3. Verdict prediction: Assess claim veracity based on evidence.\n",
    "\n",
    "LLMCheckerchain, is a chain for fact-checking, the model is prompted sequentially - first, to make the assumptions explicit, which looks like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ec5dd2d-6292-436d-86b9-9b9e8f12b463",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMCheckerChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What type of mammal lays the biggest eggs?',\n",
       " 'result': \"Based on the information provided in the assertions, the mammal that lays the biggest eggs is the platypus. Despite being a relatively small animal, the egg laid by a platypus is larger in proportion to its body size compared to other mammals. However, it's important to note that while an ostrich egg is heavier and larger in absolute terms, it belongs to the bird kingdom, not the mammal kingdom.\"}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMCheckerChain\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.cache import InMemoryCache  # if available in your version\n",
    "\n",
    "qwen_model = OllamaLLM(model=\"qwen2.5-coder:14b\", temperature=\"0.7\")\n",
    "checker_chain = LLMCheckerChain.from_llm(qwen_model, verbose=True)\n",
    "checker_chain.model_rebuild()  # Finaliz\n",
    "\n",
    "text = \"What type of mammal lays the biggest eggs?\"\n",
    "checker_chain.invoke(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f71f38b-ca46-4791-8610-14e9675abaa9",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de4b13b9-9d8f-41d7-9696-e17b5d98ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "prompt = \"\"\"\n",
    "Summarize this text in one sentence:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "qwen_model = OllamaLLM(model=\"qwen2.5-coder:14b\", temperature=\"0.7\")\n",
    "summary = qwen_model(prompt.format(text=text))\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "064fa191-194d-4585-8d3f-b417c414cb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSummarize this text in one sentence:\\nWhat type of mammal lays the biggest eggs?\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c7cda9d-12ba-4216-b619-895910ecbcf4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 7ms\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!uv pip install langchain_decorators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64e5ffbf-3e49-4a4c-84b2-da411ac39b99",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mlangchain-decorators==0.6.1                                                   \u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m42 packages\u001b[0m \u001b[2min 383ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 939ms\u001b[0m\u001b[0m                                             \n",
      "\u001b[2mUninstalled \u001b[1m2 packages\u001b[0m \u001b[2min 49ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 19ms\u001b[0m\u001b[0m                                \u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mattrs\u001b[0m\u001b[2m==24.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mattrs\u001b[0m\u001b[2m==25.1.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.2.3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! uv pip install --upgrade langchain_decorators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d406e72-5a64-4fe5-a0cb-68c24c0750f1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "no validator found for <class 'langchain_core.messages.ai.AIMessage'>, see `arbitrary_types_allowed` in Config",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_decorators\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m llm_prompt\n\u001b[1;32m      3\u001b[0m \u001b[38;5;129m@llm_prompt\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msummarize\u001b[39m(text:\u001b[38;5;28mstr\u001b[39m, length\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshort\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m Summarize this text in {length} length:\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m {text}\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain_decorators/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogColors, GlobalSettings, print_log, PromptTypes, PromptTypeSettings, LlmSelector\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OutputWithFunctionCall\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompt_decorator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PromptDecoratorTemplate\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain_decorators/common.py:16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseMessage\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatMessagePromptTemplate\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OutputWithFunctionCall\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping_inspect\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_generic_type, is_union_type\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydantic\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain_decorators/schema.py:18\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, PrivateAttr\n\u001b[1;32m     16\u001b[0m T \u001b[38;5;241m=\u001b[39m TypeVar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;21;43;01mOutputWithFunctionCall\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mGeneric\u001b[49m\u001b[43m[\u001b[49m\u001b[43mT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mBaseModel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_text\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_message\u001b[49m\u001b[43m:\u001b[49m\u001b[43mAIMessage\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/pydantic/v1/main.py:197\u001b[0m, in \u001b[0;36mModelMetaclass.__new__\u001b[0;34m(mcs, name, bases, namespace, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    190\u001b[0m         is_untouched(value)\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m ann_type \u001b[38;5;241m!=\u001b[39m PyObject\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m         )\n\u001b[1;32m    195\u001b[0m     ):\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m     fields[ann_name] \u001b[38;5;241m=\u001b[39m \u001b[43mModelField\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mann_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mannotation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mann_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_validators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_validators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mann_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ann_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m namespace \u001b[38;5;129;01mand\u001b[39;00m config\u001b[38;5;241m.\u001b[39munderscore_attrs_are_private:\n\u001b[1;32m    205\u001b[0m     private_attributes[ann_name] \u001b[38;5;241m=\u001b[39m PrivateAttr()\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/pydantic/v1/fields.py:504\u001b[0m, in \u001b[0;36mModelField.infer\u001b[0;34m(cls, name, value, annotation, class_validators, config)\u001b[0m\n\u001b[1;32m    501\u001b[0m     required \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    502\u001b[0m annotation \u001b[38;5;241m=\u001b[39m get_annotation_from_field_info(annotation, field_info, name, config\u001b[38;5;241m.\u001b[39mvalidate_assignment)\n\u001b[0;32m--> 504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtype_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mannotation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43malias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_validators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_validators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequired\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequired\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfield_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/pydantic/v1/fields.py:434\u001b[0m, in \u001b[0;36mModelField.__init__\u001b[0;34m(self, name, type_, class_validators, model_config, default, default_factory, required, final, alias, field_info)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m SHAPE_SINGLETON\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mprepare_field(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 434\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/pydantic/v1/fields.py:555\u001b[0m, in \u001b[0;36mModelField.prepare\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault \u001b[38;5;129;01mis\u001b[39;00m Undefined \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 555\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopulate_validators\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/pydantic/v1/fields.py:829\u001b[0m, in \u001b[0;36mModelField.populate_validators\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msub_fields \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m SHAPE_GENERIC:\n\u001b[1;32m    826\u001b[0m     get_validators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__get_validators__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    827\u001b[0m     v_funcs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    828\u001b[0m         \u001b[38;5;241m*\u001b[39m[v\u001b[38;5;241m.\u001b[39mfunc \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m class_validators_ \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39meach_item \u001b[38;5;129;01mand\u001b[39;00m v\u001b[38;5;241m.\u001b[39mpre],\n\u001b[0;32m--> 829\u001b[0m         \u001b[38;5;241m*\u001b[39m(get_validators() \u001b[38;5;28;01mif\u001b[39;00m get_validators \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfind_validators\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m),\n\u001b[1;32m    830\u001b[0m         \u001b[38;5;241m*\u001b[39m[v\u001b[38;5;241m.\u001b[39mfunc \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m class_validators_ \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39meach_item \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mpre],\n\u001b[1;32m    831\u001b[0m     )\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidators \u001b[38;5;241m=\u001b[39m prep_validators(v_funcs)\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_validators \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/pydantic/v1/validators.py:768\u001b[0m, in \u001b[0;36mfind_validators\u001b[0;34m(type_, config)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(type_, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__pydantic_core_schema__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    767\u001b[0m     warn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMixing V1 and V2 models is not supported. `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` is a V2 model.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;167;01mUserWarning\u001b[39;00m)\n\u001b[0;32m--> 768\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno validator found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, see `arbitrary_types_allowed` in Config\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: no validator found for <class 'langchain_core.messages.ai.AIMessage'>, see `arbitrary_types_allowed` in Config"
     ]
    }
   ],
   "source": [
    "from langchain_decorators import llm_prompt\n",
    "\n",
    "@llm_prompt\n",
    "def summarize(text:str, length=\"short\") -> str:\n",
    " \"\"\"\n",
    " Summarize this text in {length} length:\n",
    " {text}\n",
    " \"\"\"\n",
    " return\n",
    "summary = summarize(text=\"let me tell you a boring story from when I was young...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df36770e-9954-42e2-8b2b-eca297b19fdd",
   "metadata": {},
   "source": [
    "## Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f53651f8-2470-44a8-83fa-aad8e37c7056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.schema import StrOutputParser\n",
    "llm = OllamaLLM(model=\"qwen2.5-coder:14b\")\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Summarize tis text: {text}?\"\n",
    ")\n",
    "runnable = prompt | llm | StrOutputParser()\n",
    "summary = runnable.invoke({\"text\": text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af28bead-39f5-476b-85bc-0d8702378d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='Summarize tis text: {text}?')\n",
       "| OllamaLLM(model='qwen2.5-coder:14b')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4bcdf559-0609-4db0-a469-fe4d43c0427c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The mammal that lays the biggest eggs is the platypus. Platypuses are monotremes, which means they lay eggs instead of giving birth to live young. The average size of a platypus egg is about 1.5 centimeters in length and weighs around 0.2 grams. This makes them the largest eggs laid by any mammal.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "576cd808-36d0-4cb3-95aa-f3ffb4bdb897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The type of mammal that lays the largest eggs is the platypus. While it is not commonly known, the platypus is an egg-laying mammal, scientifically classified as monotremes along with the echidnas. Platypus eggs are about 2 cm in length and weigh around 0.1 grams. Although they are relatively small by human standards, compared to other mammals, platypus eggs are indeed some of the largest laid by any mammal.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d83ec6d-450b-43c8-872c-8b29ba4cb40e",
   "metadata": {},
   "source": [
    "## Chain of density\n",
    "Chain of density, a prompt-guided techniques to incrementallly increase the information density of GPT-4 gnerated summaries while controlling length.\n",
    "\n",
    "This is the prompt to sue with CoD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d99f1266-e440-4563-a6cf-9fe568c1f860",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Article: { text }\n",
    "You will generate incressingly concise, entity-dense summaries of the \n",
    "above article.\n",
    "Repeat the following 2 steps 5 times.\n",
    "Step 1. Identify 1-3 information entities (\";\" delimited) from the \n",
    "article which are missing from the previously generated summary.\n",
    "Step 2. Write a new, denser summary of indentical length which covers \n",
    "every entity and detail from the previous summary plus the missing \n",
    "entities.\n",
    "A missing entity is:\n",
    "- relevant to the main story,\n",
    "- specific yet concise (5 words or fewer),\n",
    "- novel (not in the previous summary),\n",
    "- faithful (present in the article),\n",
    "- anywhere (can be located anywhere in the article).\n",
    "Guideline:\n",
    "- The first summary should be long (4-5 sentences, ~80 workds) yet highly\n",
    "non-specific, containing little information beyond the entities marked as missing.\n",
    "Use overly verbose language and fillers (e.g., \"this article discussses\") to reach ~80 words.\n",
    "- Make every word count: rewrite the previous summary to improve flow and make space\n",
    "for additional entities.\n",
    "- Make space with fusion, compression, and removal of uninformative phrases\n",
    "like \"the article discusses\".\n",
    "- The summaries should become highly dense and concise yet self-contained, i.e.,\n",
    "easily understood without the article.\n",
    "- Missing entities can appear anywhere in the new summary.\n",
    "- Never drop entities from the previous summary. If space cannot be made, add fewer new entities.\n",
    "Remember, use the exact same number of words for each summary.\n",
    "Answer in JSON. The JSON should be a list (length 5) of dictionaries whose\n",
    "keys are \"Missing_Entities\" and \"Denser_Summary\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82be9060-603e-4020-ac5b-5b8244b70e53",
   "metadata": {},
   "source": [
    "# Map-Reduce pipelines\n",
    "Key steps\n",
    "1. Map: Each document is passed through a summarization chain (LLM chain)\n",
    "2. Collapse (optional): The summarize documents are combined into a single document.\n",
    "3. Reduce: The collapse document goes through a final LLM chain to produce the output.\n",
    "\n",
    "The map step applies a chain to each document in parallel. the reduce step aggregates the mapped output and gneerates the final result.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c038c859-cd2d-4df1-8d4a-d647098b8ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 7ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! uv pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23e34a5a-df3b-477d-861a-b72cc848c27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "# pdf_file_path = \"<pdf_file_path>\"\n",
    "# pdf_loader = PyPDFLoader(pdf_file_path)\n",
    "# docs = pdf_loader.load_and_split()\n",
    "# llm = OllamaLLM(model=\"qwen2.5-coder:14b\")\n",
    "# chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "# chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bb3ff83-f6ae-4233-ac67-18eb05cad9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 226ms\u001b[0m\u001b[0m                                          \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 61ms\u001b[0m\u001b[0m                                               \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 11ms\u001b[0m\u001b[0m                                 \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpypdf\u001b[0m\u001b[2m==5.3.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! uv pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb482fde-d042-4b8e-9b92-aa473bee0e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file_path = \"openresume-resume.pdf\"\n",
    "pdf_loader = PyPDFLoader(pdf_file_path)\n",
    "docs = pdf_loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da0a320e-5f76-4260-8d08-e6fd3a95095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model=\"qwen2.5-coder:14b\")\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "response = chain.invoke(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456632d4-65d0-48a1-811d-536ba533a55d",
   "metadata": {},
   "source": [
    "### Monitor token usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546706f2-7805-4932-873e-e7a9c26a10b1",
   "metadata": {},
   "source": [
    "Can't get tokens from openai callback using ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b155017d-3b0f-4ed5-b374-1a481b582532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 0\n",
      "Prompt Tokens: 0\n",
      "Completion Tokens: 0\n",
      "Total Cost (USD): $0.0\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "with get_openai_callback() as cb:\n",
    "    response = chain.invoke(docs) \n",
    "    # print(response)\n",
    "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Total Cost (USD): ${cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723462eb-f88c-4f61-9e0b-43b966a4ab25",
   "metadata": {},
   "source": [
    "### Extracting information from documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "08f21cee-46b4-4ab0-b8df-e3f401a547cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "import os\n",
    "\n",
    "# Define your Pydantic models\n",
    "class Experience(BaseModel):\n",
    "    start_date: Optional[str]\n",
    "    end_date: Optional[str]\n",
    "    description: Optional[str]\n",
    "\n",
    "class Study(Experience):\n",
    "    degree: Optional[str]\n",
    "    university: Optional[str]\n",
    "    country: Optional[str]\n",
    "    grade: Optional[str]\n",
    "\n",
    "class WorkExperience(Experience):\n",
    "    company: str\n",
    "    job_title: str\n",
    "\n",
    "class Resume(BaseModel):\n",
    "    first_name: str\n",
    "    last_name: str\n",
    "    linkedin_url: Optional[str]\n",
    "    nationality: Optional[str]\n",
    "    skill: Optional[str]\n",
    "    study: Optional[Study]\n",
    "    work_experience: Optional[WorkExperience]\n",
    "    hobby: Optional[str]\n",
    "\n",
    "# Load and split your PDF document\n",
    "pdf_file_path = os.path.expanduser(\"openresume-resume.pdf\")\n",
    "pdf_loader = PyPDFLoader(pdf_file_path)\n",
    "docs = pdf_loader.load_and_split()\n",
    "\n",
    "# Initialize the output parser\n",
    "parser = PydanticOutputParser(pydantic_object=Resume)\n",
    "\n",
    "# Create the prompt template\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Extract the following information from the provided document:\\n{format_instructions}\\n\\nDocument:\\n{document}\",\n",
    "    input_variables=[\"document\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# Initialize the ChatOllama model\n",
    "llm = ChatOllama(model=\"qwen2.5-coder:14b\", format=\"json\", temperature=0)\n",
    "\n",
    "# Create the LLMChain\n",
    "# chain = LLMChain(llm=llm, prompt=prompt)\n",
    "chain = prompt | llm | SimpleJsonOutputParser()  \n",
    "\n",
    "summary = chain.invoke({\"document\": doc})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "96215dd8-1977-455b-b9b0-389690b4a26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_name': 'John',\n",
       " 'last_name': 'Doe',\n",
       " 'linkedin_url': 'linkedin.com/in/john-doe',\n",
       " 'nationality': None,\n",
       " 'skill': 'HTML, TypeScript, CSS, React, Python, C++',\n",
       " 'study': {'start_date': 'Sep 2019',\n",
       "  'end_date': 'May 2023',\n",
       "  'description': 'Won 1st place in 2022 Education Hackathon, 2nd place in 2023 Health Tech Competition\\nTeaching Assistant for Programming for the Web (2022 - 2023)\\nCoursework: Object-Oriented Programming (A+), Programming for the Web (A+), Cloud Computing (A), Introduction to Machine Learning (A-), Algorithms Analysis (A-)',\n",
       "  'degree': 'Bachelor of Science in Computer Science',\n",
       "  'university': 'XYZ University',\n",
       "  'country': None,\n",
       "  'grade': '3.8 GPA'},\n",
       " 'work_experience': {'start_date': 'May 2023',\n",
       "  'end_date': 'Present',\n",
       "  'description': 'Lead a cross-functional team of 5 engineers in developing a search bar, which enables thousands of daily active users to search content across the entire platform\\nCreate stunning home page product demo animations that drives up sign up rate by 20%\\nWrite clean code that is modular and easy to maintain while ensuring 100% test coverage',\n",
       "  'company': 'ABC Company',\n",
       "  'job_title': 'Software Engineer'},\n",
       " 'hobby': None}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b40e9d5-2165-4f67-8cbc-cebbc460e604",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93e9d97a-c923-4124-825a-37e1c58db3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_agent() -> AgentExecutor:\n",
    "    llm = ChatOllama(model=\"qwen2.5-coder:14b\", temperature=0, streaming=True)\n",
    "    # DuckDuckGoSearchRun, folfram alpha, arxiv search, wikipedia\n",
    "    # Todo: try wolfram-alpha!\n",
    "    tools = load_tools(\n",
    "        tool_names=[\"ddg-search\", \"arxiv\", \"wikipedia\"],\n",
    "        llm=llm\n",
    "    )\n",
    "\n",
    "    return initialize_agent(\n",
    "        tools=tools, llm=llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019ed326-b720-4dd1-bf38-f199a7a4269f",
   "metadata": {},
   "source": [
    "AgentExecutor, is a chain. The Zero-Shot agent is a general-purpose action agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ab5536-ceda-41f9-9a1b-830f6a411d6c",
   "metadata": {},
   "source": [
    "## Building a visual interface with streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90e6f369-6781-4449-a258-71bf04c0f18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m60 packages\u001b[0m \u001b[2min 282ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 270ms\u001b[0m\u001b[0m                                              \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 0.24ms\u001b[0m\u001b[0m                               \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwikipedia\u001b[0m\u001b[2m==1.4.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! uv pip install streamlit duckduckgo-search wolframalpha arxiv wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac005613-a8c5-43a6-a2cb-f998ed2e8ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-14 23:33:13.476 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-14 23:33:13.483 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-14 23:33:13.485 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-14 23:33:13.485 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-14 23:33:13.486 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-14 23:33:13.486 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-14 23:33:13.530 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/yi/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-02-14 23:33:13.531 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from langchain.callbacks import StreamlitCallbackHandler\n",
    "\n",
    "chain = load_agent()\n",
    "st_callback = StreamlitCallbackHandler(st.container())\n",
    "\n",
    "if prompt := st.chat_input():\n",
    "    st.chat_message(\"user\").write(prompt)\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        st_callback = StreamlitCallbackHandler(st.container())\n",
    "        response = chain.run(prompt, callback=[st_callback])\n",
    "        st.write(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6411ecb5-5040-4ea2-aa90-59ee6472253d",
   "metadata": {},
   "source": [
    "## Reasoning Strategies\n",
    "\n",
    "Hybrid systems that combine neural pattern completion with deliberate symbolic manipulation can master skills including these:\n",
    "- Multi-step deductive reasoning to draw conclusions from a chain of facts\n",
    "- Mathematical reasoning like solving equations throught a series of transformations\n",
    "- Planning tactics to break down a problem into an optimized sequence of actions\n",
    "\n",
    "By integrating tools togethter with explicit reasoning steps instead of pure pattern completion, our agent can tackle problems requiring abstractio nand imagination, and can arrive at a complex understanding of the world enabling them to hold more meaningful conversations abut complex concepts.\n",
    "\n",
    "The tools are the available resources thatthe aggent can use, such as search engines or databases. The LLMChain is responsible for generating text prompts and parsing the output to determine the next action. The agent class uses the output of the LLMChain to decide which action to take.\n",
    "\n",
    "While tool-augmented language models combine LLMs with external resources like search engines and databases to enhance reasoning capabilities, this can be further enhanced with agents.\n",
    "\n",
    "In LangChain, this consists of 3 parts:\n",
    "- Tools\n",
    "- An LLMChain\n",
    "- The agent itself\n",
    "\n",
    "Thre are 2 key agent architectures:\n",
    "- Action agents reason iteratively based on observations after each action.\n",
    "- Plan-and-execute agents plan completely upfront before taking any action.\n",
    "\n",
    "In observation-dependent reasoning, the agent iteratively providees context and exampels to an LLM to generate thoughts and actions. Observations from tools are incorporated to inform the next reasoning step. this approach is used in action agents.\n",
    "\n",
    "An alternative is plan-and-execute agents that first create a complete plan and then gather evidence to execute it. The Planner LLM produces a list of plans (P). The agent gathers evidence (E) using tools. P and E are combined and fed to the Solver LLM to generate the final output.\n",
    "\n",
    "Plan-and-execute separates planning from execution. Smaller specialized models can be used for the Planner and solver roles. The trade-off is that plan-and-execute requires more upfront planning.\n",
    "\n",
    "Observation-dependent reasoning involves making judgments, predictions, or choices based on the current state of knowledge or the evidence fetched through observation. In each iteration, the agent provides context and examples to the LLM. A user's task is first combined with the context and examples and given to the LLM to initiate reasoning. The LLM generates a though and an action and then waits for an observation from tools. The observation is added to the prompt to initiate the next call to the LLM. In LangChain, this is an action agent (also ZERO_SHOT_REACT_DESCRIPTION), which is the default setting when you create an agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb4cac7-2431-4a9e-8bfb-328e7aee32dc",
   "metadata": {},
   "source": [
    "### Planning\n",
    "The strategy of making plans ahead of any actions is called the \"plan-and-execute\" agent).\n",
    "\n",
    "Thye Planner (an LLM), which can be fine-tuned for planning and tool usage, produces a list of plans (P) and calls a worker (in LangChain, the agent) to gater evidence (E) by using tools. P and E are combined with the task and then fed into the Solver (an LLM) for the final anser. we can write a pseudo algorithmn like this:\n",
    "1. Plan out all the steps (Planner).\n",
    "2. for each step, determine the proper tools to accomplish the step and execute.\n",
    "\n",
    "The Planner and the Solver can be distinct language models. This opens the possibility of using smaller, specialized models for Planner and Solver, and using fewer tokens for each of the calls.\n",
    "\n",
    "First add the strategy variable to the `load_agent()` function. It can take 2 values, either `plan-and-solve` or `zero-shot-react`. For `zero-shot-react`, the logic stays the same. For `plan-and-solve`, we'll define a planner and an executor, which we'll use to create a `PlanAndExecute` agent executor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40c4b8d6-ed07-4bd3-aed9-021df32522cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain.agents import initialize_agent, load_tools, AgentType\n",
    "from langchain.chains.base import Chain\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_experimental.plan_and_execute import (\n",
    "    load_chat_planner, load_agent_executor, PlanAndExecute\n",
    ")\n",
    "import streamlit as st\n",
    "\n",
    "ReasoningStrategies = Literal[\"zero-shot-react\", \"plan-and-solve\"]\n",
    "\n",
    "def load_agent(\n",
    "    tool_names: list[str],\n",
    "    strategy: ReasoningStrategies = \"zero-shot-react\"\n",
    "\n",
    ") -> Chain:\n",
    "    llm = ChatOllama(model=\"qwen2.5-coder:14b\", temperature=0, streaming=True)\n",
    "    tools = load_tools(\n",
    "        tool_names=tool_names,\n",
    "        llm=llm\n",
    "    )\n",
    "    if strategy == \"plan-and-solve\":\n",
    "        planner = load_chat_planner(llm)\n",
    "        executor = load_agent_executor(llm, tools, verbose=True)\n",
    "        return PlanAndExecute(planner=planner, executor=executor, verbose=True)\n",
    "\n",
    "    return initialize_agent(\n",
    "        tools=tools, llm=llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96526de0-5e19-4a41-a6b6-f2917abff11c",
   "metadata": {},
   "source": [
    "Let's define a new variable that's set through a radio button in Streamlit. We'll pass tyhis variable over the `load_agent()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7bee041-3fdc-4846-b7b1-54f663672ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-15 14:08:00.214 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-15 14:08:00.217 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-15 14:08:00.219 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-15 14:08:00.220 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-15 14:08:00.221 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n",
      "2025-02-15 14:08:00.222 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-15 14:08:00.249 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/yi/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-02-15 14:08:00.249 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "strategy = st.radio(\n",
    "    \"Reasoning strategy\",\n",
    "    (\"plan-and-solve\", \"zero-shot-react\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3f91bc-8454-4b73-88b3-5efbdc41086d",
   "metadata": {},
   "source": [
    "You might have noticed that the `load_agent()` method takes a list of strings, `tool_names`. This can be chosen in the user interface (UI) as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "595e4157-b3bf-468a-93fc-44699b7f5ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-15 15:37:03.314 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-15 15:37:03.317 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-15 15:37:03.319 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-15 15:37:03.320 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-15 15:37:03.320 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "tool_names = st.multiselect(\n",
    "    'Which tools do you want to use?',\n",
    "    [\n",
    "        \"google-search\", \"ddg-search\", \"arxiv\",\n",
    "        \"wikipedia\", \"python_repl\", \"pal_math\", \"llm-math\"\n",
    "    ],\n",
    "    [\"ddg-search\", \"wikipedia\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0188d1df-4326-4b90-99df-c2c70e5a5755",
   "metadata": {},
   "source": [
    "Finally, still the app, the agent is loaded like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69f98aed-211b-4d8e-9767-2a865426a436",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain = load_agent(tool_names=tool_names, strategy=strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff1fb962-dea5-4570-b79e-128835db7401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, Tool, create_self_ask_with_search_agent\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
    "from langchain_community.tools.ddg_search import DuckDuckGoSearchRun\n",
    "from langchain_community.tools.google_search import GoogleSearchRun\n",
    "from langchain_community.tools.wikipedia.tool import WikipediaQueryRun\n",
    "from langchain_community.tools.wolfram_alpha import WolframAlphaQueryRun\n",
    "from langchain_community.utilities.arxiv import ArxivAPIWrapper\n",
    "from langchain_community.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper\n",
    "from langchain_community.utilities.google_search import GoogleSearchAPIWrapper\n",
    "from langchain_community.utilities.wikipedia import WikipediaAPIWrapper\n",
    "from langchain_community.utilities.wolfram_alpha import WolframAlphaAPIWrapper\n",
    "from langchain_core.language_models import BaseLanguageModel\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_experimental.tools import PythonREPLTool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf5e7b9b-9af5-4f81-a90c-407b52e06a64",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Chain' from 'langchain.chains' (/home/yi/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain/chains/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chain\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Chain' from 'langchain.chains' (/home/yi/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain/chains/__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain.chains import Chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca14cd6-fa22-444e-b18e-9fd6da236102",
   "metadata": {},
   "source": [
    "# Embeddding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6110728d-f69b-4285-ba19-3e49c3b56590",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8044437170028687, 0.914264440536499, -4.007643699645996, -1.1118558645248413, 0.896572470664978, -0.7128822803497314, 0.4467930197715759, 0.25961872935295105, 0.514275848865509, -0.07405504584312439, 0.4172780513763428, 0.7774555683135986, 0.6251865029335022, -0.22206376492977142, -1.510133981704712, -0.6109319925308228, -0.13520467281341553, -2.364330768585205, 0.7819806933403015, 1.0423827171325684, -0.8954195976257324, -0.6870061159133911, -1.1416879892349243, -0.7331091165542603, 2.818359613418579, -0.49423250555992126, -0.8752056956291199, 0.34464550018310547, -1.2165148258209229, -0.13152295351028442, 0.011937551200389862, 0.008786272257566452, 0.38013291358947754, -0.34124353528022766, -1.4954615831375122, -1.4013972282409668, 0.06516040861606598, 0.3660874366760254, 0.4461685121059418, 0.12468599528074265, 1.058765172958374, 0.19058313965797424, 0.3387684226036072, -0.6107196807861328, 1.0274360179901123, -0.1766473948955536, 1.2721312046051025, 0.01457289606332779, 0.468231737613678, -0.3646760582923889, 0.25328612327575684, -0.38508033752441406, -0.034075889736413956, -0.2625436782836914, 1.6218408346176147, -0.3954959511756897, 0.8835822939872742, 0.786931574344635, -0.41004133224487305, -0.0717080608010292, 0.6167240142822266, 0.6280854344367981, -1.1026015281677246, 1.7120983600616455, -0.0492042601108551, 0.04554732143878937, -1.0489130020141602, 0.6597670316696167, -0.1412431299686432, -0.0037580616772174835, 0.21188677847385406, 0.31927934288978577, 0.6532340049743652, 0.12999697029590607, -0.5469524264335632, -0.9763076305389404, -0.43240195512771606, -0.5472317934036255, 0.05899326130747795, 0.7569355368614197, 0.7365849018096924, -0.2666846215724945, -0.142245814204216, 0.5043704509735107, 1.852942705154419, 0.30336490273475647, -0.513504683971405, -1.003780484199524, -0.07406271994113922, 0.39938753843307495, 1.0190588235855103, 0.9369532465934753, 1.3362271785736084, 0.9628337621688843, -0.17943760752677917, 0.4920896291732788, -0.12790052592754364, -0.11360777914524078, 0.3676949441432953, -0.6176630258560181, -0.718382716178894, 0.08532889932394028, -0.512789249420166, -0.163164421916008, 1.2950767278671265, 1.2518855333328247, -0.5970855355262756, 0.7189294099807739, -0.9984252452850342, -0.4626355767250061, -0.8104238510131836, 1.4123730659484863, -0.5368174314498901, 0.31124377250671387, -0.5507797598838806, 0.31449592113494873, 1.41633141040802, 0.12391753494739532, -0.3131893277168274, 0.8194953799247742, -0.41285058856010437, 0.9113914966583252, -0.4771904945373535, 2.005005359649658, -0.7039973735809326, 1.1389180421829224, -1.3721855878829956, 1.3454957008361816, 0.07116085290908813, -0.25826072692871094, -0.7875304222106934, -0.5297619104385376, -0.5102025270462036, -0.3415515720844269, 1.022637963294983, 0.11160090565681458, -0.09578373283147812, -0.29198503494262695, -0.5340188145637512, 0.3388572335243225, 0.183818519115448, 0.6096537113189697, 0.16049988567829132, 0.5427781343460083, -0.26044467091560364, -0.34140703082084656, 1.080935001373291, 0.23882436752319336, -0.6395606994628906, 0.19202300906181335, -0.47973892092704773, 0.4902794361114502, 0.9816949367523193, 0.14281947910785675, 0.1707281768321991, -0.9725269675254822, -0.03736187517642975, 0.18149103224277496, 0.1562289446592331, 0.4593706727027893, 1.5237706899642944, -0.2460366189479828, -1.0950273275375366, 1.2935333251953125, 0.2864754796028137, -1.4393548965454102, -0.16526487469673157, 1.5597236156463623, 0.7117866277694702, 0.9605814218521118, -0.7201734185218811, -1.5715501308441162, -1.1289993524551392, -0.5713915824890137, 0.32543259859085083, -1.2109376192092896, 1.5635037422180176, -0.9105020761489868, 1.3143813610076904, -0.690172553062439, 1.4425814151763916, -0.8971078395843506, 0.6747006773948669, -0.2607221305370331, 0.4103473424911499, -0.22611814737319946, -0.18671879172325134, 0.22478635609149933, 0.2634037733078003, -0.5630409717559814, -0.9242621660232544, -0.4638790488243103, -1.5689945220947266, -0.950800895690918, -1.1435754299163818, -0.4851548671722412, 1.4297902584075928, 0.11645187437534332, -0.23357319831848145, -0.01095234602689743, 0.08553431183099747, -0.2917191982269287, -1.3155730962753296, 0.6947311758995056, -0.870396614074707, 1.1639409065246582, 0.02675742842257023, -0.00757400318980217, -0.06582240760326385, 0.7310864925384521, 1.6883107423782349, -0.2152671068906784, -0.2575601041316986, 0.2289905846118927, -0.3452957570552826, -0.383836567401886, 0.37028807401657104, -0.3511035144329071, 0.30727526545524597, 0.9167230129241943, 0.16529880464076996, -0.08870425820350647, -0.07466022670269012, -0.22717313468456268, 1.2716755867004395, -0.3626006841659546, -0.72105473279953, -0.27062472701072693, -0.8028567433357239, 0.41013363003730774, -0.5425398349761963, -2.0842463970184326, 0.4041130542755127, -0.34933018684387207, 0.3199901282787323, 0.029382653534412384, -0.38217610120773315, 1.6072299480438232, -0.2139957696199417, -0.637221097946167, -0.18173830211162567, 0.1673598438501358, -0.18535053730010986, 0.10515467822551727, -0.744253396987915, 0.4610694944858551, 0.20036108791828156, -0.3284285068511963, 1.7458646297454834, -0.5771574974060059, 0.3509202003479004, -0.008606445044279099, 0.31601208448410034, 0.1548401117324829, 0.6219085454940796, -2.1394405364990234, 0.15845006704330444, 0.07197026163339615, 0.25262656807899475, 0.06579053401947021, 0.0445045605301857, -1.5967918634414673, 1.8780783414840698, -1.1272008419036865, -1.4500362873077393, -0.8423309922218323, -0.5889037251472473, 0.10737437009811401, -0.07164796441793442, -0.1722888946533203, 0.22112224996089935, -0.08096855878829956, 0.09016288816928864, -0.015506371855735779, 0.10452095419168472, 0.1783527135848999, 0.02364836260676384, 0.5742096304893494, -0.3019937574863434, 0.2933950424194336, -0.3305946886539459, -0.49256622791290283, -0.059250205755233765, 0.8852847814559937, 0.15039357542991638, 1.7080079317092896, 0.5615624785423279, -0.4722549617290497, 0.06665326654911041, -0.053205665200948715, 0.46467503905296326, -0.4685993790626526, 0.9537866115570068, 0.7504734992980957, -0.8837864398956299, 0.44542402029037476, 1.8851397037506104, -0.5816881060600281, 0.6869587302207947, -0.10550442337989807, -0.6511985063552856, 0.8737318515777588, 2.2194552421569824, 1.2419313192367554, 0.21116036176681519, -0.3628416359424591, 1.440630316734314, -1.3291226625442505, 1.0883355140686035, -0.04502640292048454, -0.9480500221252441, -0.906582772731781, -0.7449914813041687, 0.939568042755127, -0.5612624287605286, 0.4725874662399292, -0.07543990761041641, 0.38291752338409424, 1.0286462306976318, -0.07602817565202713, 0.3971967101097107, -1.1995474100112915, -0.1210896372795105, -0.8076462149620056, 0.12150028347969055, 1.1633524894714355, -1.0278759002685547, 1.177788496017456, 0.06634192913770676, -1.2192283868789673, 0.1740211546421051, 0.5201773643493652, -0.8111301064491272, -1.288145899772644, -0.27786847949028015, 0.6161328554153442, 0.8101293444633484, 0.007606773171573877, 0.035237520933151245, 1.3804470300674438, 0.8519508838653564, -1.0262749195098877, 0.17429286241531372, -1.095607876777649, 0.2541939914226532, 0.007228606380522251, -1.442422866821289, -0.4704830050468445, 0.22845083475112915, 0.12824192643165588, -0.8381829261779785, -0.19229429960250854, -0.17392075061798096, -0.4106745421886444, -0.09530826658010483, 0.9916165471076965, 1.749085783958435, -0.20967581868171692, 0.5671603679656982, 0.21464723348617554, 1.4567283391952515, -0.9175335764884949, 0.8255200386047363, -1.2971831560134888, 0.5479162931442261, 0.9204725027084351, 0.603603720664978, 0.8515881299972534, 1.1539498567581177, 0.20463557541370392, -0.9595168828964233, -0.6182208061218262, 0.47038084268569946, 0.8802950382232666, 1.2574964761734009, 0.25806090235710144, -1.7487750053405762, 0.3909752666950226, 0.1275852918624878, 0.1595713496208191, 1.3253744840621948, 0.2859867215156555, -0.021600738167762756, -0.11634626984596252, 0.1914636641740799, -0.19843390583992004, -1.2265040874481201, 0.5082444548606873, -1.0700277090072632, -0.48363667726516724, 0.04220283031463623, -0.2783801555633545, -1.2666594982147217, 0.5552852749824524, -1.0010043382644653, -0.7412916421890259, -0.00696071982383728, -0.41582563519477844, -0.1663159877061844, 0.9998428821563721, -0.18952274322509766, -0.855100154876709, 0.43295201659202576, -0.22480016946792603, 0.24677151441574097, 0.7880158424377441, 0.1878882199525833, -1.427490472793579, 0.6650503873825073, -0.2278839647769928, 0.6151002645492554, -0.054425887763500214, -0.6759178042411804, -0.589756965637207, 0.43854469060897827, 0.30054864287376404, 0.9150928854942322, 0.4147998094558716, -0.04440080001950264, -0.4580157995223999, 0.22061532735824585, 0.41980263590812683, 0.26662352681159973, 0.4565787613391876, 0.5112394094467163, 0.05719628185033798, -0.3491061329841614, 1.5927963256835938, 0.34465542435646057, -1.2306889295578003, -0.2372240275144577, 1.203948736190796, 0.5743578672409058, -0.07707618921995163, 0.26614508032798767, 0.5174498558044434, 0.08720869570970535, -0.40794065594673157, -0.08094697445631027, 0.5723485350608826, 0.15519119799137115, -0.19262124598026276, -0.5193743109703064, 0.15939033031463623, -0.20561040937900543, 2.5811452865600586, 0.9577866196632385, -0.3562552034854889, -0.6102741956710815, 0.8176755309104919, 0.2999020516872406, 0.6822009086608887, -0.64531409740448, 0.07283516228199005, 1.8610464334487915, -1.1735154390335083, 1.1155844926834106, -0.846867561340332, 0.4257456064224243, 1.3773072957992554, 1.0212963819503784, 0.06295029819011688, -0.5410007834434509, 0.4713560938835144, 0.2380068153142929, -1.685140609741211, -0.43778514862060547, -0.2452441155910492, 0.5806519985198975, 1.118287205696106, -1.2926483154296875, -0.354763001203537, -0.11173619329929352, -0.8812477588653564, 0.8788036704063416, -0.38362836837768555, -0.6677197813987732, 0.19325655698776245, -0.5496029257774353, 1.0646995306015015, 0.5734899044036865, -0.3100234270095825, -0.02941722422838211, -1.38490891456604, -0.053607355803251266, -0.4247777760028839, 0.16731971502304077, -0.5463887453079224, 0.17031806707382202, -0.2082882821559906, 0.5809780359268188, 0.15737177431583405, 0.43513578176498413, 0.44566935300827026, -0.21819503605365753, -1.2199230194091797, -0.5034757852554321, 0.365889310836792, 0.1134243756532669, -0.05393238365650177, 0.00018548965454101562, 0.7535566687583923, -0.24979719519615173, -0.06920288503170013, 0.14372405409812927, 0.8699983358383179, -0.10850094258785248, -1.0291668176651, -1.1403017044067383, 0.18761798739433289, 0.07944390922784805, 0.8200569152832031, 0.5068116784095764, 0.8284112215042114, 1.0778926610946655, -0.15227077901363373, 0.881582498550415, 0.4976547956466675, 0.22178523242473602, 0.7190673351287842, 0.5022713541984558, -0.8390051126480103, -0.8458074331283569, 0.5035760402679443, -1.132439374923706, 0.3206050395965576, 0.8730059862136841, -0.7293544411659241, 1.1887582540512085, -0.536067008972168, 0.184086412191391, -0.0061746202409267426, -0.9968743324279785, -0.6617611050605774, -0.30276548862457275, -0.8800727128982544, -1.4914606809616089, 0.9848299026489258, 0.5839979648590088, 0.5962715148925781, -1.1709980964660645, -0.361942857503891, 0.7435777187347412, -0.7745550870895386, 1.1696758270263672, 0.7242509722709656, -0.6915848851203918, -0.787778377532959, 0.11844758689403534, -1.2081997394561768, 0.14505332708358765, -1.4934430122375488, -0.7551590204238892, -0.33239734172821045, -0.11613748967647552, -0.835224986076355, 0.041516564786434174, -0.486211359500885, -0.8266245126724243, -1.0862727165222168, -0.042742036283016205, -0.3630317449569702, 0.4700332283973694, -0.7208739519119263, 0.4421793520450592, -0.24472950398921967, 0.07859735190868378, 0.3036835789680481, -0.9068487286567688, 0.004197359085083008, -0.3117341697216034, -0.8673655986785889, 0.086043581366539, -0.4867948889732361, 0.02780327945947647, 0.4692065119743347, -0.31901735067367554, 0.9330568313598633, -0.5587276816368103, -0.8066303730010986, 0.8747535943984985, -1.3673468828201294, 1.1037567853927612, 1.065603256225586, -0.20639903843402863, 0.07380551844835281, -0.6449920535087585, -0.007001563906669617, 0.3872873783111572, -1.416000485420227, -0.6492065787315369, -0.1413963884115219, -0.15609252452850342, -0.8483040928840637, 0.2748755216598511, -0.25501638650894165, 0.46451982855796814, -0.766758918762207, -0.3260316252708435, -0.944282054901123, -0.22435949742794037, -0.47462332248687744, 0.821194589138031, -0.8952817916870117, 0.5062146186828613, 1.4404066801071167, 0.24215632677078247, 0.830852746963501, 0.3258543908596039, -0.33261948823928833, -0.2819332182407379, -0.054409854114055634, -0.6536542773246765, -0.0002258196473121643, 0.2287123203277588, -2.163848876953125, 0.4728994369506836, -0.2937215566635132, -0.592559814453125, -0.14317551255226135, 0.039955977350473404, -1.0689506530761719, 0.8625741004943848, 0.07933633029460907, 0.15700379014015198, 0.6035330295562744, -1.5662319660186768, 0.6467610597610474, 0.9645611047744751, 0.8330069780349731, -0.8484874963760376, 0.22334331274032593, -1.7014796733856201, -0.9566660523414612, -1.904868245124817, 0.30771690607070923, -0.4173128306865692, 1.169834852218628, 0.6773732304573059, 1.4417786598205566, 0.5682870745658875, 0.16476663947105408, -0.5171328186988831, 0.23206613957881927, -0.2203277051448822, -0.15800534188747406, 2.278604745864868, 0.7326521873474121, 1.1791720390319824, -0.36607858538627625, 2.0449931621551514, 2.2656683921813965, 0.9902157187461853, -0.5656656622886658, 0.34445494413375854, 0.4609249234199524, 1.712591528892517, -0.043530285358428955, -0.7936089038848877, -1.6434675455093384, -0.22187204658985138, 0.06266161054372787, -1.0595815181732178, -0.12223401665687561, 0.3657125234603882, 0.2871432900428772, -0.7559854984283447, -0.7056323885917664, -0.7905158996582031, -1.404165506362915, 0.7598892450332642, -0.49735403060913086, 0.938809871673584, 0.04672111198306084, -0.7948818802833557, 0.13423866033554077, 1.3974982500076294, 1.304200291633606, -0.22204415500164032, -1.0997984409332275, -0.5225594639778137, 0.3850887715816498, 0.4527633786201477, -0.2574901878833771, 0.32859504222869873, -1.9477046728134155, -0.4563472867012024, -0.8940701484680176, -0.4159628450870514, -1.4608163833618164, -0.44772791862487793, -0.6451098322868347, 0.058615703135728836, -0.5323455333709717, -0.6399465799331665, -0.8719016313552856, -0.028044264763593674, -1.228973627090454, -0.40776175260543823, 1.2645659446716309, -0.9751258492469788, 1.5251442193984985, 0.5983078479766846, 0.8372694253921509, -0.9175456166267395, -1.200682520866394, 0.9528214335441589, 0.10896246135234833, -0.25260257720947266, -1.3545072078704834, 0.14294293522834778, 0.5459114909172058, 0.08216950297355652, 0.726294994354248, 0.6206281781196594, 0.14097777009010315, -1.0048028230667114, -0.9762288928031921, 0.25027066469192505, -0.04658249765634537, 0.8456312417984009, 0.8607296347618103, -0.49984002113342285, -0.7294963598251343, -0.7603419423103333, -0.8006911873817444, 0.7774250507354736, -0.13334687054157257, 0.8028297424316406, -1.002670407295227, -0.7334121465682983, -0.22275318205356598, -1.093764305114746, 0.8965562582015991, -0.18334081768989563, 0.013336321339011192, -0.2743288576602936, -0.5601423978805542, -0.08687029778957367, 0.26383528113365173, -1.2060879468917847, 0.8257660269737244, -0.389912873506546, 0.1416797786951065, -0.055221959948539734, -0.43209052085876465, -0.9172345995903015, -0.4291463792324066, 0.7032018899917603, -0.5472372770309448, 0.6098455190658569, -0.7383185625076294, -0.39531785249710083, 0.1445864886045456, 0.8167325258255005, -0.7275242805480957, 0.4934079647064209, 1.8279733657836914, 2.6550207138061523, 1.181665301322937, -0.08337263762950897, -0.3833933472633362, 0.2246008664369583, 0.7001459002494812, -0.07276690006256104, -0.5093886852264404, -1.202061653137207, 0.12638913094997406]\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    ")\n",
    "\n",
    "text = \"This is a sample query.\"\n",
    "query_result = embeddings.embed_query(text)\n",
    "print(query_result)\n",
    "print(len(query_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e3e69d-96ac-4d18-ad0a-11e0bb0cdf36",
   "metadata": {},
   "source": [
    "This code passes a single string input to the embed_query method and retrieves the corresponding\n",
    "text embedding. The result is stored in the query_result variable. The length of the embedding\n",
    "(the number of dimensions) can be obtained using the len() function. \n",
    "\n",
    "You can also obtain embeddings for multiple document inputs using the embed_documents() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25744e60-b4ad-448d-b1e2-09269e048c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "words = [\"cat\", \"dog\", \"computer\", \"animal\"]\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    ")\n",
    "doc_vectors = embeddings.embed_documents(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cd9cfb5-ca20-4a22-ba8c-9af450154073",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.7717188596725464,\n",
       "  1.0309089422225952,\n",
       "  -3.2454001903533936,\n",
       "  -1.6525245904922485,\n",
       "  0.7204437851905823,\n",
       "  0.7939174771308899,\n",
       "  -0.9439053535461426,\n",
       "  0.6470693349838257,\n",
       "  -1.8985167741775513,\n",
       "  -0.5372151136398315,\n",
       "  -0.6041316986083984,\n",
       "  1.4551784992218018,\n",
       "  2.1501429080963135,\n",
       "  0.578033447265625,\n",
       "  -0.014118000864982605,\n",
       "  -0.5572053790092468,\n",
       "  1.6918145418167114,\n",
       "  -1.1941981315612793,\n",
       "  0.6711783409118652,\n",
       "  0.31632357835769653,\n",
       "  0.44778701663017273,\n",
       "  0.4624062776565552,\n",
       "  0.30035534501075745,\n",
       "  0.017211640253663063,\n",
       "  2.849835157394409,\n",
       "  1.7002432346343994,\n",
       "  0.3621326982975006,\n",
       "  0.7707653045654297,\n",
       "  -1.0500714778900146,\n",
       "  0.7595260739326477,\n",
       "  0.8547594547271729,\n",
       "  -0.4365848898887634,\n",
       "  -0.2862957715988159,\n",
       "  -0.18457455933094025,\n",
       "  -2.1360435485839844,\n",
       "  -0.22779615223407745,\n",
       "  2.0792272090911865,\n",
       "  0.45198410749435425,\n",
       "  0.24995695054531097,\n",
       "  1.1447800397872925,\n",
       "  1.0145636796951294,\n",
       "  0.6517409682273865,\n",
       "  -0.6026995778083801,\n",
       "  -0.5098872184753418,\n",
       "  0.06362254172563553,\n",
       "  0.14950408041477203,\n",
       "  0.15848112106323242,\n",
       "  -1.1765817403793335,\n",
       "  -0.5461001992225647,\n",
       "  0.25635138154029846,\n",
       "  -0.3247138559818268,\n",
       "  -0.02989530749619007,\n",
       "  -0.45935365557670593,\n",
       "  -1.5642194747924805,\n",
       "  1.002726435661316,\n",
       "  1.5515649318695068,\n",
       "  2.196007490158081,\n",
       "  -1.2716171741485596,\n",
       "  -1.0397694110870361,\n",
       "  -0.24005688726902008,\n",
       "  2.0366032123565674,\n",
       "  0.1055912896990776,\n",
       "  -0.8343712687492371,\n",
       "  1.7663559913635254,\n",
       "  0.9955558776855469,\n",
       "  -0.04884622246026993,\n",
       "  -0.06846214830875397,\n",
       "  1.588670253753662,\n",
       "  -0.585758626461029,\n",
       "  -0.3135237693786621,\n",
       "  1.7530680894851685,\n",
       "  0.48562175035476685,\n",
       "  0.47513556480407715,\n",
       "  -0.0967918410897255,\n",
       "  -0.3522239625453949,\n",
       "  -0.6930463314056396,\n",
       "  0.10556233674287796,\n",
       "  -0.08557747304439545,\n",
       "  -0.5448663830757141,\n",
       "  1.2778301239013672,\n",
       "  -0.04396652430295944,\n",
       "  0.8077526688575745,\n",
       "  1.4546115398406982,\n",
       "  -0.2289680540561676,\n",
       "  1.2318462133407593,\n",
       "  -0.37697628140449524,\n",
       "  0.005574333015829325,\n",
       "  -0.4103069305419922,\n",
       "  -1.5279557704925537,\n",
       "  0.31838133931159973,\n",
       "  -0.9687839150428772,\n",
       "  0.20178952813148499,\n",
       "  1.2407273054122925,\n",
       "  -0.5009133815765381,\n",
       "  -0.44029945135116577,\n",
       "  0.5512824654579163,\n",
       "  0.04253587871789932,\n",
       "  -0.37795376777648926,\n",
       "  -0.2410614788532257,\n",
       "  -1.8790688514709473,\n",
       "  -1.391498327255249,\n",
       "  -0.24647077918052673,\n",
       "  0.49601903557777405,\n",
       "  -0.177149698138237,\n",
       "  1.1561039686203003,\n",
       "  2.4225831031799316,\n",
       "  -0.3926570415496826,\n",
       "  0.11284277588129044,\n",
       "  -0.683449923992157,\n",
       "  -0.6288449764251709,\n",
       "  -1.0372049808502197,\n",
       "  0.4892081022262573,\n",
       "  -0.35152995586395264,\n",
       "  -0.7828144431114197,\n",
       "  0.3683066964149475,\n",
       "  0.3150665760040283,\n",
       "  1.840786337852478,\n",
       "  -0.3345949351787567,\n",
       "  0.5866679549217224,\n",
       "  0.5109255313873291,\n",
       "  -0.7154868841171265,\n",
       "  -0.23612508177757263,\n",
       "  0.4988676905632019,\n",
       "  1.2062671184539795,\n",
       "  0.6303960680961609,\n",
       "  0.9342679977416992,\n",
       "  -1.5946791172027588,\n",
       "  0.22777897119522095,\n",
       "  0.1231391653418541,\n",
       "  0.979138970375061,\n",
       "  0.12451925873756409,\n",
       "  -0.07808464020490646,\n",
       "  0.2901894450187683,\n",
       "  0.4251309037208557,\n",
       "  -0.1523093432188034,\n",
       "  0.8938007354736328,\n",
       "  0.21761372685432434,\n",
       "  -1.5049446821212769,\n",
       "  0.958389163017273,\n",
       "  0.8523901104927063,\n",
       "  1.2856967449188232,\n",
       "  0.016827888786792755,\n",
       "  0.8588170409202576,\n",
       "  -0.05441920831799507,\n",
       "  -0.2588103711605072,\n",
       "  -0.3514874577522278,\n",
       "  1.7121809720993042,\n",
       "  -0.9637351036071777,\n",
       "  -0.705095112323761,\n",
       "  0.10265382379293442,\n",
       "  -0.11031029373407364,\n",
       "  0.9762860536575317,\n",
       "  0.15868020057678223,\n",
       "  1.9091726541519165,\n",
       "  1.199974775314331,\n",
       "  -1.0201307535171509,\n",
       "  0.46402934193611145,\n",
       "  0.4196373522281647,\n",
       "  -0.71122807264328,\n",
       "  0.9507030844688416,\n",
       "  0.9318891167640686,\n",
       "  -0.2839198708534241,\n",
       "  -1.6326780319213867,\n",
       "  -0.18009252846240997,\n",
       "  -0.35140863060951233,\n",
       "  -0.9784924387931824,\n",
       "  1.1271792650222778,\n",
       "  1.0512758493423462,\n",
       "  0.39662325382232666,\n",
       "  1.461558222770691,\n",
       "  0.2423381805419922,\n",
       "  -0.6903484463691711,\n",
       "  -1.224905252456665,\n",
       "  0.5333160758018494,\n",
       "  -0.29480814933776855,\n",
       "  -0.5494104623794556,\n",
       "  1.04952871799469,\n",
       "  -1.0742552280426025,\n",
       "  -0.18073925375938416,\n",
       "  -1.1039963960647583,\n",
       "  1.107704997062683,\n",
       "  -0.9043551087379456,\n",
       "  0.37729412317276,\n",
       "  0.772900402545929,\n",
       "  -0.38230034708976746,\n",
       "  -0.5238728523254395,\n",
       "  -0.6514272093772888,\n",
       "  -0.4255037307739258,\n",
       "  -0.7489071488380432,\n",
       "  -0.9789689183235168,\n",
       "  -1.5457431077957153,\n",
       "  1.1009552478790283,\n",
       "  -0.7427445650100708,\n",
       "  0.0217752605676651,\n",
       "  -1.1479634046554565,\n",
       "  -0.878333568572998,\n",
       "  0.9554181694984436,\n",
       "  -0.8347075581550598,\n",
       "  -0.7021329998970032,\n",
       "  -0.6732887625694275,\n",
       "  -0.6074435114860535,\n",
       "  -0.28873300552368164,\n",
       "  -1.6774314641952515,\n",
       "  0.2731853127479553,\n",
       "  -1.3502634763717651,\n",
       "  0.41903698444366455,\n",
       "  -1.2755171060562134,\n",
       "  0.5554221868515015,\n",
       "  -0.01929435320198536,\n",
       "  0.8720799684524536,\n",
       "  1.8964661359786987,\n",
       "  0.26167795062065125,\n",
       "  -0.8453285098075867,\n",
       "  0.3316769301891327,\n",
       "  -0.5040820837020874,\n",
       "  -1.3847360610961914,\n",
       "  -0.44811975955963135,\n",
       "  -0.8052797913551331,\n",
       "  -0.8454448580741882,\n",
       "  0.09548759460449219,\n",
       "  0.7942990660667419,\n",
       "  -0.21607032418251038,\n",
       "  1.2302740812301636,\n",
       "  -1.123327612876892,\n",
       "  1.092645287513733,\n",
       "  0.005274377763271332,\n",
       "  0.09565601497888565,\n",
       "  -0.46209415793418884,\n",
       "  -1.297376036643982,\n",
       "  0.4264374375343323,\n",
       "  -0.9719712138175964,\n",
       "  -0.5039177536964417,\n",
       "  0.537325918674469,\n",
       "  0.35907649993896484,\n",
       "  -0.323403924703598,\n",
       "  1.4548649787902832,\n",
       "  1.5576244592666626,\n",
       "  1.4307992458343506,\n",
       "  -0.14294220507144928,\n",
       "  -0.3142551779747009,\n",
       "  0.12488598376512527,\n",
       "  0.7693071365356445,\n",
       "  -1.0795468091964722,\n",
       "  -0.43083685636520386,\n",
       "  -0.7070075869560242,\n",
       "  0.9877952933311462,\n",
       "  0.541462242603302,\n",
       "  -0.3064242899417877,\n",
       "  0.24975767731666565,\n",
       "  1.398213505744934,\n",
       "  -0.34613120555877686,\n",
       "  -0.1266421675682068,\n",
       "  1.3266624212265015,\n",
       "  -0.5417084097862244,\n",
       "  0.6054713129997253,\n",
       "  -1.6421997547149658,\n",
       "  0.15010711550712585,\n",
       "  -0.22961771488189697,\n",
       "  -0.36248746514320374,\n",
       "  -0.16898034512996674,\n",
       "  -0.22509612143039703,\n",
       "  -1.8888791799545288,\n",
       "  0.1831808090209961,\n",
       "  -1.5224852561950684,\n",
       "  -0.7752118706703186,\n",
       "  -0.28544875979423523,\n",
       "  -0.1327562928199768,\n",
       "  -0.10425572842359543,\n",
       "  0.7837252020835876,\n",
       "  -0.5917967557907104,\n",
       "  1.0060734748840332,\n",
       "  0.9952933192253113,\n",
       "  0.13420811295509338,\n",
       "  0.1817181408405304,\n",
       "  -0.26962003111839294,\n",
       "  -0.5949024558067322,\n",
       "  -0.22602251172065735,\n",
       "  -1.1835291385650635,\n",
       "  0.002728927182033658,\n",
       "  0.0896616280078888,\n",
       "  0.4849497079849243,\n",
       "  -0.574141800403595,\n",
       "  -1.3573524951934814,\n",
       "  -0.3496896028518677,\n",
       "  -0.16940537095069885,\n",
       "  0.42721959948539734,\n",
       "  0.7620348930358887,\n",
       "  1.0262267589569092,\n",
       "  0.4583868682384491,\n",
       "  -0.5553185343742371,\n",
       "  1.3292019367218018,\n",
       "  -0.08294368535280228,\n",
       "  -0.439804345369339,\n",
       "  1.446977138519287,\n",
       "  -0.023847388103604317,\n",
       "  -1.080198049545288,\n",
       "  1.6332080364227295,\n",
       "  -0.1856248527765274,\n",
       "  0.7109230756759644,\n",
       "  -0.6336239576339722,\n",
       "  0.6012776494026184,\n",
       "  1.1852916479110718,\n",
       "  -0.01399028580635786,\n",
       "  0.8154668807983398,\n",
       "  0.15580549836158752,\n",
       "  0.4048525393009186,\n",
       "  0.810660183429718,\n",
       "  -0.16322484612464905,\n",
       "  0.7393059134483337,\n",
       "  -0.14775961637496948,\n",
       "  -1.3208004236221313,\n",
       "  -1.0560216903686523,\n",
       "  0.5694972276687622,\n",
       "  0.046508222818374634,\n",
       "  -1.7898499965667725,\n",
       "  0.14747563004493713,\n",
       "  -0.5379517078399658,\n",
       "  0.2635370194911957,\n",
       "  0.6264338493347168,\n",
       "  0.6743236780166626,\n",
       "  0.07289448380470276,\n",
       "  -0.8318761587142944,\n",
       "  1.1051573753356934,\n",
       "  -0.708375096321106,\n",
       "  -0.02606232278048992,\n",
       "  -0.46742555499076843,\n",
       "  -1.0567244291305542,\n",
       "  0.7915072441101074,\n",
       "  -0.09900666773319244,\n",
       "  -0.8598942756652832,\n",
       "  -0.002344781067222357,\n",
       "  0.9677391052246094,\n",
       "  1.108209252357483,\n",
       "  -0.693670392036438,\n",
       "  -0.25385820865631104,\n",
       "  0.4955112338066101,\n",
       "  0.3077719509601593,\n",
       "  0.30681633949279785,\n",
       "  -0.8235563039779663,\n",
       "  0.0891232043504715,\n",
       "  1.5751142501831055,\n",
       "  -1.1872918605804443,\n",
       "  0.30879950523376465,\n",
       "  -1.190129041671753,\n",
       "  1.752550721168518,\n",
       "  -1.8320722579956055,\n",
       "  -0.8718439340591431,\n",
       "  0.12316052615642548,\n",
       "  0.5515384078025818,\n",
       "  0.29594218730926514,\n",
       "  -1.5279649496078491,\n",
       "  -0.4028342664241791,\n",
       "  -0.11077675968408585,\n",
       "  0.7411999106407166,\n",
       "  -0.00516924075782299,\n",
       "  0.44908416271209717,\n",
       "  0.5719848275184631,\n",
       "  0.23600201308727264,\n",
       "  -0.9713648557662964,\n",
       "  0.10699208080768585,\n",
       "  0.7867777943611145,\n",
       "  -1.5073375701904297,\n",
       "  -0.18160225450992584,\n",
       "  0.2526625990867615,\n",
       "  0.7136651873588562,\n",
       "  1.2816606760025024,\n",
       "  1.2717022895812988,\n",
       "  0.11030080914497375,\n",
       "  0.643733024597168,\n",
       "  0.8880311250686646,\n",
       "  -0.30827978253364563,\n",
       "  -0.6592755913734436,\n",
       "  0.3237406015396118,\n",
       "  -0.14927874505519867,\n",
       "  1.6379448175430298,\n",
       "  0.036529578268527985,\n",
       "  -1.012722134590149,\n",
       "  -0.5369856953620911,\n",
       "  -0.6051604151725769,\n",
       "  0.32562828063964844,\n",
       "  0.09142249822616577,\n",
       "  0.07321256399154663,\n",
       "  -0.08948999643325806,\n",
       "  0.014572588726878166,\n",
       "  1.1371452808380127,\n",
       "  -0.006079866085201502,\n",
       "  -1.115062952041626,\n",
       "  0.7125245928764343,\n",
       "  0.023113785311579704,\n",
       "  0.6941862106323242,\n",
       "  -0.1712031215429306,\n",
       "  0.03096742182970047,\n",
       "  -1.5838181972503662,\n",
       "  0.011837157420814037,\n",
       "  0.15208235383033752,\n",
       "  -0.8160439729690552,\n",
       "  1.0468640327453613,\n",
       "  0.20977744460105896,\n",
       "  -0.7248472571372986,\n",
       "  0.9138599634170532,\n",
       "  -0.6523595452308655,\n",
       "  -0.5285582542419434,\n",
       "  -0.0473300963640213,\n",
       "  1.0422221422195435,\n",
       "  -0.05311259627342224,\n",
       "  1.3386367559432983,\n",
       "  0.6724856495857239,\n",
       "  -1.1155232191085815,\n",
       "  0.998680591583252,\n",
       "  0.08679145574569702,\n",
       "  -0.2301873415708542,\n",
       "  1.3336597681045532,\n",
       "  -0.3755987286567688,\n",
       "  -0.8694241642951965,\n",
       "  0.4305688440799713,\n",
       "  0.6393604278564453,\n",
       "  0.8939700722694397,\n",
       "  0.41612526774406433,\n",
       "  -0.5270268321037292,\n",
       "  -0.7999024391174316,\n",
       "  0.856759786605835,\n",
       "  0.8167700171470642,\n",
       "  -1.2533085346221924,\n",
       "  0.22464297711849213,\n",
       "  0.14728766679763794,\n",
       "  -0.4207245111465454,\n",
       "  -0.3963267207145691,\n",
       "  1.1979588270187378,\n",
       "  -0.2997722029685974,\n",
       "  -1.1774760484695435,\n",
       "  -0.3242214322090149,\n",
       "  0.06816720962524414,\n",
       "  0.24156619608402252,\n",
       "  1.1271814107894897,\n",
       "  -0.6004382371902466,\n",
       "  0.1700972616672516,\n",
       "  -0.5967203974723816,\n",
       "  0.17321617901325226,\n",
       "  0.6428110599517822,\n",
       "  1.264747142791748,\n",
       "  0.46136990189552307,\n",
       "  -0.8873606324195862,\n",
       "  -1.0125309228897095,\n",
       "  -0.32157784700393677,\n",
       "  -0.12144031375646591,\n",
       "  1.018362045288086,\n",
       "  0.6709908843040466,\n",
       "  -1.8514460325241089,\n",
       "  -0.7859243154525757,\n",
       "  1.4994125366210938,\n",
       "  -0.8792381882667542,\n",
       "  1.0098834037780762,\n",
       "  0.0908581018447876,\n",
       "  0.7294541001319885,\n",
       "  1.958188533782959,\n",
       "  -2.4478888511657715,\n",
       "  -0.7683789134025574,\n",
       "  -0.48894304037094116,\n",
       "  0.861936092376709,\n",
       "  0.36668452620506287,\n",
       "  0.7450284957885742,\n",
       "  1.2996495962142944,\n",
       "  -1.7239775657653809,\n",
       "  0.14674760401248932,\n",
       "  1.3924596309661865,\n",
       "  -0.005840398836880922,\n",
       "  0.5947576761245728,\n",
       "  0.06643101572990417,\n",
       "  1.2641160488128662,\n",
       "  1.9817460775375366,\n",
       "  -0.18922047317028046,\n",
       "  0.265972763299942,\n",
       "  0.15900413691997528,\n",
       "  -1.2620110511779785,\n",
       "  -0.002400543773546815,\n",
       "  -0.49055561423301697,\n",
       "  0.04068054258823395,\n",
       "  0.11052843928337097,\n",
       "  -0.09277691692113876,\n",
       "  0.8249126076698303,\n",
       "  -0.036879461258649826,\n",
       "  0.3875325620174408,\n",
       "  0.006523560266941786,\n",
       "  -1.7011520862579346,\n",
       "  0.08573286980390549,\n",
       "  0.09346818923950195,\n",
       "  0.06263946741819382,\n",
       "  0.2614154815673828,\n",
       "  -0.8819417953491211,\n",
       "  -0.3836766481399536,\n",
       "  0.3471566140651703,\n",
       "  0.5071466565132141,\n",
       "  -0.009198149666190147,\n",
       "  -0.38470953702926636,\n",
       "  -0.48576033115386963,\n",
       "  -0.1670895516872406,\n",
       "  0.6298079490661621,\n",
       "  0.08343801647424698,\n",
       "  1.6419697999954224,\n",
       "  0.9222766160964966,\n",
       "  0.10167840868234634,\n",
       "  -0.05571391060948372,\n",
       "  -0.22247156500816345,\n",
       "  1.244828462600708,\n",
       "  1.0560728311538696,\n",
       "  -0.6795501112937927,\n",
       "  -0.7548357248306274,\n",
       "  -1.3618488311767578,\n",
       "  -0.8311790227890015,\n",
       "  -0.5852933526039124,\n",
       "  -0.7320753931999207,\n",
       "  0.13202480971813202,\n",
       "  0.17710180580615997,\n",
       "  0.9820990562438965,\n",
       "  1.9385817050933838,\n",
       "  -0.12593215703964233,\n",
       "  0.6712968349456787,\n",
       "  -0.08072341233491898,\n",
       "  -0.011091061867773533,\n",
       "  0.4034143090248108,\n",
       "  0.8651745915412903,\n",
       "  -0.37840771675109863,\n",
       "  -0.9809575080871582,\n",
       "  -0.02545921318233013,\n",
       "  -0.4582943320274353,\n",
       "  0.1296907216310501,\n",
       "  0.9257448315620422,\n",
       "  -1.3508086204528809,\n",
       "  -0.3541356325149536,\n",
       "  -0.6715032458305359,\n",
       "  0.5206411480903625,\n",
       "  0.15575915575027466,\n",
       "  -1.469618558883667,\n",
       "  -1.159159779548645,\n",
       "  -0.5257123708724976,\n",
       "  -1.0179297924041748,\n",
       "  -0.4411426782608032,\n",
       "  -0.2670416831970215,\n",
       "  -0.2148827612400055,\n",
       "  -0.21003630757331848,\n",
       "  -0.6067033410072327,\n",
       "  -0.2259945571422577,\n",
       "  -0.16094231605529785,\n",
       "  0.8364918828010559,\n",
       "  0.07500556111335754,\n",
       "  0.15515436232089996,\n",
       "  -0.18441544473171234,\n",
       "  -0.054110415279865265,\n",
       "  -1.311026930809021,\n",
       "  -1.0159006118774414,\n",
       "  0.9717004895210266,\n",
       "  -1.6968779563903809,\n",
       "  -0.6202425956726074,\n",
       "  0.07101313769817352,\n",
       "  -0.027882220223546028,\n",
       "  -0.9476311802864075,\n",
       "  -0.024282194674015045,\n",
       "  0.7042746543884277,\n",
       "  -0.42948758602142334,\n",
       "  -1.2749850749969482,\n",
       "  0.7522425055503845,\n",
       "  -0.07714198529720306,\n",
       "  1.2460532188415527,\n",
       "  0.7929213643074036,\n",
       "  0.13030824065208435,\n",
       "  0.3000372052192688,\n",
       "  -0.08276354521512985,\n",
       "  0.8421987295150757,\n",
       "  0.3410131335258484,\n",
       "  -0.4564364552497864,\n",
       "  -0.5429307222366333,\n",
       "  -0.03839618340134621,\n",
       "  -0.7350100874900818,\n",
       "  -0.42190688848495483,\n",
       "  0.12831735610961914,\n",
       "  0.06646454334259033,\n",
       "  0.160757377743721,\n",
       "  0.4789015054702759,\n",
       "  -1.2288028001785278,\n",
       "  -0.6107956171035767,\n",
       "  0.2703644931316376,\n",
       "  -0.7860599756240845,\n",
       "  -1.0737498998641968,\n",
       "  -0.4944068491458893,\n",
       "  -0.397602379322052,\n",
       "  -0.06884487718343735,\n",
       "  -1.0788127183914185,\n",
       "  -0.696276843547821,\n",
       "  0.16415351629257202,\n",
       "  0.217951238155365,\n",
       "  0.11478794366121292,\n",
       "  -0.7414450645446777,\n",
       "  -0.2931674122810364,\n",
       "  -0.5881572365760803,\n",
       "  0.2339896559715271,\n",
       "  0.4488842189311981,\n",
       "  -0.2896333932876587,\n",
       "  -1.1560879945755005,\n",
       "  0.1793527454137802,\n",
       "  -0.7595891952514648,\n",
       "  -0.657190203666687,\n",
       "  0.9133917689323425,\n",
       "  1.686598300933838,\n",
       "  -1.2731852531433105,\n",
       "  -0.7472933530807495,\n",
       "  0.7811073064804077,\n",
       "  0.5431769490242004,\n",
       "  -0.002333683893084526,\n",
       "  -0.6218106150627136,\n",
       "  -0.9381048679351807,\n",
       "  0.5377113819122314,\n",
       "  0.030855827033519745,\n",
       "  -0.11299119144678116,\n",
       "  -0.05787980929017067,\n",
       "  0.7855027914047241,\n",
       "  -0.45281559228897095,\n",
       "  1.7289831638336182,\n",
       "  -0.295168399810791,\n",
       "  -0.4090964198112488,\n",
       "  -0.1329704225063324,\n",
       "  -0.3964812755584717,\n",
       "  -1.222161889076233,\n",
       "  0.7611773610115051,\n",
       "  -0.42005303502082825,\n",
       "  0.8915858864784241,\n",
       "  -0.1170075386762619,\n",
       "  -0.8446839451789856,\n",
       "  -0.001760056708008051,\n",
       "  0.20800752937793732,\n",
       "  1.2219257354736328,\n",
       "  -0.5880127549171448,\n",
       "  0.5252568125724792,\n",
       "  -1.6013755798339844,\n",
       "  -1.3631951808929443,\n",
       "  -0.15263701975345612,\n",
       "  -0.15198394656181335,\n",
       "  -1.2317065000534058,\n",
       "  -0.6378090977668762,\n",
       "  -0.22366882860660553,\n",
       "  0.3695838749408722,\n",
       "  0.5606662631034851,\n",
       "  0.1019764319062233,\n",
       "  -0.0465066060423851,\n",
       "  -0.6323215365409851,\n",
       "  0.30917036533355713,\n",
       "  -1.1920294761657715,\n",
       "  0.946891725063324,\n",
       "  0.024523157626390457,\n",
       "  0.4017939865589142,\n",
       "  -1.0535391569137573,\n",
       "  1.2081104516983032,\n",
       "  2.269792318344116,\n",
       "  -0.3203449547290802,\n",
       "  0.301181435585022,\n",
       "  1.3386542797088623,\n",
       "  -1.408956527709961,\n",
       "  0.18556584417819977,\n",
       "  -1.0557657480239868,\n",
       "  -0.4524129033088684,\n",
       "  -0.4709186851978302,\n",
       "  0.04988342896103859,\n",
       "  -0.2784005403518677,\n",
       "  -0.38063928484916687,\n",
       "  0.062404315918684006,\n",
       "  1.124484896659851,\n",
       "  -0.5457385778427124,\n",
       "  0.18301555514335632,\n",
       "  -0.9940823912620544,\n",
       "  -1.3185933828353882,\n",
       "  -0.6086262464523315,\n",
       "  0.6446277499198914,\n",
       "  0.3065759837627411,\n",
       "  0.7932758331298828,\n",
       "  -0.02652924880385399,\n",
       "  0.1861618310213089,\n",
       "  1.0218502283096313,\n",
       "  0.1745915710926056,\n",
       "  1.5522938966751099,\n",
       "  0.8037228584289551,\n",
       "  -1.0254851579666138,\n",
       "  0.4695143401622772,\n",
       "  -0.43184104561805725,\n",
       "  -0.42588284611701965,\n",
       "  0.9569547176361084,\n",
       "  0.2863008379936218,\n",
       "  -2.608757257461548,\n",
       "  0.6452140808105469,\n",
       "  -1.460004210472107,\n",
       "  0.28106728196144104,\n",
       "  -0.8086926341056824,\n",
       "  0.4732748866081238,\n",
       "  -1.923712134361267,\n",
       "  0.8174495100975037,\n",
       "  -0.46725404262542725,\n",
       "  -0.38184577226638794,\n",
       "  -0.3004201054573059,\n",
       "  0.4805849492549896,\n",
       "  -0.19583794474601746,\n",
       "  -0.32933440804481506,\n",
       "  1.9813865423202515,\n",
       "  -0.178144633769989,\n",
       "  0.7716463804244995,\n",
       "  -0.04054054617881775,\n",
       "  0.7955785393714905,\n",
       "  -0.13705474138259888,\n",
       "  -0.8767654299736023,\n",
       "  -0.5034687519073486,\n",
       "  0.023362671956419945,\n",
       "  -0.03572553023695946,\n",
       "  0.18504399061203003,\n",
       "  -0.26133331656455994,\n",
       "  0.9350084662437439,\n",
       "  -0.6821648478507996,\n",
       "  0.2717694640159607,\n",
       "  0.476837158203125,\n",
       "  -0.11573164165019989,\n",
       "  -0.28683924674987793,\n",
       "  0.1582363396883011,\n",
       "  -0.45678025484085083,\n",
       "  1.7875688076019287,\n",
       "  0.6387368440628052,\n",
       "  -0.2774260938167572,\n",
       "  0.13193930685520172,\n",
       "  -0.18086875975131989,\n",
       "  -0.02152128331363201,\n",
       "  -1.0069630146026611,\n",
       "  0.5355061888694763,\n",
       "  -0.7195471525192261,\n",
       "  1.532026767730713,\n",
       "  0.4902706444263458,\n",
       "  0.4162465035915375,\n",
       "  -0.011204197071492672,\n",
       "  -1.3698997497558594,\n",
       "  0.709191620349884,\n",
       "  -0.4755409359931946,\n",
       "  -0.0008497544913552701,\n",
       "  -1.3356274366378784,\n",
       "  -0.06233725696802139,\n",
       "  0.22705072164535522,\n",
       "  -0.8277896642684937,\n",
       "  -1.192234754562378,\n",
       "  -0.2525407373905182,\n",
       "  0.2907256484031677,\n",
       "  -0.07354174554347992,\n",
       "  -0.21418067812919617,\n",
       "  0.03646191209554672,\n",
       "  -0.9436604380607605,\n",
       "  -0.055509302765131,\n",
       "  1.536651849746704,\n",
       "  -0.9829429388046265,\n",
       "  0.5547512769699097,\n",
       "  -0.733458936214447,\n",
       "  -1.455413818359375,\n",
       "  -0.33601972460746765,\n",
       "  -0.09978052228689194,\n",
       "  0.7373764514923096,\n",
       "  -0.6842513680458069,\n",
       "  1.6015714406967163,\n",
       "  1.105846643447876,\n",
       "  0.041324879974126816,\n",
       "  0.3278428614139557,\n",
       "  -0.671728789806366,\n",
       "  1.708365797996521,\n",
       "  -0.1280783712863922,\n",
       "  -0.23385797441005707,\n",
       "  -0.4904670715332031,\n",
       "  -0.5624747276306152,\n",
       "  -0.784548819065094],\n",
       " [0.26116693019866943,\n",
       "  0.038772113621234894,\n",
       "  -3.6801345348358154,\n",
       "  -1.833993673324585,\n",
       "  0.4224504828453064,\n",
       "  0.6381832361221313,\n",
       "  -0.6209225058555603,\n",
       "  1.0520128011703491,\n",
       "  -1.4182243347167969,\n",
       "  -1.5008978843688965,\n",
       "  -0.6659188866615295,\n",
       "  1.107799768447876,\n",
       "  1.086401104927063,\n",
       "  0.2433466613292694,\n",
       "  0.4389606714248657,\n",
       "  -0.7664315104484558,\n",
       "  1.489372968673706,\n",
       "  -1.7160091400146484,\n",
       "  1.277543544769287,\n",
       "  0.18449483811855316,\n",
       "  0.21702635288238525,\n",
       "  1.530013084411621,\n",
       "  0.3127829134464264,\n",
       "  0.6465379595756531,\n",
       "  4.0531840324401855,\n",
       "  0.885586142539978,\n",
       "  0.175531804561615,\n",
       "  0.7073987722396851,\n",
       "  -0.7657634615898132,\n",
       "  0.6932646036148071,\n",
       "  -0.05120917782187462,\n",
       "  -0.014230617322027683,\n",
       "  -0.6604363322257996,\n",
       "  0.23944923281669617,\n",
       "  -0.605119526386261,\n",
       "  -0.38504931330680847,\n",
       "  1.1493961811065674,\n",
       "  1.2239164113998413,\n",
       "  -0.4355546832084656,\n",
       "  0.48017147183418274,\n",
       "  1.267346978187561,\n",
       "  0.5638874173164368,\n",
       "  -0.06826653331518173,\n",
       "  0.05691782757639885,\n",
       "  1.1236907243728638,\n",
       "  -0.9128497838973999,\n",
       "  1.1121691465377808,\n",
       "  -0.7505840063095093,\n",
       "  -0.004655277822166681,\n",
       "  -0.13548317551612854,\n",
       "  0.6585513353347778,\n",
       "  0.7583655118942261,\n",
       "  0.4916955828666687,\n",
       "  -0.9202736020088196,\n",
       "  1.709333062171936,\n",
       "  0.886333703994751,\n",
       "  1.4176640510559082,\n",
       "  -0.571077823638916,\n",
       "  -0.8772395253181458,\n",
       "  -0.0161251500248909,\n",
       "  2.1780591011047363,\n",
       "  0.7860655784606934,\n",
       "  -1.3375502824783325,\n",
       "  0.10557258874177933,\n",
       "  1.3357110023498535,\n",
       "  -1.9370609521865845,\n",
       "  -0.04315654933452606,\n",
       "  1.2566384077072144,\n",
       "  -0.7461757659912109,\n",
       "  -0.07906919717788696,\n",
       "  2.2896573543548584,\n",
       "  -0.07713937014341354,\n",
       "  0.5732525587081909,\n",
       "  -0.13998711109161377,\n",
       "  -0.43324360251426697,\n",
       "  -1.3175331354141235,\n",
       "  -0.3733130991458893,\n",
       "  0.11386211216449738,\n",
       "  -0.05979745090007782,\n",
       "  0.5730257034301758,\n",
       "  0.049055445939302444,\n",
       "  0.909483790397644,\n",
       "  1.4257992506027222,\n",
       "  -0.057918380945920944,\n",
       "  1.3833730220794678,\n",
       "  -0.7386223077774048,\n",
       "  -0.7074645757675171,\n",
       "  -1.0608172416687012,\n",
       "  -1.420855164527893,\n",
       "  0.4414244294166565,\n",
       "  -0.39080536365509033,\n",
       "  0.07382475584745407,\n",
       "  0.7635982036590576,\n",
       "  -0.1549527943134308,\n",
       "  -0.7397984266281128,\n",
       "  -0.49877238273620605,\n",
       "  0.10076575726270676,\n",
       "  -0.20258183777332306,\n",
       "  0.11044430732727051,\n",
       "  -1.4272416830062866,\n",
       "  -1.23902428150177,\n",
       "  -0.46430742740631104,\n",
       "  0.45732933282852173,\n",
       "  0.5306390523910522,\n",
       "  0.3189138174057007,\n",
       "  2.4266321659088135,\n",
       "  0.5188050866127014,\n",
       "  0.4634227752685547,\n",
       "  -0.37856772541999817,\n",
       "  -0.2842203974723816,\n",
       "  -1.4788354635238647,\n",
       "  0.820239782333374,\n",
       "  0.4760490357875824,\n",
       "  -0.7486407160758972,\n",
       "  0.5231245756149292,\n",
       "  0.5307334661483765,\n",
       "  1.9244084358215332,\n",
       "  0.1255560964345932,\n",
       "  0.0874878391623497,\n",
       "  1.3813098669052124,\n",
       "  -1.1592975854873657,\n",
       "  -0.01796971634030342,\n",
       "  -0.00026943429838865995,\n",
       "  1.7435722351074219,\n",
       "  0.06974436342716217,\n",
       "  0.31219542026519775,\n",
       "  -0.6374872326850891,\n",
       "  0.7604613900184631,\n",
       "  -0.10163278877735138,\n",
       "  0.26956191658973694,\n",
       "  -0.10968491435050964,\n",
       "  -0.4570991098880768,\n",
       "  0.16582705080509186,\n",
       "  0.3514387905597687,\n",
       "  0.276719868183136,\n",
       "  0.6200173497200012,\n",
       "  -0.3400534689426422,\n",
       "  -0.9092640280723572,\n",
       "  -0.07239007949829102,\n",
       "  0.7907003164291382,\n",
       "  0.7049591541290283,\n",
       "  0.9526897668838501,\n",
       "  0.3290935158729553,\n",
       "  0.13856758177280426,\n",
       "  -0.29997140169143677,\n",
       "  -0.8539673089981079,\n",
       "  0.9694918990135193,\n",
       "  -1.09037446975708,\n",
       "  0.020646924152970314,\n",
       "  -0.4371296465396881,\n",
       "  0.04117100313305855,\n",
       "  0.7539941668510437,\n",
       "  -0.5939452648162842,\n",
       "  1.7234046459197998,\n",
       "  1.37495756149292,\n",
       "  -0.7032638192176819,\n",
       "  0.581520140171051,\n",
       "  0.8406816124916077,\n",
       "  -0.5699050426483154,\n",
       "  0.9465509653091431,\n",
       "  1.0383472442626953,\n",
       "  -0.7503629922866821,\n",
       "  -0.5458738207817078,\n",
       "  0.5256272554397583,\n",
       "  -0.14682190120220184,\n",
       "  -0.32458898425102234,\n",
       "  -0.08087358623743057,\n",
       "  0.9091811776161194,\n",
       "  0.22184619307518005,\n",
       "  1.1871908903121948,\n",
       "  0.32528793811798096,\n",
       "  -1.4938852787017822,\n",
       "  -0.1692320853471756,\n",
       "  0.48471370339393616,\n",
       "  -0.2013004571199417,\n",
       "  -0.3664359450340271,\n",
       "  0.33452481031417847,\n",
       "  -1.6204346418380737,\n",
       "  -0.626704752445221,\n",
       "  -0.6758406758308411,\n",
       "  0.7439106702804565,\n",
       "  -1.004127860069275,\n",
       "  0.32866066694259644,\n",
       "  0.8638191819190979,\n",
       "  -0.2317979633808136,\n",
       "  -0.1025610864162445,\n",
       "  0.17297345399856567,\n",
       "  -0.6059375405311584,\n",
       "  -0.6176363229751587,\n",
       "  -1.059140682220459,\n",
       "  -2.2299885749816895,\n",
       "  0.7223286032676697,\n",
       "  -0.3382948637008667,\n",
       "  -0.31816786527633667,\n",
       "  -1.3380799293518066,\n",
       "  -0.45552632212638855,\n",
       "  0.10040359199047089,\n",
       "  -1.4642211198806763,\n",
       "  0.2017996609210968,\n",
       "  -0.8667886257171631,\n",
       "  0.5515345335006714,\n",
       "  -0.029977425932884216,\n",
       "  -1.3176624774932861,\n",
       "  -0.19027186930179596,\n",
       "  -1.9932100772857666,\n",
       "  -0.5231024026870728,\n",
       "  -0.8608329892158508,\n",
       "  0.7749274969100952,\n",
       "  -0.3433953821659088,\n",
       "  0.7932929992675781,\n",
       "  1.6613712310791016,\n",
       "  -0.2827411890029907,\n",
       "  -1.3413333892822266,\n",
       "  -0.13402971625328064,\n",
       "  0.07052887231111526,\n",
       "  -0.6914217472076416,\n",
       "  -0.056977737694978714,\n",
       "  0.08615285903215408,\n",
       "  -0.23085452616214752,\n",
       "  0.460419237613678,\n",
       "  0.7956045269966125,\n",
       "  0.3772701323032379,\n",
       "  -0.19755510985851288,\n",
       "  -1.7860207557678223,\n",
       "  0.6352857351303101,\n",
       "  0.039055902510881424,\n",
       "  -0.30562862753868103,\n",
       "  -1.0513406991958618,\n",
       "  -1.261817216873169,\n",
       "  -0.03972509875893593,\n",
       "  -1.12368643283844,\n",
       "  -0.9232870936393738,\n",
       "  0.5584235191345215,\n",
       "  -0.04115595668554306,\n",
       "  -0.09763065725564957,\n",
       "  0.6378311514854431,\n",
       "  1.268212914466858,\n",
       "  0.8583604097366333,\n",
       "  -0.2739948630332947,\n",
       "  -0.019364643841981888,\n",
       "  0.8680413961410522,\n",
       "  0.6478082537651062,\n",
       "  -0.6450585722923279,\n",
       "  -0.4016840159893036,\n",
       "  -1.2573447227478027,\n",
       "  1.4290746450424194,\n",
       "  0.32772940397262573,\n",
       "  -0.7948550581932068,\n",
       "  0.6839030385017395,\n",
       "  1.448806643486023,\n",
       "  -0.4473227858543396,\n",
       "  -0.11941312253475189,\n",
       "  1.5912643671035767,\n",
       "  0.5280860662460327,\n",
       "  0.4523899257183075,\n",
       "  -1.5019543170928955,\n",
       "  -0.11070962250232697,\n",
       "  -0.3451181650161743,\n",
       "  -0.09698765724897385,\n",
       "  0.7159489989280701,\n",
       "  0.5060527324676514,\n",
       "  -1.0716689825057983,\n",
       "  0.6371404528617859,\n",
       "  -1.4368233680725098,\n",
       "  -0.7147471308708191,\n",
       "  -0.5795784592628479,\n",
       "  0.4172072410583496,\n",
       "  0.8052682876586914,\n",
       "  0.4731942415237427,\n",
       "  -0.8303520679473877,\n",
       "  0.9867832064628601,\n",
       "  0.5039276480674744,\n",
       "  -0.8633431196212769,\n",
       "  -0.1894151121377945,\n",
       "  -0.3201891779899597,\n",
       "  -0.3723387122154236,\n",
       "  -0.36844488978385925,\n",
       "  0.44518694281578064,\n",
       "  -0.4115259349346161,\n",
       "  0.15836496651172638,\n",
       "  1.0039143562316895,\n",
       "  -0.6516207456588745,\n",
       "  -1.0226401090621948,\n",
       "  -0.40603330731391907,\n",
       "  -0.01206947211176157,\n",
       "  0.01792364940047264,\n",
       "  0.7848408222198486,\n",
       "  0.9689167141914368,\n",
       "  0.5476568341255188,\n",
       "  -0.1855144500732422,\n",
       "  0.11753524839878082,\n",
       "  -0.15436530113220215,\n",
       "  -0.24178831279277802,\n",
       "  2.259841203689575,\n",
       "  0.19985194504261017,\n",
       "  0.9386550784111023,\n",
       "  2.18548583984375,\n",
       "  -0.14953221380710602,\n",
       "  0.6958175301551819,\n",
       "  -1.2729911804199219,\n",
       "  0.30697405338287354,\n",
       "  -0.193930983543396,\n",
       "  0.23331376910209656,\n",
       "  -0.03428679704666138,\n",
       "  0.01614851877093315,\n",
       "  0.3104041516780853,\n",
       "  1.286163091659546,\n",
       "  -0.3895758390426636,\n",
       "  0.83771151304245,\n",
       "  -0.3576473891735077,\n",
       "  -1.6707720756530762,\n",
       "  -0.6408941745758057,\n",
       "  -0.2049487829208374,\n",
       "  0.18853944540023804,\n",
       "  -2.1170990467071533,\n",
       "  0.4394288659095764,\n",
       "  -1.0021344423294067,\n",
       "  0.16966202855110168,\n",
       "  0.8604320287704468,\n",
       "  -0.22565817832946777,\n",
       "  0.08514931797981262,\n",
       "  -0.6377639770507812,\n",
       "  0.8594900965690613,\n",
       "  -1.0785536766052246,\n",
       "  0.08991825580596924,\n",
       "  -0.09713326394557953,\n",
       "  -1.3326719999313354,\n",
       "  0.967808723449707,\n",
       "  -0.1333334892988205,\n",
       "  -0.6737678050994873,\n",
       "  0.19274969398975372,\n",
       "  0.7614172697067261,\n",
       "  0.20615220069885254,\n",
       "  -1.4896306991577148,\n",
       "  -0.71359783411026,\n",
       "  0.4344363212585449,\n",
       "  0.6863661408424377,\n",
       "  0.20231084525585175,\n",
       "  -1.2087875604629517,\n",
       "  0.4193990230560303,\n",
       "  1.3792412281036377,\n",
       "  -1.7645938396453857,\n",
       "  0.5365091562271118,\n",
       "  -1.2639312744140625,\n",
       "  0.7760234475135803,\n",
       "  -1.4914004802703857,\n",
       "  -0.2638087570667267,\n",
       "  0.21576613187789917,\n",
       "  0.44951435923576355,\n",
       "  -0.15245577692985535,\n",
       "  -1.2970750331878662,\n",
       "  0.5318872332572937,\n",
       "  -0.5387690663337708,\n",
       "  0.12893910706043243,\n",
       "  0.40404486656188965,\n",
       "  -0.051749102771282196,\n",
       "  0.5621098279953003,\n",
       "  0.6083804368972778,\n",
       "  -0.8774632811546326,\n",
       "  -0.7465337514877319,\n",
       "  0.9466308951377869,\n",
       "  -1.08622407913208,\n",
       "  0.5396193861961365,\n",
       "  -0.5406872034072876,\n",
       "  1.3841018676757812,\n",
       "  0.5092250108718872,\n",
       "  0.9283649921417236,\n",
       "  0.44977277517318726,\n",
       "  0.8962411284446716,\n",
       "  0.5589155554771423,\n",
       "  -0.6870251297950745,\n",
       "  -0.023673387244343758,\n",
       "  -0.11839049309492111,\n",
       "  0.34504786133766174,\n",
       "  1.9699097871780396,\n",
       "  -0.4586862027645111,\n",
       "  -1.5847116708755493,\n",
       "  -0.06835588812828064,\n",
       "  -0.6620163917541504,\n",
       "  -0.03149261325597763,\n",
       "  -0.43398013710975647,\n",
       "  0.4114474058151245,\n",
       "  0.17512066662311554,\n",
       "  -0.11331960558891296,\n",
       "  0.511317253112793,\n",
       "  -0.04602227360010147,\n",
       "  -0.4383625388145447,\n",
       "  -0.10859739780426025,\n",
       "  0.055974602699279785,\n",
       "  0.7802956700325012,\n",
       "  -0.0889681801199913,\n",
       "  -0.5351454615592957,\n",
       "  -1.0946017503738403,\n",
       "  -0.08098442852497101,\n",
       "  0.7722717523574829,\n",
       "  -0.36493876576423645,\n",
       "  0.9538620114326477,\n",
       "  0.07157786935567856,\n",
       "  -0.1479487419128418,\n",
       "  1.1641038656234741,\n",
       "  -0.6551645398139954,\n",
       "  -0.5194012522697449,\n",
       "  -0.06912064552307129,\n",
       "  0.8731905817985535,\n",
       "  -0.1965242475271225,\n",
       "  2.0795769691467285,\n",
       "  1.2166450023651123,\n",
       "  -1.0102674961090088,\n",
       "  0.09187540411949158,\n",
       "  -0.021481765434145927,\n",
       "  0.9156087040901184,\n",
       "  2.0349783897399902,\n",
       "  -0.3756314814090729,\n",
       "  -0.49759501218795776,\n",
       "  0.43153679370880127,\n",
       "  0.37931278347969055,\n",
       "  0.4397813379764557,\n",
       "  -0.674240231513977,\n",
       "  -0.7734977602958679,\n",
       "  -0.23315215110778809,\n",
       "  0.7113113403320312,\n",
       "  0.38654395937919617,\n",
       "  -1.0120822191238403,\n",
       "  -0.3582417368888855,\n",
       "  0.11750047653913498,\n",
       "  -0.8749427795410156,\n",
       "  -0.5587165355682373,\n",
       "  1.0913574695587158,\n",
       "  -0.6690704226493835,\n",
       "  -1.6386194229125977,\n",
       "  0.23791511356830597,\n",
       "  -0.2624889314174652,\n",
       "  0.38699811697006226,\n",
       "  0.7405089139938354,\n",
       "  -0.635432779788971,\n",
       "  1.5774918794631958,\n",
       "  0.12916505336761475,\n",
       "  -0.36098721623420715,\n",
       "  0.7645881772041321,\n",
       "  1.4330428838729858,\n",
       "  -0.20483560860157013,\n",
       "  -0.7683521509170532,\n",
       "  -0.39581018686294556,\n",
       "  0.07555300742387772,\n",
       "  0.17629720270633698,\n",
       "  0.9118668437004089,\n",
       "  1.0963935852050781,\n",
       "  -1.8060108423233032,\n",
       "  -0.498945027589798,\n",
       "  1.0067315101623535,\n",
       "  0.23468761146068573,\n",
       "  1.0018543004989624,\n",
       "  0.01584736816585064,\n",
       "  0.8472015857696533,\n",
       "  1.8299436569213867,\n",
       "  -1.8841127157211304,\n",
       "  -0.764342725276947,\n",
       "  -0.164032980799675,\n",
       "  0.692728579044342,\n",
       "  0.9196455478668213,\n",
       "  0.08042579144239426,\n",
       "  1.295418620109558,\n",
       "  -1.79402756690979,\n",
       "  0.35153234004974365,\n",
       "  -0.1380860060453415,\n",
       "  -0.7910464406013489,\n",
       "  0.7868033051490784,\n",
       "  -0.15179964900016785,\n",
       "  0.9656144380569458,\n",
       "  2.0861549377441406,\n",
       "  -0.9226036667823792,\n",
       "  -0.599155604839325,\n",
       "  0.8124890327453613,\n",
       "  -0.4785442054271698,\n",
       "  0.14224743843078613,\n",
       "  0.13202691078186035,\n",
       "  -0.6970706582069397,\n",
       "  -0.020212553441524506,\n",
       "  0.6595953702926636,\n",
       "  1.0526931285858154,\n",
       "  -0.48665323853492737,\n",
       "  -0.23136046528816223,\n",
       "  -0.2310693860054016,\n",
       "  -1.8835288286209106,\n",
       "  0.12542735040187836,\n",
       "  -0.4382186233997345,\n",
       "  0.2903217077255249,\n",
       "  0.11095844954252243,\n",
       "  -0.710777223110199,\n",
       "  -0.44311490654945374,\n",
       "  0.0709930881857872,\n",
       "  1.1366099119186401,\n",
       "  1.0750868320465088,\n",
       "  -0.5545338988304138,\n",
       "  -1.0137399435043335,\n",
       "  0.15129117667675018,\n",
       "  0.6706896424293518,\n",
       "  -0.1338757574558258,\n",
       "  0.6375172138214111,\n",
       "  0.5359623432159424,\n",
       "  0.6387481093406677,\n",
       "  -0.683908224105835,\n",
       "  -0.2922416031360626,\n",
       "  1.030909538269043,\n",
       "  1.291778802871704,\n",
       "  0.27070051431655884,\n",
       "  -0.5610662698745728,\n",
       "  -0.8687320351600647,\n",
       "  -1.1758683919906616,\n",
       "  0.5365082025527954,\n",
       "  -0.28817594051361084,\n",
       "  0.516899585723877,\n",
       "  0.4390659034252167,\n",
       "  0.7485194206237793,\n",
       "  0.7735916376113892,\n",
       "  -0.10585891455411911,\n",
       "  -0.029941581189632416,\n",
       "  0.41855111718177795,\n",
       "  -0.7146964073181152,\n",
       "  0.46557047963142395,\n",
       "  0.5005373954772949,\n",
       "  -0.15002354979515076,\n",
       "  -0.38405925035476685,\n",
       "  0.7798268795013428,\n",
       "  -1.152783751487732,\n",
       "  0.9554247260093689,\n",
       "  0.36886876821517944,\n",
       "  -1.5152106285095215,\n",
       "  -0.12297407537698746,\n",
       "  -0.37248820066452026,\n",
       "  0.22268927097320557,\n",
       "  -0.29103803634643555,\n",
       "  -0.33088940382003784,\n",
       "  -0.7324842810630798,\n",
       "  0.761879563331604,\n",
       "  -0.6425495147705078,\n",
       "  -1.287527322769165,\n",
       "  0.49500417709350586,\n",
       "  -0.08196656405925751,\n",
       "  -0.14865750074386597,\n",
       "  0.25627022981643677,\n",
       "  0.47415027022361755,\n",
       "  0.06812050193548203,\n",
       "  1.0484251976013184,\n",
       "  -0.15370608866214752,\n",
       "  -0.3041733503341675,\n",
       "  -0.5254188776016235,\n",
       "  -0.22700640559196472,\n",
       "  -1.2729905843734741,\n",
       "  -0.39487358927726746,\n",
       "  1.7435797452926636,\n",
       "  -1.8775973320007324,\n",
       "  -1.5174591541290283,\n",
       "  -0.32414013147354126,\n",
       "  0.564760148525238,\n",
       "  -0.9397574067115784,\n",
       "  0.6349375247955322,\n",
       "  0.4245986342430115,\n",
       "  -0.6264091730117798,\n",
       "  -1.024376392364502,\n",
       "  0.8622399568557739,\n",
       "  0.5878339409828186,\n",
       "  0.4637056291103363,\n",
       "  1.218308448791504,\n",
       "  1.1967827081680298,\n",
       "  -0.3720599412918091,\n",
       "  -0.13077981770038605,\n",
       "  0.1632450670003891,\n",
       "  0.2765491008758545,\n",
       "  -0.44544318318367004,\n",
       "  -0.03270062804222107,\n",
       "  -0.4328274130821228,\n",
       "  -0.2701200246810913,\n",
       "  -0.5783190727233887,\n",
       "  0.08751189708709717,\n",
       "  0.012506292201578617,\n",
       "  -0.17794576287269592,\n",
       "  1.6007460355758667,\n",
       "  -1.1985394954681396,\n",
       "  -0.07381536066532135,\n",
       "  0.08239231258630753,\n",
       "  -0.5306231379508972,\n",
       "  -1.1376845836639404,\n",
       "  0.7251242399215698,\n",
       "  -0.6938712000846863,\n",
       "  0.39113232493400574,\n",
       "  -0.60049968957901,\n",
       "  0.43218350410461426,\n",
       "  0.0071375565603375435,\n",
       "  -0.22118711471557617,\n",
       "  -0.19985567033290863,\n",
       "  -0.6006633043289185,\n",
       "  -0.21711070835590363,\n",
       "  -0.649273157119751,\n",
       "  0.3838343620300293,\n",
       "  0.07844150066375732,\n",
       "  -0.3456592261791229,\n",
       "  -0.8504737615585327,\n",
       "  -0.46470871567726135,\n",
       "  -1.443630337715149,\n",
       "  0.1577368527650833,\n",
       "  0.4715119004249573,\n",
       "  1.5583488941192627,\n",
       "  -1.6464840173721313,\n",
       "  -0.38604167103767395,\n",
       "  1.4023919105529785,\n",
       "  -0.10471536964178085,\n",
       "  -0.6159970760345459,\n",
       "  -0.5510141849517822,\n",
       "  -0.7092422246932983,\n",
       "  0.7276144027709961,\n",
       "  -0.028743965551257133,\n",
       "  -0.5465503334999084,\n",
       "  -0.42607906460762024,\n",
       "  0.9778393507003784,\n",
       "  0.05831615626811981,\n",
       "  1.2725892066955566,\n",
       "  0.697324812412262,\n",
       "  -0.2641623616218567,\n",
       "  -0.11817625164985657,\n",
       "  -0.228709414601326,\n",
       "  -1.0863027572631836,\n",
       "  0.9735797643661499,\n",
       "  -0.4161287844181061,\n",
       "  0.952299952507019,\n",
       "  -0.2978381812572479,\n",
       "  -2.057706117630005,\n",
       "  -0.6619875431060791,\n",
       "  0.24264872074127197,\n",
       "  1.1534454822540283,\n",
       "  -0.884783148765564,\n",
       "  0.9762126207351685,\n",
       "  -1.791325569152832,\n",
       "  -1.4984172582626343,\n",
       "  -0.5375934839248657,\n",
       "  -0.629931628704071,\n",
       "  -1.4194767475128174,\n",
       "  -1.1128894090652466,\n",
       "  -0.34243395924568176,\n",
       "  0.870216429233551,\n",
       "  1.259622573852539,\n",
       "  -0.43627235293388367,\n",
       "  -0.14758558571338654,\n",
       "  0.4165596663951874,\n",
       "  0.03894011676311493,\n",
       "  0.005603776313364506,\n",
       "  1.2452969551086426,\n",
       "  0.7019366025924683,\n",
       "  1.1577118635177612,\n",
       "  -0.9477331042289734,\n",
       "  2.2466511726379395,\n",
       "  1.660119891166687,\n",
       "  -0.40706372261047363,\n",
       "  0.3939093053340912,\n",
       "  1.3679784536361694,\n",
       "  -1.4615727663040161,\n",
       "  0.6436914801597595,\n",
       "  -1.8641868829727173,\n",
       "  -0.6162028908729553,\n",
       "  -0.9968710541725159,\n",
       "  -0.04276501387357712,\n",
       "  -0.7134620547294617,\n",
       "  -0.07681193947792053,\n",
       "  0.514995813369751,\n",
       "  0.30907827615737915,\n",
       "  -0.4127793610095978,\n",
       "  0.34023505449295044,\n",
       "  -0.5584483742713928,\n",
       "  -1.0774493217468262,\n",
       "  -0.1069253534078598,\n",
       "  0.8219823837280273,\n",
       "  0.5627779364585876,\n",
       "  0.7784462571144104,\n",
       "  -0.02260006032884121,\n",
       "  0.25267401337623596,\n",
       "  0.8264483213424683,\n",
       "  -0.09313119202852249,\n",
       "  1.167733073234558,\n",
       "  0.46359193325042725,\n",
       "  -1.5362520217895508,\n",
       "  0.046547550708055496,\n",
       "  -0.9385424852371216,\n",
       "  -1.165169596672058,\n",
       "  -0.07086627930402756,\n",
       "  -0.41476011276245117,\n",
       "  -1.4201099872589111,\n",
       "  1.059219479560852,\n",
       "  -0.9906155467033386,\n",
       "  -0.40455949306488037,\n",
       "  -0.47995609045028687,\n",
       "  0.02229311130940914,\n",
       "  -1.2449365854263306,\n",
       "  0.9563578963279724,\n",
       "  -0.26429998874664307,\n",
       "  -0.7607954144477844,\n",
       "  -0.5799292325973511,\n",
       "  0.1733117550611496,\n",
       "  -0.07181470096111298,\n",
       "  0.09323462843894958,\n",
       "  1.5738991498947144,\n",
       "  0.24332286417484283,\n",
       "  0.9944661855697632,\n",
       "  0.40117383003234863,\n",
       "  0.5818399786949158,\n",
       "  -0.7213674187660217,\n",
       "  -1.4949895143508911,\n",
       "  -0.003305322490632534,\n",
       "  -0.07167787104845047,\n",
       "  -0.8126658201217651,\n",
       "  -0.3715140223503113,\n",
       "  0.17947782576084137,\n",
       "  1.6125702857971191,\n",
       "  0.02338242158293724,\n",
       "  0.21330079436302185,\n",
       "  0.6061869859695435,\n",
       "  0.5184757709503174,\n",
       "  -0.573918342590332,\n",
       "  0.3538607656955719,\n",
       "  -0.40031662583351135,\n",
       "  0.532241940498352,\n",
       "  0.4983147978782654,\n",
       "  -0.0490444041788578,\n",
       "  -1.5972028970718384,\n",
       "  -0.44662272930145264,\n",
       "  -0.01762719638645649,\n",
       "  -0.38371098041534424,\n",
       "  0.7917308211326599,\n",
       "  -0.3001037836074829,\n",
       "  1.4227688312530518,\n",
       "  0.23816856741905212,\n",
       "  -0.037762511521577835,\n",
       "  0.7501430511474609,\n",
       "  -1.3761910200119019,\n",
       "  0.5356625914573669,\n",
       "  -0.0021052968222647905,\n",
       "  0.20223841071128845,\n",
       "  -0.7869229912757874,\n",
       "  -0.06099448353052139,\n",
       "  -0.40970727801322937,\n",
       "  -0.2703251242637634,\n",
       "  -0.6483051180839539,\n",
       "  0.04393310844898224,\n",
       "  0.13650880753993988,\n",
       "  -0.021647984161973,\n",
       "  -0.4388214945793152,\n",
       "  -0.6657382845878601,\n",
       "  -0.4338303506374359,\n",
       "  -0.202556774020195,\n",
       "  0.5768231153488159,\n",
       "  0.19250573217868805,\n",
       "  -0.12024237215518951,\n",
       "  0.10487272590398788,\n",
       "  -1.0335361957550049,\n",
       "  -0.3242493271827698,\n",
       "  -0.44424834847450256,\n",
       "  0.06914693117141724,\n",
       "  -0.8314264416694641,\n",
       "  2.3469016551971436,\n",
       "  0.4294325113296509,\n",
       "  0.13899381458759308,\n",
       "  0.903292179107666,\n",
       "  -0.2651185095310211,\n",
       "  1.4734960794448853,\n",
       "  -0.8999943137168884,\n",
       "  -1.0070809125900269,\n",
       "  -1.0136793851852417,\n",
       "  -1.133154034614563,\n",
       "  -0.012828817591071129],\n",
       " [0.5105383396148682,\n",
       "  1.3752578496932983,\n",
       "  -3.4325971603393555,\n",
       "  -0.9706447124481201,\n",
       "  0.20265847444534302,\n",
       "  0.2716697156429291,\n",
       "  1.3474847078323364,\n",
       "  0.105655737221241,\n",
       "  -1.6053335666656494,\n",
       "  -0.23773923516273499,\n",
       "  -0.08341661840677261,\n",
       "  1.4840657711029053,\n",
       "  0.7200313210487366,\n",
       "  1.0463334321975708,\n",
       "  -0.120165154337883,\n",
       "  0.32194799184799194,\n",
       "  0.2506813704967499,\n",
       "  -0.5380688309669495,\n",
       "  0.3000168204307556,\n",
       "  0.9482163190841675,\n",
       "  0.5724181532859802,\n",
       "  -0.980958878993988,\n",
       "  -1.5783207416534424,\n",
       "  0.23625345528125763,\n",
       "  2.8679604530334473,\n",
       "  1.0325438976287842,\n",
       "  0.095655158162117,\n",
       "  -0.055943965911865234,\n",
       "  -1.0645948648452759,\n",
       "  -0.23465658724308014,\n",
       "  1.4131418466567993,\n",
       "  -0.5669636130332947,\n",
       "  0.02757437713444233,\n",
       "  -0.7055858373641968,\n",
       "  -2.3620269298553467,\n",
       "  -1.8770084381103516,\n",
       "  0.2921012341976166,\n",
       "  0.30524951219558716,\n",
       "  -0.3221437633037567,\n",
       "  1.0418344736099243,\n",
       "  0.8847312331199646,\n",
       "  -0.47599589824676514,\n",
       "  -0.2857835292816162,\n",
       "  -0.7452163696289062,\n",
       "  1.0341132879257202,\n",
       "  0.8260596990585327,\n",
       "  -0.2797149419784546,\n",
       "  -1.5384716987609863,\n",
       "  0.7368186116218567,\n",
       "  -0.7000340819358826,\n",
       "  0.9312517642974854,\n",
       "  -0.8056110739707947,\n",
       "  0.2110673487186432,\n",
       "  -1.1237070560455322,\n",
       "  0.9507207274436951,\n",
       "  1.1569864749908447,\n",
       "  0.06596999615430832,\n",
       "  0.5475965738296509,\n",
       "  -0.10062865912914276,\n",
       "  -0.3366190791130066,\n",
       "  2.4942402839660645,\n",
       "  1.8479527235031128,\n",
       "  0.0007562027312815189,\n",
       "  1.569445252418518,\n",
       "  1.667184829711914,\n",
       "  -0.7836428284645081,\n",
       "  0.5820566415786743,\n",
       "  1.9224601984024048,\n",
       "  -0.8703009486198425,\n",
       "  0.21173757314682007,\n",
       "  1.1933767795562744,\n",
       "  -0.360479474067688,\n",
       "  0.923413097858429,\n",
       "  -0.9237878918647766,\n",
       "  -0.06144382804632187,\n",
       "  -1.2400561571121216,\n",
       "  -1.3230886459350586,\n",
       "  -0.8920378088951111,\n",
       "  0.37436044216156006,\n",
       "  1.3220747709274292,\n",
       "  -0.06744566559791565,\n",
       "  0.3499799370765686,\n",
       "  1.8132925033569336,\n",
       "  -0.2317245602607727,\n",
       "  0.9242118000984192,\n",
       "  0.4730722904205322,\n",
       "  -0.5889033079147339,\n",
       "  -0.8392823338508606,\n",
       "  -0.25900915265083313,\n",
       "  0.52247154712677,\n",
       "  -0.7855512499809265,\n",
       "  0.815535843372345,\n",
       "  0.8428214192390442,\n",
       "  0.25005286931991577,\n",
       "  0.5291638374328613,\n",
       "  -0.10575058311223984,\n",
       "  0.7223858833312988,\n",
       "  0.4118056893348694,\n",
       "  -0.6912664771080017,\n",
       "  -1.760960340499878,\n",
       "  0.05274350196123123,\n",
       "  -0.5674536228179932,\n",
       "  0.4177868366241455,\n",
       "  -0.34234124422073364,\n",
       "  1.0222541093826294,\n",
       "  1.4773856401443481,\n",
       "  -0.26911085844039917,\n",
       "  -0.13480757176876068,\n",
       "  -1.1944340467453003,\n",
       "  0.20700548589229584,\n",
       "  0.1703098565340042,\n",
       "  0.31255295872688293,\n",
       "  0.04685431718826294,\n",
       "  -1.2844570875167847,\n",
       "  0.632432758808136,\n",
       "  0.4150158166885376,\n",
       "  1.8856996297836304,\n",
       "  -0.7652059197425842,\n",
       "  0.5898734331130981,\n",
       "  0.9407964944839478,\n",
       "  -1.343901515007019,\n",
       "  -0.2077295035123825,\n",
       "  -0.23904556035995483,\n",
       "  1.005678415298462,\n",
       "  1.2386821508407593,\n",
       "  1.0789425373077393,\n",
       "  -1.77426278591156,\n",
       "  0.06655429303646088,\n",
       "  -0.030048495158553123,\n",
       "  0.2197807878255844,\n",
       "  0.5540170669555664,\n",
       "  -0.6983027458190918,\n",
       "  -0.8517918586730957,\n",
       "  0.6088617444038391,\n",
       "  0.21817277371883392,\n",
       "  0.24247197806835175,\n",
       "  -0.2609819769859314,\n",
       "  -0.9275295734405518,\n",
       "  0.21757984161376953,\n",
       "  0.7087240219116211,\n",
       "  0.33827459812164307,\n",
       "  -0.5474690198898315,\n",
       "  -0.1993597000837326,\n",
       "  -0.736987829208374,\n",
       "  0.11470243334770203,\n",
       "  -0.6014731526374817,\n",
       "  1.3925716876983643,\n",
       "  -0.06587452441453934,\n",
       "  0.08224278688430786,\n",
       "  -0.7970892190933228,\n",
       "  -1.0481562614440918,\n",
       "  1.110256314277649,\n",
       "  -0.07954417914152145,\n",
       "  0.7959055304527283,\n",
       "  0.6804941296577454,\n",
       "  -0.6457386612892151,\n",
       "  0.5740222334861755,\n",
       "  -0.05808142200112343,\n",
       "  -0.2444533109664917,\n",
       "  1.3289567232131958,\n",
       "  1.3839974403381348,\n",
       "  -0.3031793236732483,\n",
       "  -0.8491060733795166,\n",
       "  1.4640796184539795,\n",
       "  -1.153325080871582,\n",
       "  -1.289239764213562,\n",
       "  0.34624969959259033,\n",
       "  0.7205833792686462,\n",
       "  1.0738211870193481,\n",
       "  0.8190290331840515,\n",
       "  -0.4932197034358978,\n",
       "  -1.1906378269195557,\n",
       "  -1.258433222770691,\n",
       "  -0.28764021396636963,\n",
       "  -0.3272245228290558,\n",
       "  -0.3150402903556824,\n",
       "  0.2528265416622162,\n",
       "  -1.019771933555603,\n",
       "  0.8182318210601807,\n",
       "  -0.9380451440811157,\n",
       "  -0.12288229167461395,\n",
       "  -0.36804211139678955,\n",
       "  0.943307638168335,\n",
       "  1.057314395904541,\n",
       "  -0.5493959188461304,\n",
       "  -0.8294624090194702,\n",
       "  -0.6379357576370239,\n",
       "  0.5208480358123779,\n",
       "  -0.5480058193206787,\n",
       "  -0.0718972235918045,\n",
       "  -1.6087814569473267,\n",
       "  0.9019330739974976,\n",
       "  -1.0996127128601074,\n",
       "  -1.0178844928741455,\n",
       "  -1.0841648578643799,\n",
       "  -0.6143607497215271,\n",
       "  1.061528205871582,\n",
       "  -0.3521832823753357,\n",
       "  0.39535582065582275,\n",
       "  -1.007751226425171,\n",
       "  -0.6979573965072632,\n",
       "  -0.2412874549627304,\n",
       "  -1.4521043300628662,\n",
       "  0.010311547666788101,\n",
       "  -0.9802883267402649,\n",
       "  0.27446767687797546,\n",
       "  -0.4715355634689331,\n",
       "  0.542241096496582,\n",
       "  -0.6942560076713562,\n",
       "  0.994605302810669,\n",
       "  1.4983552694320679,\n",
       "  0.7487748861312866,\n",
       "  -0.5195649266242981,\n",
       "  -0.18887700140476227,\n",
       "  0.4504780173301697,\n",
       "  -1.6578189134597778,\n",
       "  -0.34528428316116333,\n",
       "  -1.1471080780029297,\n",
       "  -0.7562881112098694,\n",
       "  0.6138152480125427,\n",
       "  1.184726595878601,\n",
       "  -1.0132306814193726,\n",
       "  1.1633732318878174,\n",
       "  -0.47162413597106934,\n",
       "  -0.13950346410274506,\n",
       "  0.15485148131847382,\n",
       "  -0.8169605731964111,\n",
       "  -0.3597128093242645,\n",
       "  -1.5556203126907349,\n",
       "  0.3007020652294159,\n",
       "  -1.0756961107254028,\n",
       "  -1.322450041770935,\n",
       "  0.323982834815979,\n",
       "  1.0963082313537598,\n",
       "  -0.35114845633506775,\n",
       "  0.050451721996068954,\n",
       "  -0.0441659651696682,\n",
       "  0.709748387336731,\n",
       "  0.7110635042190552,\n",
       "  1.1355994939804077,\n",
       "  0.38361185789108276,\n",
       "  1.29017972946167,\n",
       "  -0.9552237391471863,\n",
       "  -0.9939910173416138,\n",
       "  -1.375942349433899,\n",
       "  0.45295506715774536,\n",
       "  0.08102114498615265,\n",
       "  -0.14522339403629303,\n",
       "  0.22651921212673187,\n",
       "  0.9243015646934509,\n",
       "  0.4322635531425476,\n",
       "  -0.9581992030143738,\n",
       "  0.2974911630153656,\n",
       "  0.7230510711669922,\n",
       "  0.23094229400157928,\n",
       "  -1.4027621746063232,\n",
       "  0.23746822774410248,\n",
       "  -0.5421631336212158,\n",
       "  -0.07541979104280472,\n",
       "  0.1414325088262558,\n",
       "  0.5248588919639587,\n",
       "  -1.4658970832824707,\n",
       "  0.397582083940506,\n",
       "  -0.371489942073822,\n",
       "  0.5732792019844055,\n",
       "  -0.13220781087875366,\n",
       "  0.3351260721683502,\n",
       "  -0.201833114027977,\n",
       "  0.5790624022483826,\n",
       "  0.3238201439380646,\n",
       "  0.2536458373069763,\n",
       "  0.4355979263782501,\n",
       "  0.23462674021720886,\n",
       "  1.1598013639450073,\n",
       "  0.4570460319519043,\n",
       "  -1.3660873174667358,\n",
       "  0.5169962644577026,\n",
       "  0.5268750786781311,\n",
       "  -0.059140659868717194,\n",
       "  0.7699823379516602,\n",
       "  -0.6696375608444214,\n",
       "  -1.4187936782836914,\n",
       "  -0.8315146565437317,\n",
       "  -0.8095812797546387,\n",
       "  0.33367305994033813,\n",
       "  0.1399475783109665,\n",
       "  1.0451428890228271,\n",
       "  0.8663779497146606,\n",
       "  0.22940537333488464,\n",
       "  -0.1418641060590744,\n",
       "  0.6536663174629211,\n",
       "  -0.5696428418159485,\n",
       "  -0.7686097025871277,\n",
       "  0.7804906964302063,\n",
       "  0.6360096335411072,\n",
       "  0.5716860890388489,\n",
       "  1.6231293678283691,\n",
       "  -0.24943439662456512,\n",
       "  0.7336416840553284,\n",
       "  -0.8300354480743408,\n",
       "  0.34683266282081604,\n",
       "  0.6156578660011292,\n",
       "  0.6090651750564575,\n",
       "  0.7539504170417786,\n",
       "  -1.275510549545288,\n",
       "  -0.530902624130249,\n",
       "  -0.22931325435638428,\n",
       "  -0.7812637686729431,\n",
       "  0.15026523172855377,\n",
       "  -0.9969882965087891,\n",
       "  -1.057904601097107,\n",
       "  -0.9402199983596802,\n",
       "  0.6914350390434265,\n",
       "  -0.2088802009820938,\n",
       "  -0.780604898929596,\n",
       "  1.1145066022872925,\n",
       "  -0.8014050126075745,\n",
       "  0.7336364984512329,\n",
       "  0.07940641790628433,\n",
       "  0.48220714926719666,\n",
       "  -0.8919311165809631,\n",
       "  -1.0506272315979004,\n",
       "  0.24821944534778595,\n",
       "  -1.0017677545547485,\n",
       "  -0.24118493497371674,\n",
       "  0.3425118029117584,\n",
       "  -0.75948566198349,\n",
       "  1.0297622680664062,\n",
       "  0.1340649127960205,\n",
       "  -0.6944918036460876,\n",
       "  -0.040665797889232635,\n",
       "  0.4330246150493622,\n",
       "  -0.029062118381261826,\n",
       "  -0.624273955821991,\n",
       "  -0.4500344395637512,\n",
       "  0.047052618116140366,\n",
       "  0.01882600039243698,\n",
       "  0.1043626219034195,\n",
       "  0.1752823442220688,\n",
       "  -0.054525986313819885,\n",
       "  2.2622246742248535,\n",
       "  0.04744524508714676,\n",
       "  -0.18797667324543,\n",
       "  -0.5633718371391296,\n",
       "  1.1197686195373535,\n",
       "  -0.6477279663085938,\n",
       "  -0.8826648592948914,\n",
       "  0.042047251015901566,\n",
       "  0.6393876075744629,\n",
       "  0.36359304189682007,\n",
       "  -1.0983870029449463,\n",
       "  -0.6742797493934631,\n",
       "  -0.8037424087524414,\n",
       "  0.23993822932243347,\n",
       "  0.23927466571331024,\n",
       "  0.3885505497455597,\n",
       "  -0.053299058228731155,\n",
       "  0.7902604341506958,\n",
       "  0.44734424352645874,\n",
       "  0.2579583525657654,\n",
       "  0.8831261396408081,\n",
       "  -1.0845633745193481,\n",
       "  0.8166059255599976,\n",
       "  -0.42180705070495605,\n",
       "  -0.2897551953792572,\n",
       "  0.965914785861969,\n",
       "  0.7611865401268005,\n",
       "  0.9066900610923767,\n",
       "  0.2672029733657837,\n",
       "  0.024074522778391838,\n",
       "  -0.6971426606178284,\n",
       "  -0.6486845016479492,\n",
       "  0.42620834708213806,\n",
       "  0.3055298924446106,\n",
       "  0.9792828559875488,\n",
       "  -0.8025882244110107,\n",
       "  -0.938288152217865,\n",
       "  -1.6935019493103027,\n",
       "  0.5280264616012573,\n",
       "  0.4571952521800995,\n",
       "  -0.5717823505401611,\n",
       "  -0.8182039856910706,\n",
       "  0.19403916597366333,\n",
       "  0.07934687286615372,\n",
       "  1.2557952404022217,\n",
       "  -1.2252789735794067,\n",
       "  -1.0671080350875854,\n",
       "  -0.03752921149134636,\n",
       "  0.060225438326597214,\n",
       "  0.9673741459846497,\n",
       "  -0.36353930830955505,\n",
       "  -0.8648173809051514,\n",
       "  -1.1527761220932007,\n",
       "  0.47831785678863525,\n",
       "  -0.10459922254085541,\n",
       "  -0.19914446771144867,\n",
       "  -0.35371077060699463,\n",
       "  0.1262010633945465,\n",
       "  0.2928689122200012,\n",
       "  0.3232802152633667,\n",
       "  -0.6260697841644287,\n",
       "  -0.6448107361793518,\n",
       "  0.3625977635383606,\n",
       "  0.1863585263490677,\n",
       "  0.6230900883674622,\n",
       "  1.7531439065933228,\n",
       "  0.9096660614013672,\n",
       "  -1.2196263074874878,\n",
       "  0.9330182671546936,\n",
       "  0.3972351551055908,\n",
       "  0.13418540358543396,\n",
       "  0.6319370269775391,\n",
       "  0.0799451395869255,\n",
       "  -1.440878987312317,\n",
       "  0.16352704167366028,\n",
       "  0.8257232308387756,\n",
       "  0.7048187255859375,\n",
       "  0.8115642070770264,\n",
       "  0.0841231718659401,\n",
       "  -0.06572892516851425,\n",
       "  0.6860679388046265,\n",
       "  0.553753137588501,\n",
       "  -0.712915301322937,\n",
       "  0.13474838435649872,\n",
       "  -0.26625481247901917,\n",
       "  0.007566304411739111,\n",
       "  -0.18723760545253754,\n",
       "  1.0350953340530396,\n",
       "  -1.0257760286331177,\n",
       "  -1.3860702514648438,\n",
       "  -0.603937029838562,\n",
       "  0.6993285417556763,\n",
       "  1.177722454071045,\n",
       "  1.270344614982605,\n",
       "  -0.23152491450309753,\n",
       "  0.9938835501670837,\n",
       "  0.5015689730644226,\n",
       "  0.23452778160572052,\n",
       "  0.5799625515937805,\n",
       "  1.6793999671936035,\n",
       "  0.31877216696739197,\n",
       "  -0.8305190801620483,\n",
       "  -0.831412672996521,\n",
       "  -0.9349801540374756,\n",
       "  0.39428403973579407,\n",
       "  2.8933749198913574,\n",
       "  1.324001431465149,\n",
       "  -1.7861416339874268,\n",
       "  -1.026829719543457,\n",
       "  1.079353928565979,\n",
       "  -0.04919658601284027,\n",
       "  1.410830020904541,\n",
       "  0.07751991599798203,\n",
       "  1.3816808462142944,\n",
       "  1.2535537481307983,\n",
       "  -1.5157253742218018,\n",
       "  -0.7934852242469788,\n",
       "  0.30355677008628845,\n",
       "  1.0753815174102783,\n",
       "  0.5518547892570496,\n",
       "  -0.7859189510345459,\n",
       "  0.7349361181259155,\n",
       "  -1.6338183879852295,\n",
       "  0.7379584908485413,\n",
       "  -0.11898685246706009,\n",
       "  0.03769523277878761,\n",
       "  0.8064020872116089,\n",
       "  -0.07518372684717178,\n",
       "  0.5859365463256836,\n",
       "  1.9285017251968384,\n",
       "  0.3731980621814728,\n",
       "  0.7879129648208618,\n",
       "  0.5157390832901001,\n",
       "  -1.0209343433380127,\n",
       "  0.26330995559692383,\n",
       "  0.953271746635437,\n",
       "  -0.6465689539909363,\n",
       "  -0.46198758482933044,\n",
       "  -0.46764662861824036,\n",
       "  1.792670488357544,\n",
       "  -0.49066486954689026,\n",
       "  0.053708478808403015,\n",
       "  -0.32817989587783813,\n",
       "  -0.9962676763534546,\n",
       "  0.18072116374969482,\n",
       "  0.10949093103408813,\n",
       "  0.03956383094191551,\n",
       "  0.5451825261116028,\n",
       "  -0.6183737516403198,\n",
       "  0.3442608714103699,\n",
       "  0.2599838972091675,\n",
       "  0.6913420557975769,\n",
       "  -0.1277487576007843,\n",
       "  -0.035123180598020554,\n",
       "  -0.42372843623161316,\n",
       "  -0.03661995753645897,\n",
       "  -0.1696135401725769,\n",
       "  0.528337836265564,\n",
       "  0.9876734614372253,\n",
       "  0.9041765332221985,\n",
       "  0.6680241823196411,\n",
       "  0.28612658381462097,\n",
       "  0.11149592697620392,\n",
       "  0.42997685074806213,\n",
       "  0.740227460861206,\n",
       "  -0.4810728430747986,\n",
       "  -0.29047536849975586,\n",
       "  -1.1261197328567505,\n",
       "  -1.7617712020874023,\n",
       "  0.31144917011260986,\n",
       "  -0.6385918259620667,\n",
       "  0.708411455154419,\n",
       "  0.14691506326198578,\n",
       "  1.895387887954712,\n",
       "  1.0292973518371582,\n",
       "  -0.41808992624282837,\n",
       "  0.29942962527275085,\n",
       "  0.5970648527145386,\n",
       "  -1.01493501663208,\n",
       "  0.2908271551132202,\n",
       "  0.61263108253479,\n",
       "  -0.3097953200340271,\n",
       "  -0.4846242368221283,\n",
       "  0.642512857913971,\n",
       "  -2.020505428314209,\n",
       "  0.42053285241127014,\n",
       "  0.6467677354812622,\n",
       "  -1.37385094165802,\n",
       "  0.9104928970336914,\n",
       "  -0.018616752699017525,\n",
       "  0.9519191384315491,\n",
       "  1.183582067489624,\n",
       "  -1.6832026243209839,\n",
       "  -0.5913077592849731,\n",
       "  -0.006123492028564215,\n",
       "  -1.093716025352478,\n",
       "  -1.6326457262039185,\n",
       "  -0.32543113827705383,\n",
       "  0.713843047618866,\n",
       "  0.8056944012641907,\n",
       "  -0.5928955674171448,\n",
       "  0.10912376642227173,\n",
       "  0.11075103282928467,\n",
       "  1.1367216110229492,\n",
       "  0.24446798861026764,\n",
       "  0.12860757112503052,\n",
       "  -0.3868533670902252,\n",
       "  0.6841300129890442,\n",
       "  -0.951410710811615,\n",
       "  -1.2617955207824707,\n",
       "  1.0442109107971191,\n",
       "  -1.5775558948516846,\n",
       "  -0.4952632784843445,\n",
       "  0.33766016364097595,\n",
       "  0.4561936557292938,\n",
       "  -1.1328855752944946,\n",
       "  1.0946844816207886,\n",
       "  0.11700106412172318,\n",
       "  -0.2207847386598587,\n",
       "  -0.3927450180053711,\n",
       "  0.32321470975875854,\n",
       "  0.15673285722732544,\n",
       "  1.146580457687378,\n",
       "  0.3632136285305023,\n",
       "  0.04811866208910942,\n",
       "  -1.339094638824463,\n",
       "  0.5401177406311035,\n",
       "  -0.2546174228191376,\n",
       "  -0.023073414340615273,\n",
       "  0.07961009442806244,\n",
       "  0.11733628809452057,\n",
       "  -1.0993282794952393,\n",
       "  -0.3324454128742218,\n",
       "  -0.26716148853302,\n",
       "  -0.16657771170139313,\n",
       "  -0.03687119111418724,\n",
       "  0.18457794189453125,\n",
       "  -0.47877243161201477,\n",
       "  -1.684828758239746,\n",
       "  -1.1267427206039429,\n",
       "  -0.9159397482872009,\n",
       "  -1.3064916133880615,\n",
       "  0.5078231692314148,\n",
       "  0.4047040641307831,\n",
       "  0.565837025642395,\n",
       "  0.16619296371936798,\n",
       "  -1.3764861822128296,\n",
       "  1.0799742937088013,\n",
       "  0.5579820871353149,\n",
       "  -0.7912842631340027,\n",
       "  -0.8388918042182922,\n",
       "  -0.2647817134857178,\n",
       "  0.07263641059398651,\n",
       "  -0.6646730303764343,\n",
       "  -0.38262301683425903,\n",
       "  0.7929781079292297,\n",
       "  -0.47460901737213135,\n",
       "  -0.8722904324531555,\n",
       "  -0.2940467298030853,\n",
       "  -0.5423420071601868,\n",
       "  -0.47799453139305115,\n",
       "  1.1892402172088623,\n",
       "  1.1802091598510742,\n",
       "  -1.170440673828125,\n",
       "  -0.15704703330993652,\n",
       "  0.6390060186386108,\n",
       "  -0.3848024606704712,\n",
       "  -0.7241174578666687,\n",
       "  -0.001561766373924911,\n",
       "  -2.108603000640869,\n",
       "  0.9104975461959839,\n",
       "  0.16243396699428558,\n",
       "  1.0736079216003418,\n",
       "  -0.17357483506202698,\n",
       "  1.474103331565857,\n",
       "  -0.175553098320961,\n",
       "  0.9922734498977661,\n",
       "  -1.3593618869781494,\n",
       "  0.14902515709400177,\n",
       "  -0.4360128939151764,\n",
       "  0.09112803637981415,\n",
       "  -1.296221375465393,\n",
       "  1.156523585319519,\n",
       "  -1.525037407875061,\n",
       "  1.4963622093200684,\n",
       "  0.06459368765354156,\n",
       "  -0.8474940657615662,\n",
       "  0.6019827723503113,\n",
       "  1.3181239366531372,\n",
       "  1.7506341934204102,\n",
       "  -0.7677643895149231,\n",
       "  0.4444141685962677,\n",
       "  -1.3343803882598877,\n",
       "  -1.1754851341247559,\n",
       "  0.31944987177848816,\n",
       "  0.040527425706386566,\n",
       "  -0.8638177514076233,\n",
       "  -0.8372789621353149,\n",
       "  0.07137223333120346,\n",
       "  0.9614095687866211,\n",
       "  0.8604186773300171,\n",
       "  -1.1623353958129883,\n",
       "  -0.17892126739025116,\n",
       "  -0.865800678730011,\n",
       "  0.6124404668807983,\n",
       "  -0.8991873860359192,\n",
       "  1.191772699356079,\n",
       "  -0.20832517743110657,\n",
       "  0.7804754376411438,\n",
       "  -1.0129270553588867,\n",
       "  1.3300341367721558,\n",
       "  1.723989486694336,\n",
       "  0.08179830759763718,\n",
       "  0.143788143992424,\n",
       "  0.4266550540924072,\n",
       "  -0.8053454756736755,\n",
       "  -0.029291760176420212,\n",
       "  -1.0100302696228027,\n",
       "  -0.3124352991580963,\n",
       "  -1.523851990699768,\n",
       "  -0.011754389852285385,\n",
       "  -0.21915355324745178,\n",
       "  -0.08201263844966888,\n",
       "  -0.44619104266166687,\n",
       "  0.36717742681503296,\n",
       "  -0.32752296328544617,\n",
       "  -0.5600002408027649,\n",
       "  0.03970307484269142,\n",
       "  -1.1271361112594604,\n",
       "  -0.6023520827293396,\n",
       "  0.09520751237869263,\n",
       "  0.8126767873764038,\n",
       "  0.9142878651618958,\n",
       "  0.556162416934967,\n",
       "  0.14630256593227386,\n",
       "  1.4312222003936768,\n",
       "  0.032918643206357956,\n",
       "  0.26762232184410095,\n",
       "  -1.4532042741775513,\n",
       "  -1.2839667797088623,\n",
       "  -0.39127373695373535,\n",
       "  -1.1245040893554688,\n",
       "  0.2889409363269806,\n",
       "  0.2447788119316101,\n",
       "  0.8118202090263367,\n",
       "  -1.1502763032913208,\n",
       "  0.48408418893814087,\n",
       "  -0.4369272291660309,\n",
       "  -0.11372774839401245,\n",
       "  -0.41540271043777466,\n",
       "  0.5843859314918518,\n",
       "  -1.8056761026382446,\n",
       "  0.48003143072128296,\n",
       "  -0.9617745280265808,\n",
       "  -0.48083189129829407,\n",
       "  0.343551903963089,\n",
       "  -0.8885239958763123,\n",
       "  -0.40986111760139465,\n",
       "  -0.42085835337638855,\n",
       "  1.7480107545852661,\n",
       "  -0.18396858870983124,\n",
       "  0.9788273572921753,\n",
       "  0.4638931453227997,\n",
       "  1.5235174894332886,\n",
       "  -1.2375093698501587,\n",
       "  -0.09855412691831589,\n",
       "  -0.7911772727966309,\n",
       "  0.15712566673755646,\n",
       "  -0.20668435096740723,\n",
       "  0.18101179599761963,\n",
       "  -0.05379021167755127,\n",
       "  -0.07731148600578308,\n",
       "  0.1966310441493988,\n",
       "  0.5256878137588501,\n",
       "  0.8005873560905457,\n",
       "  0.6637232899665833,\n",
       "  0.052750322967767715,\n",
       "  -1.204704999923706,\n",
       "  -0.8993051052093506,\n",
       "  0.5511264204978943,\n",
       "  1.4366930723190308,\n",
       "  -0.3107830584049225,\n",
       "  -1.3447322845458984,\n",
       "  -0.5564500689506531,\n",
       "  0.1945781707763672,\n",
       "  -0.7203722596168518,\n",
       "  1.055024266242981,\n",
       "  -0.35584428906440735,\n",
       "  1.5851185321807861,\n",
       "  0.257184773683548,\n",
       "  0.1985032856464386,\n",
       "  -0.5680220723152161,\n",
       "  -0.8303921222686768,\n",
       "  1.1436575651168823,\n",
       "  -0.9057115316390991,\n",
       "  0.10073085874319077,\n",
       "  -2.236480474472046,\n",
       "  -0.20200996100902557,\n",
       "  -0.6722332239151001,\n",
       "  -1.0566513538360596,\n",
       "  -0.6468158960342407,\n",
       "  -0.385358065366745,\n",
       "  0.016542350873351097,\n",
       "  0.31220704317092896,\n",
       "  -0.02423389069736004,\n",
       "  -0.46573227643966675,\n",
       "  -1.1841611862182617,\n",
       "  -0.7922247052192688,\n",
       "  1.0637390613555908,\n",
       "  -0.701212465763092,\n",
       "  0.9605400562286377,\n",
       "  -1.1456300020217896,\n",
       "  -1.2353969812393188,\n",
       "  -0.3396967947483063,\n",
       "  0.6558908820152283,\n",
       "  0.7282720804214478,\n",
       "  0.07206319272518158,\n",
       "  0.9552679657936096,\n",
       "  1.3208866119384766,\n",
       "  0.5782951712608337,\n",
       "  0.11812737584114075,\n",
       "  -0.30912137031555176,\n",
       "  1.5846385955810547,\n",
       "  0.3823232650756836,\n",
       "  -0.1514091193675995,\n",
       "  -0.44077473878860474,\n",
       "  -0.4786544144153595,\n",
       "  0.12495912611484528],\n",
       " [0.35475778579711914,\n",
       "  0.5637201070785522,\n",
       "  -3.884230613708496,\n",
       "  -1.5681341886520386,\n",
       "  0.9161431789398193,\n",
       "  0.8284855484962463,\n",
       "  -0.504990816116333,\n",
       "  0.7257483005523682,\n",
       "  -1.5883064270019531,\n",
       "  -0.8939196467399597,\n",
       "  -0.24560242891311646,\n",
       "  1.4676017761230469,\n",
       "  1.3233314752578735,\n",
       "  -0.10629329830408096,\n",
       "  0.6328519582748413,\n",
       "  -0.731476366519928,\n",
       "  1.714982271194458,\n",
       "  -1.6759790182113647,\n",
       "  1.2137724161148071,\n",
       "  0.4280719459056854,\n",
       "  -0.16919776797294617,\n",
       "  1.6997325420379639,\n",
       "  1.0390863418579102,\n",
       "  1.0083261728286743,\n",
       "  3.8077943325042725,\n",
       "  0.822836697101593,\n",
       "  -0.09407301992177963,\n",
       "  1.0032564401626587,\n",
       "  -0.7315153479576111,\n",
       "  0.6447138786315918,\n",
       "  0.030183909460902214,\n",
       "  0.01241248194128275,\n",
       "  -0.4994271993637085,\n",
       "  0.13136738538742065,\n",
       "  -0.9757622480392456,\n",
       "  -0.5265620946884155,\n",
       "  1.5599077939987183,\n",
       "  0.9166251420974731,\n",
       "  0.5691351294517517,\n",
       "  0.11167466640472412,\n",
       "  1.0870541334152222,\n",
       "  0.038880351930856705,\n",
       "  -0.02012820728123188,\n",
       "  -0.06421591341495514,\n",
       "  0.6138461232185364,\n",
       "  -0.629375159740448,\n",
       "  1.3110637664794922,\n",
       "  -0.9088719487190247,\n",
       "  0.34282588958740234,\n",
       "  -0.16520704329013824,\n",
       "  0.6847936511039734,\n",
       "  0.3732105791568756,\n",
       "  0.11088565737009048,\n",
       "  -0.8490850329399109,\n",
       "  1.5305140018463135,\n",
       "  0.9894859790802002,\n",
       "  1.312988042831421,\n",
       "  -0.88657146692276,\n",
       "  -0.6355196833610535,\n",
       "  -0.09727977961301804,\n",
       "  1.8852474689483643,\n",
       "  1.1402431726455688,\n",
       "  -1.1019542217254639,\n",
       "  0.6416919827461243,\n",
       "  1.5660755634307861,\n",
       "  -1.8427163362503052,\n",
       "  -0.18289285898208618,\n",
       "  1.4156744480133057,\n",
       "  -0.3661561906337738,\n",
       "  0.11576400697231293,\n",
       "  2.3156521320343018,\n",
       "  -0.51253741979599,\n",
       "  0.6060761213302612,\n",
       "  0.007703613955527544,\n",
       "  -0.1002742350101471,\n",
       "  -1.0956554412841797,\n",
       "  -0.44626012444496155,\n",
       "  -0.05463273450732231,\n",
       "  0.3418160080909729,\n",
       "  0.516499400138855,\n",
       "  0.37071940302848816,\n",
       "  0.7810840010643005,\n",
       "  1.3611711263656616,\n",
       "  0.4246062934398651,\n",
       "  1.3607670068740845,\n",
       "  -0.5447375178337097,\n",
       "  -0.41679367423057556,\n",
       "  -0.6547034382820129,\n",
       "  -1.3070192337036133,\n",
       "  0.6389153003692627,\n",
       "  -0.3563247323036194,\n",
       "  0.21331828832626343,\n",
       "  0.6088975667953491,\n",
       "  -0.3251814842224121,\n",
       "  -0.8553903698921204,\n",
       "  -0.1009933352470398,\n",
       "  -1.0274438858032227,\n",
       "  0.39890986680984497,\n",
       "  -0.4231797158718109,\n",
       "  -1.1386818885803223,\n",
       "  -1.3399802446365356,\n",
       "  -0.6245468854904175,\n",
       "  0.38322436809539795,\n",
       "  -0.1127224937081337,\n",
       "  0.704589307308197,\n",
       "  2.1022701263427734,\n",
       "  0.30379340052604675,\n",
       "  0.3891933560371399,\n",
       "  -0.6432387232780457,\n",
       "  -0.40303924679756165,\n",
       "  -1.431648850440979,\n",
       "  0.6674575209617615,\n",
       "  0.42866382002830505,\n",
       "  -0.6255362033843994,\n",
       "  0.3835790455341339,\n",
       "  0.35972848534584045,\n",
       "  1.832118272781372,\n",
       "  -0.15604235231876373,\n",
       "  0.4043363332748413,\n",
       "  1.4126555919647217,\n",
       "  -0.6182058453559875,\n",
       "  -0.0032991773914545774,\n",
       "  0.5551474690437317,\n",
       "  1.4919853210449219,\n",
       "  0.0583329051733017,\n",
       "  0.4396830201148987,\n",
       "  -1.008970022201538,\n",
       "  0.415902316570282,\n",
       "  -0.07319806516170502,\n",
       "  0.0961974635720253,\n",
       "  0.0247582346200943,\n",
       "  -0.3273027837276459,\n",
       "  0.09451627731323242,\n",
       "  -0.04064152017235756,\n",
       "  0.5966154336929321,\n",
       "  0.922709047794342,\n",
       "  -0.363610178232193,\n",
       "  -0.852757453918457,\n",
       "  0.3492778241634369,\n",
       "  0.7027414441108704,\n",
       "  0.9627162218093872,\n",
       "  1.0711537599563599,\n",
       "  0.22147080302238464,\n",
       "  -0.08893799781799316,\n",
       "  -0.7065942883491516,\n",
       "  -0.732231080532074,\n",
       "  1.373901605606079,\n",
       "  -1.1888703107833862,\n",
       "  0.0962342694401741,\n",
       "  -0.3025898337364197,\n",
       "  0.08464942872524261,\n",
       "  1.133257269859314,\n",
       "  -0.34410110116004944,\n",
       "  1.591058373451233,\n",
       "  0.9558537602424622,\n",
       "  -0.5263260006904602,\n",
       "  0.8103281259536743,\n",
       "  0.729546844959259,\n",
       "  -0.4813486933708191,\n",
       "  0.8451835513114929,\n",
       "  1.3056648969650269,\n",
       "  -0.18779879808425903,\n",
       "  -0.5603923797607422,\n",
       "  0.5877307653427124,\n",
       "  -0.4113020598888397,\n",
       "  -0.7190792560577393,\n",
       "  0.38639047741889954,\n",
       "  0.8871753811836243,\n",
       "  0.6409270167350769,\n",
       "  1.8559021949768066,\n",
       "  0.1747441589832306,\n",
       "  -1.2450188398361206,\n",
       "  -0.47360530495643616,\n",
       "  0.5195199251174927,\n",
       "  0.03234408050775528,\n",
       "  -0.5516611337661743,\n",
       "  0.60297030210495,\n",
       "  -1.4048539400100708,\n",
       "  -0.821907639503479,\n",
       "  -1.214438557624817,\n",
       "  1.2818832397460938,\n",
       "  -1.144702434539795,\n",
       "  0.6476529240608215,\n",
       "  1.1067017316818237,\n",
       "  -0.171000137925148,\n",
       "  -0.5555739402770996,\n",
       "  0.002193909604102373,\n",
       "  -0.3732447624206543,\n",
       "  -0.48143959045410156,\n",
       "  -1.297765851020813,\n",
       "  -2.227161169052124,\n",
       "  0.9529320001602173,\n",
       "  -0.531606912612915,\n",
       "  -0.7910411357879639,\n",
       "  -1.4011560678482056,\n",
       "  -0.3203166425228119,\n",
       "  0.3118114471435547,\n",
       "  -1.2654143571853638,\n",
       "  -0.1397700309753418,\n",
       "  -1.183782696723938,\n",
       "  0.31335604190826416,\n",
       "  -0.28278017044067383,\n",
       "  -1.9306141138076782,\n",
       "  0.011697264388203621,\n",
       "  -2.1282103061676025,\n",
       "  -0.3950818181037903,\n",
       "  -1.2756409645080566,\n",
       "  0.32816314697265625,\n",
       "  -0.2361757904291153,\n",
       "  0.6146042943000793,\n",
       "  2.0177364349365234,\n",
       "  -0.201043501496315,\n",
       "  -1.3849836587905884,\n",
       "  0.12202106416225433,\n",
       "  -0.3581167459487915,\n",
       "  -0.6859491467475891,\n",
       "  -0.259561151266098,\n",
       "  -0.5716795325279236,\n",
       "  -0.47356486320495605,\n",
       "  0.5052899122238159,\n",
       "  1.0315406322479248,\n",
       "  0.4586515724658966,\n",
       "  -0.1975569725036621,\n",
       "  -1.1970282793045044,\n",
       "  0.7510539889335632,\n",
       "  0.22497661411762238,\n",
       "  -0.016852062195539474,\n",
       "  -0.6446712017059326,\n",
       "  -1.3437645435333252,\n",
       "  0.3544486165046692,\n",
       "  -0.7691466212272644,\n",
       "  -0.5010278224945068,\n",
       "  0.7286182045936584,\n",
       "  -0.1494663655757904,\n",
       "  0.05520922690629959,\n",
       "  0.6941447854042053,\n",
       "  1.7483528852462769,\n",
       "  1.0724835395812988,\n",
       "  -0.29290276765823364,\n",
       "  -0.21684066951274872,\n",
       "  0.7920249700546265,\n",
       "  0.6669213175773621,\n",
       "  -1.1899447441101074,\n",
       "  -0.5696448683738708,\n",
       "  -0.8819370269775391,\n",
       "  1.3322439193725586,\n",
       "  0.4906840920448303,\n",
       "  -0.9804784059524536,\n",
       "  0.8653998374938965,\n",
       "  1.6719017028808594,\n",
       "  -0.4035242199897766,\n",
       "  -0.3594774603843689,\n",
       "  1.6003530025482178,\n",
       "  0.4113948345184326,\n",
       "  0.4510785639286041,\n",
       "  -1.3944603204727173,\n",
       "  -0.2848297953605652,\n",
       "  -0.5843981504440308,\n",
       "  -0.12243182212114334,\n",
       "  0.6923010945320129,\n",
       "  0.4919957220554352,\n",
       "  -0.9572163224220276,\n",
       "  0.9127964377403259,\n",
       "  -1.1320428848266602,\n",
       "  -0.9408490657806396,\n",
       "  -0.6671188473701477,\n",
       "  0.0028904853388667107,\n",
       "  0.9514382481575012,\n",
       "  0.5172134637832642,\n",
       "  -0.9804638624191284,\n",
       "  0.9831364154815674,\n",
       "  0.3366073668003082,\n",
       "  -0.6688900589942932,\n",
       "  -0.22102729976177216,\n",
       "  -0.27072012424468994,\n",
       "  -0.2428804337978363,\n",
       "  -0.42171019315719604,\n",
       "  0.1411140263080597,\n",
       "  -0.14551730453968048,\n",
       "  -0.034275468438863754,\n",
       "  0.7025639414787292,\n",
       "  -0.8545458316802979,\n",
       "  -1.1921099424362183,\n",
       "  -0.475334495306015,\n",
       "  -0.345081627368927,\n",
       "  0.19061064720153809,\n",
       "  0.8010258674621582,\n",
       "  0.8948745131492615,\n",
       "  0.5787580013275146,\n",
       "  -0.3297763466835022,\n",
       "  0.30622926354408264,\n",
       "  -0.0518777072429657,\n",
       "  -0.5403957366943359,\n",
       "  2.0517735481262207,\n",
       "  0.5759737491607666,\n",
       "  0.506102979183197,\n",
       "  2.3833441734313965,\n",
       "  0.40433427691459656,\n",
       "  0.5839784145355225,\n",
       "  -1.0290361642837524,\n",
       "  0.33733364939689636,\n",
       "  -0.11121660470962524,\n",
       "  0.036101147532463074,\n",
       "  0.12554903328418732,\n",
       "  -0.0955507829785347,\n",
       "  0.3788377642631531,\n",
       "  1.4412147998809814,\n",
       "  -0.27440357208251953,\n",
       "  1.0239977836608887,\n",
       "  -0.436544269323349,\n",
       "  -1.5473003387451172,\n",
       "  -0.8912095427513123,\n",
       "  -0.0865086242556572,\n",
       "  0.48633190989494324,\n",
       "  -1.9452670812606812,\n",
       "  0.7133665084838867,\n",
       "  -1.2399451732635498,\n",
       "  0.23550748825073242,\n",
       "  1.1019083261489868,\n",
       "  -0.2064293622970581,\n",
       "  0.13285280764102936,\n",
       "  -0.9058158993721008,\n",
       "  0.9564481377601624,\n",
       "  -0.7765880227088928,\n",
       "  -0.011016297154128551,\n",
       "  0.3272022008895874,\n",
       "  -1.4400027990341187,\n",
       "  0.9512280821800232,\n",
       "  -0.20263274013996124,\n",
       "  -1.0906867980957031,\n",
       "  -0.07482045888900757,\n",
       "  1.0576319694519043,\n",
       "  0.652133047580719,\n",
       "  -1.0051792860031128,\n",
       "  -0.7318978309631348,\n",
       "  0.6530517935752869,\n",
       "  0.46394115686416626,\n",
       "  0.060400769114494324,\n",
       "  -1.197543978691101,\n",
       "  0.4145498275756836,\n",
       "  1.4513837099075317,\n",
       "  -1.3661162853240967,\n",
       "  0.5255602598190308,\n",
       "  -1.1281089782714844,\n",
       "  0.5859745144844055,\n",
       "  -1.2266254425048828,\n",
       "  -0.4046606719493866,\n",
       "  -0.31083837151527405,\n",
       "  0.37140658497810364,\n",
       "  0.045138221234083176,\n",
       "  -1.469336986541748,\n",
       "  0.15775300562381744,\n",
       "  -0.5297372341156006,\n",
       "  0.2583106458187103,\n",
       "  0.17012052237987518,\n",
       "  -0.2884591519832611,\n",
       "  0.8635023832321167,\n",
       "  0.3285696804523468,\n",
       "  -0.9669808745384216,\n",
       "  -0.4402823746204376,\n",
       "  0.9988057017326355,\n",
       "  -1.3315908908843994,\n",
       "  0.5323963165283203,\n",
       "  -0.36174169182777405,\n",
       "  1.2517521381378174,\n",
       "  0.6563014984130859,\n",
       "  0.9625159502029419,\n",
       "  0.24855898320674896,\n",
       "  1.0401172637939453,\n",
       "  0.7457097172737122,\n",
       "  -0.3615637421607971,\n",
       "  -0.34423157572746277,\n",
       "  -0.09923975169658661,\n",
       "  0.19688214361667633,\n",
       "  1.6006919145584106,\n",
       "  -0.46191707253456116,\n",
       "  -1.6053208112716675,\n",
       "  0.0315171480178833,\n",
       "  -1.0570616722106934,\n",
       "  0.03745979443192482,\n",
       "  -0.13109081983566284,\n",
       "  0.30126893520355225,\n",
       "  0.2838076651096344,\n",
       "  0.1365334689617157,\n",
       "  0.33746081590652466,\n",
       "  -0.42600399255752563,\n",
       "  -0.47105684876441956,\n",
       "  -0.5158219337463379,\n",
       "  0.2223135232925415,\n",
       "  0.8343257308006287,\n",
       "  -0.5328518152236938,\n",
       "  -0.5278983116149902,\n",
       "  -1.4294922351837158,\n",
       "  -0.4285529851913452,\n",
       "  0.46536535024642944,\n",
       "  -1.0041030645370483,\n",
       "  1.1897015571594238,\n",
       "  0.03184099495410919,\n",
       "  -0.06788571923971176,\n",
       "  1.104892611503601,\n",
       "  -0.5959690809249878,\n",
       "  -0.5396496057510376,\n",
       "  -0.08816646039485931,\n",
       "  0.7340991497039795,\n",
       "  -0.16472601890563965,\n",
       "  1.9898741245269775,\n",
       "  0.9823452830314636,\n",
       "  -1.056932806968689,\n",
       "  0.23361271619796753,\n",
       "  0.12415719777345657,\n",
       "  0.5437313914299011,\n",
       "  1.7948616743087769,\n",
       "  -0.32701489329338074,\n",
       "  -0.7485261559486389,\n",
       "  -0.30409884452819824,\n",
       "  0.35850173234939575,\n",
       "  0.5726432204246521,\n",
       "  -0.13591112196445465,\n",
       "  -0.8162773847579956,\n",
       "  -0.3812115788459778,\n",
       "  0.7845274806022644,\n",
       "  0.5025718808174133,\n",
       "  -1.1307634115219116,\n",
       "  -0.04252856969833374,\n",
       "  -0.32027459144592285,\n",
       "  -0.5090148448944092,\n",
       "  -0.6414567828178406,\n",
       "  0.8604727387428284,\n",
       "  -0.3552606701850891,\n",
       "  -1.4597867727279663,\n",
       "  0.3043346405029297,\n",
       "  -0.08725962787866592,\n",
       "  0.3813934326171875,\n",
       "  0.7859547734260559,\n",
       "  -0.6434991955757141,\n",
       "  1.456185221672058,\n",
       "  -0.12415921688079834,\n",
       "  -0.17241936922073364,\n",
       "  1.217812418937683,\n",
       "  1.085871696472168,\n",
       "  0.10084442794322968,\n",
       "  -1.0229454040527344,\n",
       "  -0.40100738406181335,\n",
       "  -0.3780153691768646,\n",
       "  0.39417436718940735,\n",
       "  1.1881386041641235,\n",
       "  1.542353868484497,\n",
       "  -1.9725686311721802,\n",
       "  -0.5203942060470581,\n",
       "  1.1160944700241089,\n",
       "  -0.014395506121218204,\n",
       "  0.7230808138847351,\n",
       "  -0.11082858592271805,\n",
       "  1.0363773107528687,\n",
       "  1.8468562364578247,\n",
       "  -2.0043156147003174,\n",
       "  -0.857660174369812,\n",
       "  -0.016947176307439804,\n",
       "  0.9268367886543274,\n",
       "  0.43811312317848206,\n",
       "  0.03879019618034363,\n",
       "  1.5003983974456787,\n",
       "  -1.9666718244552612,\n",
       "  0.24025940895080566,\n",
       "  -0.1281508356332779,\n",
       "  -0.4565701186656952,\n",
       "  0.9136591553688049,\n",
       "  0.13354016840457916,\n",
       "  1.4720755815505981,\n",
       "  2.2242579460144043,\n",
       "  -0.9771332144737244,\n",
       "  -0.2118615359067917,\n",
       "  0.42171016335487366,\n",
       "  -0.3062329888343811,\n",
       "  -0.08225347101688385,\n",
       "  -0.14035509526729584,\n",
       "  -0.44873225688934326,\n",
       "  -0.1342362016439438,\n",
       "  0.8969573378562927,\n",
       "  0.9649704098701477,\n",
       "  -0.3184075355529785,\n",
       "  0.05100765451788902,\n",
       "  -0.3010237514972687,\n",
       "  -1.994753122329712,\n",
       "  0.23152372241020203,\n",
       "  -0.43320539593696594,\n",
       "  0.30013665556907654,\n",
       "  0.3593301773071289,\n",
       "  -0.49544548988342285,\n",
       "  -0.2677685022354126,\n",
       "  -0.32895347476005554,\n",
       "  0.47677841782569885,\n",
       "  0.5957240462303162,\n",
       "  -0.5214465260505676,\n",
       "  -0.7509101033210754,\n",
       "  -0.5308319926261902,\n",
       "  0.4380829632282257,\n",
       "  -0.3486383855342865,\n",
       "  0.8670448064804077,\n",
       "  0.49849584698677063,\n",
       "  0.35085511207580566,\n",
       "  -0.3497740626335144,\n",
       "  -0.12181560695171356,\n",
       "  0.9101688265800476,\n",
       "  1.4270000457763672,\n",
       "  0.1688191443681717,\n",
       "  -0.5369781851768494,\n",
       "  -1.298940658569336,\n",
       "  -1.2320137023925781,\n",
       "  0.6238635778427124,\n",
       "  -0.305776447057724,\n",
       "  0.3326358199119568,\n",
       "  0.20119649171829224,\n",
       "  0.7106612920761108,\n",
       "  0.612585723400116,\n",
       "  -0.2824658155441284,\n",
       "  0.31141382455825806,\n",
       "  0.017915556207299232,\n",
       "  -0.7348000407218933,\n",
       "  0.5519070029258728,\n",
       "  0.9619629383087158,\n",
       "  -0.24329659342765808,\n",
       "  -0.35985398292541504,\n",
       "  0.42393243312835693,\n",
       "  -0.9171541333198547,\n",
       "  0.7874794006347656,\n",
       "  0.4591333866119385,\n",
       "  -1.2163174152374268,\n",
       "  -0.19382549822330475,\n",
       "  -0.2279851734638214,\n",
       "  0.09523838013410568,\n",
       "  -0.09776803851127625,\n",
       "  -0.7298553586006165,\n",
       "  -0.6937829852104187,\n",
       "  0.06570646911859512,\n",
       "  -0.9908565878868103,\n",
       "  -1.137206792831421,\n",
       "  0.5305777788162231,\n",
       "  0.14013360440731049,\n",
       "  -0.5639883875846863,\n",
       "  0.5132665634155273,\n",
       "  0.4876028001308441,\n",
       "  -0.03626338019967079,\n",
       "  0.5123088359832764,\n",
       "  0.04086695611476898,\n",
       "  -0.3464132845401764,\n",
       "  -1.2529419660568237,\n",
       "  -0.11896364390850067,\n",
       "  -1.0780384540557861,\n",
       "  -0.7252869606018066,\n",
       "  1.2735633850097656,\n",
       "  -1.770756483078003,\n",
       "  -1.3559248447418213,\n",
       "  -0.4425646960735321,\n",
       "  -0.07050430029630661,\n",
       "  -1.3163882493972778,\n",
       "  0.1992529183626175,\n",
       "  0.5986555218696594,\n",
       "  -0.4449828863143921,\n",
       "  -1.2407692670822144,\n",
       "  0.7635737657546997,\n",
       "  0.9723789691925049,\n",
       "  0.6091117262840271,\n",
       "  0.8403080701828003,\n",
       "  0.6270805597305298,\n",
       "  -0.3162863850593567,\n",
       "  -0.13352656364440918,\n",
       "  -0.0922563448548317,\n",
       "  0.35156863927841187,\n",
       "  -0.7110291719436646,\n",
       "  -0.2205553948879242,\n",
       "  -0.18776461482048035,\n",
       "  0.10886421799659729,\n",
       "  -0.5138785243034363,\n",
       "  0.20376111567020416,\n",
       "  0.16185283660888672,\n",
       "  0.02073831297457218,\n",
       "  1.003756046295166,\n",
       "  -1.5112593173980713,\n",
       "  -0.4924792945384979,\n",
       "  0.4064434766769409,\n",
       "  -1.1391249895095825,\n",
       "  -1.2264302968978882,\n",
       "  0.6491557359695435,\n",
       "  -0.3732842803001404,\n",
       "  0.5134333968162537,\n",
       "  -0.4194371998310089,\n",
       "  -0.1425277292728424,\n",
       "  0.48593059182167053,\n",
       "  0.007722914218902588,\n",
       "  0.20749589800834656,\n",
       "  -0.32297611236572266,\n",
       "  -0.2871229648590088,\n",
       "  -0.5917553901672363,\n",
       "  0.08187642693519592,\n",
       "  -0.036566171795129776,\n",
       "  -0.33058735728263855,\n",
       "  -1.1234263181686401,\n",
       "  -0.43397262692451477,\n",
       "  -0.6944589614868164,\n",
       "  0.26784831285476685,\n",
       "  0.3025170862674713,\n",
       "  1.5088883638381958,\n",
       "  -1.6363383531570435,\n",
       "  -0.20570097863674164,\n",
       "  1.5923376083374023,\n",
       "  -0.18439941108226776,\n",
       "  -0.30326956510543823,\n",
       "  -0.27180808782577515,\n",
       "  -1.0245373249053955,\n",
       "  0.6121546030044556,\n",
       "  -0.19086244702339172,\n",
       "  -0.23219208419322968,\n",
       "  -0.02657068707048893,\n",
       "  0.5410881042480469,\n",
       "  0.2793097198009491,\n",
       "  1.311288595199585,\n",
       "  0.11528853327035904,\n",
       "  -0.2937442362308502,\n",
       "  -0.6176654100418091,\n",
       "  -0.4125719964504242,\n",
       "  -1.2376269102096558,\n",
       "  0.9006844758987427,\n",
       "  -0.575075626373291,\n",
       "  1.0611597299575806,\n",
       "  -0.6528575420379639,\n",
       "  -2.2196102142333984,\n",
       "  -0.2538857161998749,\n",
       "  0.4516369104385376,\n",
       "  1.3173598051071167,\n",
       "  -0.8558019399642944,\n",
       "  0.9558899402618408,\n",
       "  -1.778191089630127,\n",
       "  -1.4735815525054932,\n",
       "  -0.42438986897468567,\n",
       "  -0.631700336933136,\n",
       "  -0.8254136443138123,\n",
       "  -0.5254575610160828,\n",
       "  -0.22158248722553253,\n",
       "  0.9046706557273865,\n",
       "  0.4769757091999054,\n",
       "  -0.2724475860595703,\n",
       "  -0.14533206820487976,\n",
       "  0.41141462326049805,\n",
       "  0.32732781767845154,\n",
       "  -0.665069043636322,\n",
       "  1.1854168176651,\n",
       "  0.6615901589393616,\n",
       "  0.8470917344093323,\n",
       "  -1.2924093008041382,\n",
       "  1.8585574626922607,\n",
       "  1.9868868589401245,\n",
       "  -0.16062957048416138,\n",
       "  0.201873779296875,\n",
       "  0.9513229131698608,\n",
       "  -1.0418353080749512,\n",
       "  0.6644391417503357,\n",
       "  -1.745572566986084,\n",
       "  -0.8698028922080994,\n",
       "  -0.7074482440948486,\n",
       "  -0.1921924352645874,\n",
       "  -0.45231732726097107,\n",
       "  -0.537926435470581,\n",
       "  0.5713998079299927,\n",
       "  0.35358452796936035,\n",
       "  -0.5050451159477234,\n",
       "  0.2874166965484619,\n",
       "  -0.8551613092422485,\n",
       "  -1.1664677858352661,\n",
       "  -0.007082620169967413,\n",
       "  1.1009587049484253,\n",
       "  0.5655152201652527,\n",
       "  0.6524333357810974,\n",
       "  0.43570753931999207,\n",
       "  0.1539478302001953,\n",
       "  0.8178704977035522,\n",
       "  0.01660430245101452,\n",
       "  1.2007057666778564,\n",
       "  0.7326721549034119,\n",
       "  -1.7113200426101685,\n",
       "  0.41457781195640564,\n",
       "  -0.28453385829925537,\n",
       "  -0.4241360127925873,\n",
       "  -0.20378921926021576,\n",
       "  -0.37923768162727356,\n",
       "  -1.9972379207611084,\n",
       "  0.9599770903587341,\n",
       "  -1.0005782842636108,\n",
       "  0.0019000580068677664,\n",
       "  -0.7989634275436401,\n",
       "  0.2873186469078064,\n",
       "  -0.9045395255088806,\n",
       "  0.6488743424415588,\n",
       "  -0.5509166121482849,\n",
       "  -0.473300576210022,\n",
       "  -0.7173073291778564,\n",
       "  0.17363525927066803,\n",
       "  0.0818098708987236,\n",
       "  -0.13603700697422028,\n",
       "  1.732576847076416,\n",
       "  0.09819991141557693,\n",
       "  1.0219606161117554,\n",
       "  0.09969967603683472,\n",
       "  0.6729124784469604,\n",
       "  -0.643262505531311,\n",
       "  -1.5545017719268799,\n",
       "  0.11030621826648712,\n",
       "  0.19128607213497162,\n",
       "  -0.8465402126312256,\n",
       "  -0.3420805037021637,\n",
       "  0.06047574430704117,\n",
       "  1.5501629114151,\n",
       "  -0.07090883702039719,\n",
       "  0.4265688955783844,\n",
       "  0.7685563564300537,\n",
       "  -0.0021534976549446583,\n",
       "  -0.43066298961639404,\n",
       "  0.13246037065982819,\n",
       "  -0.5926840305328369,\n",
       "  0.9210754036903381,\n",
       "  0.5539515614509583,\n",
       "  -0.10692299902439117,\n",
       "  -1.0262304544448853,\n",
       "  -0.5247345566749573,\n",
       "  -0.25825807452201843,\n",
       "  -0.5827562212944031,\n",
       "  0.7864335179328918,\n",
       "  -0.7950692772865295,\n",
       "  1.3766059875488281,\n",
       "  0.16910450160503387,\n",
       "  0.3173970580101013,\n",
       "  0.2932294011116028,\n",
       "  -0.9604978561401367,\n",
       "  0.7939589619636536,\n",
       "  0.05670551583170891,\n",
       "  -0.017920177429914474,\n",
       "  -1.0769374370574951,\n",
       "  0.17467965185642242,\n",
       "  -0.39154863357543945,\n",
       "  -0.34224796295166016,\n",
       "  -0.9155281186103821,\n",
       "  0.13091076910495758,\n",
       "  0.22796478867530823,\n",
       "  -0.14910179376602173,\n",
       "  -0.3024307191371918,\n",
       "  -0.7869777679443359,\n",
       "  -0.5933096408843994,\n",
       "  0.22534820437431335,\n",
       "  0.6333368420600891,\n",
       "  -0.0023393300361931324,\n",
       "  0.30079931020736694,\n",
       "  -0.166265070438385,\n",
       "  -1.1152641773223877,\n",
       "  -0.4978061616420746,\n",
       "  -0.07934486865997314,\n",
       "  0.5410964488983154,\n",
       "  -0.9518009424209595,\n",
       "  1.7615876197814941,\n",
       "  0.599899411201477,\n",
       "  0.4490099251270294,\n",
       "  1.1143608093261719,\n",
       "  0.14927901327610016,\n",
       "  1.4841676950454712,\n",
       "  -0.6822470426559448,\n",
       "  -0.9599718451499939,\n",
       "  -1.1886441707611084,\n",
       "  -1.2840125560760498,\n",
       "  -0.2297176718711853]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba8c558-3832-469f-942b-07f5615d337f",
   "metadata": {},
   "source": [
    "We can do arithmetic between these embeddings to calculate distances between them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "171b4bf5-c638-4280-8564-ef45268a60a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "X = np.array(doc_vectors)\n",
    "dists = squareform(pdist(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e73d64-9d04-45de-809a-0d50c5299a11",
   "metadata": {},
   "source": [
    "This gives us the Euclidean distances between our words as a square matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a37fa987-aba4-4521-ac37-083a566954af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b98b7_row0_col0, #T_b98b7_row1_col1, #T_b98b7_row2_col2, #T_b98b7_row3_col3 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b98b7_row0_col1 {\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b98b7_row0_col2 {\n",
       "  background-color: #d1493f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b98b7_row0_col3 {\n",
       "  background-color: #f7ad90;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b98b7_row1_col0 {\n",
       "  background-color: #e9785d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b98b7_row1_col2, #T_b98b7_row2_col0, #T_b98b7_row2_col1, #T_b98b7_row2_col3 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b98b7_row1_col3 {\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b98b7_row3_col0 {\n",
       "  background-color: #f59d7e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b98b7_row3_col1 {\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b98b7_row3_col2 {\n",
       "  background-color: #be242e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b98b7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b98b7_level0_col0\" class=\"col_heading level0 col0\" >cat</th>\n",
       "      <th id=\"T_b98b7_level0_col1\" class=\"col_heading level0 col1\" >dog</th>\n",
       "      <th id=\"T_b98b7_level0_col2\" class=\"col_heading level0 col2\" >computer</th>\n",
       "      <th id=\"T_b98b7_level0_col3\" class=\"col_heading level0 col3\" >animal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b98b7_level0_row0\" class=\"row_heading level0 row0\" >cat</th>\n",
       "      <td id=\"T_b98b7_row0_col0\" class=\"data row0 col0\" >0.000000</td>\n",
       "      <td id=\"T_b98b7_row0_col1\" class=\"data row0 col1\" >14.640208</td>\n",
       "      <td id=\"T_b98b7_row0_col2\" class=\"data row0 col2\" >17.752331</td>\n",
       "      <td id=\"T_b98b7_row0_col3\" class=\"data row0 col3\" >13.146150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b98b7_level0_row1\" class=\"row_heading level0 row1\" >dog</th>\n",
       "      <td id=\"T_b98b7_row1_col0\" class=\"data row1 col0\" >14.640208</td>\n",
       "      <td id=\"T_b98b7_row1_col1\" class=\"data row1 col1\" >0.000000</td>\n",
       "      <td id=\"T_b98b7_row1_col2\" class=\"data row1 col2\" >19.349403</td>\n",
       "      <td id=\"T_b98b7_row1_col3\" class=\"data row1 col3\" >7.541415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b98b7_level0_row2\" class=\"row_heading level0 row2\" >computer</th>\n",
       "      <td id=\"T_b98b7_row2_col0\" class=\"data row2 col0\" >17.752331</td>\n",
       "      <td id=\"T_b98b7_row2_col1\" class=\"data row2 col1\" >19.349403</td>\n",
       "      <td id=\"T_b98b7_row2_col2\" class=\"data row2 col2\" >0.000000</td>\n",
       "      <td id=\"T_b98b7_row2_col3\" class=\"data row2 col3\" >18.804777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b98b7_level0_row3\" class=\"row_heading level0 row3\" >animal</th>\n",
       "      <td id=\"T_b98b7_row3_col0\" class=\"data row3 col0\" >13.146150</td>\n",
       "      <td id=\"T_b98b7_row3_col1\" class=\"data row3 col1\" >7.541415</td>\n",
       "      <td id=\"T_b98b7_row3_col2\" class=\"data row3 col2\" >18.804777</td>\n",
       "      <td id=\"T_b98b7_row3_col3\" class=\"data row3 col3\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x73431e1a9ca0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=dists,\n",
    "    index=words,\n",
    "    columns=words\n",
    ")\n",
    "df.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8d2a93-0435-488d-980d-b1d57a47f15c",
   "metadata": {},
   "source": [
    "Concept in RAG\n",
    "1. Indexing organizes vectors to optimize retrieval, structuring them so that vectors can be retrieval quickly. There are different algorithms like k-d trees or Annoy for this.\n",
    "2. Vector libraries provide functions for vector operations like dot product and vector indexing.\n",
    "3. Vector databases like Milvus or Pinecone are designed to store, manage, and retrieve larget sets of vectors. They use indexing mechanism to facilitate efficient similarity searches on these vvectorsl."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6855b362-26b2-4ae1-bc0c-a4973fd408bc",
   "metadata": {},
   "source": [
    "### Chroma\n",
    "Vector store optimized for storing and querying vectors using Chroma as a backend. Chroma takes over for encoding and comparing vectors based on their angular similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c850b299-228a-463f-9e4f-bdfdc3d9141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af78d6e7-5e75-4eb6-8db6-36fb80d1e0b2",
   "metadata": {},
   "source": [
    "Create an instance of Chroma and provide the documents (splits) and the embedding method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e640ae9e-3eac-42c6-b7c4-3138e21a7278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m88 packages\u001b[0m \u001b[2min 669ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m16 packages\u001b[0m \u001b[2min 471ms\u001b[0m\u001b[0m                                            \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m41 packages\u001b[0m \u001b[2min 22ms\u001b[0m\u001b[0m                               \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1masgiref\u001b[0m\u001b[2m==3.8.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbackoff\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbcrypt\u001b[0m\u001b[2m==4.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mchroma-hnswlib\u001b[0m\u001b[2m==0.7.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mchromadb\u001b[0m\u001b[2m==0.6.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdeprecated\u001b[0m\u001b[2m==1.2.18\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdurationpy\u001b[0m\u001b[2m==0.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfastapi\u001b[0m\u001b[2m==0.115.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-auth\u001b[0m\u001b[2m==2.38.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogleapis-common-protos\u001b[0m\u001b[2m==1.67.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgrpcio\u001b[0m\u001b[2m==1.70.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttptools\u001b[0m\u001b[2m==0.6.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mimportlib-metadata\u001b[0m\u001b[2m==8.5.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mimportlib-resources\u001b[0m\u001b[2m==6.5.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mkubernetes\u001b[0m\u001b[2m==32.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmonotonic\u001b[0m\u001b[2m==1.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1moauthlib\u001b[0m\u001b[2m==3.2.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-api\u001b[0m\u001b[2m==1.30.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-exporter-otlp-proto-common\u001b[0m\u001b[2m==1.30.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-exporter-otlp-proto-grpc\u001b[0m\u001b[2m==1.30.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-instrumentation\u001b[0m\u001b[2m==0.51b0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-instrumentation-asgi\u001b[0m\u001b[2m==0.51b0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-instrumentation-fastapi\u001b[0m\u001b[2m==0.51b0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-proto\u001b[0m\u001b[2m==1.30.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-sdk\u001b[0m\u001b[2m==1.30.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-semantic-conventions\u001b[0m\u001b[2m==0.51b0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-util-http\u001b[0m\u001b[2m==0.51b0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mposthog\u001b[0m\u001b[2m==3.14.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyasn1\u001b[0m\u001b[2m==0.6.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyasn1-modules\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpypika\u001b[0m\u001b[2m==0.48.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrequests-oauthlib\u001b[0m\u001b[2m==2.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrsa\u001b[0m\u001b[2m==4.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mstarlette\u001b[0m\u001b[2m==0.45.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyper\u001b[0m\u001b[2m==0.15.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1muvicorn\u001b[0m\u001b[2m==0.34.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1muvloop\u001b[0m\u001b[2m==0.21.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwatchfiles\u001b[0m\u001b[2m==1.0.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwebsockets\u001b[0m\u001b[2m==15.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwrapt\u001b[0m\u001b[2m==1.17.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mzipp\u001b[0m\u001b[2m==3.21.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! uv pip install pymupdf chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfd43000-50db-4775-87e5-810e4dc886a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 9ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! uv pip install langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d0c4066-ec7a-4246-92e3-b86a84482975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import ArxivLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "loader = ArxivLoader(query=\"2310.06825\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3318c7eb-5dda-404c-8739-dbf7d2e0f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    ")\n",
    "vectorstore = Chroma.from_documents(documents=docs, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e262606-9e87-4df3-955e-f959fdae11fa",
   "metadata": {},
   "source": [
    "# Evaluating LLMS\n",
    "## Comparing two outputs\n",
    "1. Create the evaluator: Load the evaluator using the `load_evaluator()` function, specifying the type of evaluator (in this case, pairwise_string).\n",
    "2. Select the dataset: Load a dataset of inputs using the `load_dataset()` function.\n",
    "3. Define models to compare: Initialize the LLMs, chains, or agents to compare using the necessary configurations. This involves initializing the language model and any additional tools or agents required.\n",
    "4. Generate responses: Generate outputs for each of the models before evaluating them. This is typically done in batches to improve efficiency.\n",
    "5. Evaluate pairs: Evaluate the results by comparing the outputs of different models for each input. This is done using a random selection order to reduce positional bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43db90ed-3d56-486c-b993-e555644dcdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! seed is not default parameter.\n",
      "                    seed was transferred to model_kwargs.\n",
      "                    Please confirm that seed is what you intended.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Evaluation with the <class 'langchain.evaluation.comparison.eval_chain.LabeledPairwiseStringEvalChain'> requires a language model to function. Failed to create the default 'gpt-4' model. Please manually provide an evaluation LLM or check your openai credentials.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain/evaluation/loading.py:150\u001b[0m, in \u001b[0;36mload_evaluator\u001b[0;34m(evaluator, llm, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    143\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import langchain_openai or fallback onto \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlangchain_community. Please install langchain_openai \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecify a language model explicitly.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m             )\n\u001b[0;32m--> 150\u001b[0m     llm \u001b[38;5;241m=\u001b[39m llm \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-arg]\u001b[39;49;00m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:214\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m     emit_warning()\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain_core/load/serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/pydantic/main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ChatOpenAI\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'temperature': 0, 'model...ne, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_evaluator\n\u001b[1;32m      2\u001b[0m embedding_function \u001b[38;5;241m=\u001b[39m OllamaEmbeddings(\n\u001b[1;32m      3\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnomic-embed-text\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m )\n\u001b[0;32m----> 6\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m \u001b[43mload_evaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabeled_pairwise_string\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mevaluate_string_pairs(\n\u001b[1;32m      8\u001b[0m     prediction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthere are three dogs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     prediction_b\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhow many dogs are in the park?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     refeerence\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfour\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain/evaluation/loading.py:154\u001b[0m, in \u001b[0;36mload_evaluator\u001b[0;34m(evaluator, llm, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         llm \u001b[38;5;241m=\u001b[39m llm \u001b[38;5;129;01mor\u001b[39;00m ChatOpenAI(  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m    151\u001b[0m             model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m\"\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    152\u001b[0m         )\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 154\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    155\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation with the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevaluator_cls\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage model to function.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Failed to create the default \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m model.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please manually provide an evaluation LLM\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or check your openai credentials.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m evaluator_cls\u001b[38;5;241m.\u001b[39mfrom_llm(llm\u001b[38;5;241m=\u001b[39mllm, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Evaluation with the <class 'langchain.evaluation.comparison.eval_chain.LabeledPairwiseStringEvalChain'> requires a language model to function. Failed to create the default 'gpt-4' model. Please manually provide an evaluation LLM or check your openai credentials."
     ]
    }
   ],
   "source": [
    "from langchain.evaluation import load_evaluator\n",
    "embedding_function = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    ")\n",
    "\n",
    "evaluator = load_evaluator(\"labeled_pairwise_string\", embeddings=embedding_function)\n",
    "evaluator.evaluate_string_pairs(\n",
    "    prediction=\"there are three dogs\",\n",
    "    prediction_b=\"4\",\n",
    "    input=\"how many dogs are in the park?\",\n",
    "    refeerence=\"four\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "192fa082-a3f6-4b40-815a-f588e6072537",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for LabeledPairwiseStringEvalChain\nprompt\n  Field required [type=missing, input_value={'evaluation_llm': ChatOl...phi3', temperature=0.0)}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\nllm\n  Field required [type=missing, input_value={'evaluation_llm': ChatOl...phi3', temperature=0.0)}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Provide your chosen Ollama model for evaluation\u001b[39;00m\n\u001b[1;32m      5\u001b[0m evaluation_llm \u001b[38;5;241m=\u001b[39m ChatOllama(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphi3\u001b[39m\u001b[38;5;124m\"\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m eval_chain \u001b[38;5;241m=\u001b[39m \u001b[43mLabeledPairwiseStringEvalChain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluation_llm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluation_llm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:214\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     emit_warning()\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain_core/load/serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/pydantic/main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    216\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    220\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    221\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 2 validation errors for LabeledPairwiseStringEvalChain\nprompt\n  Field required [type=missing, input_value={'evaluation_llm': ChatOl...phi3', temperature=0.0)}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\nllm\n  Field required [type=missing, input_value={'evaluation_llm': ChatOl...phi3', temperature=0.0)}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing"
     ]
    }
   ],
   "source": [
    "from langchain.evaluation.comparison.eval_chain import LabeledPairwiseStringEvalChain\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Provide your chosen Ollama model for evaluation\n",
    "evaluation_llm = ChatOllama(model=\"phi3\", temperature=0)\n",
    "\n",
    "eval_chain = LabeledPairwiseStringEvalChain(evaluation_llm=evaluation_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10b90fed-2f9c-4e48-9065-21cae610dc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.comparison.eval_chain import LabeledPairwiseStringEvalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Initialize your local Ollama model (or any other model)\n",
    "evaluation_llm = ChatOllama(model=\"phi3\", temperature=0)\n",
    "\n",
    "# Define a prompt template for evaluation\n",
    "eval_prompt = PromptTemplate(\n",
    "    template=(\n",
    "        \"You are an expert evaluator. Compare the following two outputs and decide which is better. \"\n",
    "        \"Output A: {output_a}\\nOutput B: {output_b}\\n\"\n",
    "        \"Provide a brief explanation for your choice.\"\n",
    "    ),\n",
    "    input_variables=[\"output_a\", \"output_b\"]\n",
    ")\n",
    "\n",
    "# Now instantiate the evaluation chain by providing both llm and prompt.\n",
    "eval_chain = LabeledPairwiseStringEvalChain(\n",
    "    llm=evaluation_llm,         # This is the main LLM to use\n",
    "    prompt=eval_prompt,         # The prompt instructing how to compare outputs\n",
    "    evaluation_llm=evaluation_llm  # You can use the same model for evaluation, or a different one\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3d4fb37e-e64e-43d3-8db6-d719b5cf8164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.comparison.eval_chain import LabeledPairwiseStringEvalChain\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "evaluation_llm = ChatOllama(model=\"phi3\", temperature=0)\n",
    "\n",
    "eval_chain = LabeledPairwiseStringEvalChain(\n",
    "    llm=evaluation_llm,\n",
    "    prompt=custom_eval_prompt,\n",
    "    evaluation_llm=evaluation_llm\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e948534d-d71b-44df-a029-07008433ec79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output_a': 'there are three dogs', 'output_b': '4', 'input': 'how many dogs are in the park?', 'reference': 'four', 'results': {'reasoning': '[[B]]', 'value': 'B', 'score': 0}}\n"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"output_a\": \"there are three dogs\",\n",
    "    \"output_b\": \"4\",\n",
    "    \"input\": \"how many dogs are in the park?\",\n",
    "    \"reference\": \"four\"\n",
    "}\n",
    "\n",
    "result = eval_chain.invoke(inputs)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2256cefb-8065-4277-a644-2ad1431382c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing some input keys: {'output_b', 'output_a'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43meval_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_string_pairs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthere are three dogs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m \u001b[49m\u001b[43mprediction_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m \u001b[49m\u001b[43mreference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfour\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43moutput_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkk\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43moutput_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjjj\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain/evaluation/schema.py:324\u001b[0m, in \u001b[0;36mPairwiseStringEvaluator.evaluate_string_pairs\u001b[0;34m(self, prediction, prediction_b, reference, input, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate the output string pairs.\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;124;03m    dict: A dictionary containing the preference, scores, and/or other information.\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_evaluation_args(reference\u001b[38;5;241m=\u001b[39mreference, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_string_pairs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprediction_b\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain/evaluation/comparison/eval_chain.py:342\u001b[0m, in \u001b[0;36mPairwiseStringEvalChain._evaluate_string_pairs\u001b[0;34m(self, prediction, prediction_b, input, reference, callbacks, tags, metadata, include_run_info, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate whether output A is preferred to output B.\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    339\u001b[0m \n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    341\u001b[0m input_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(prediction, prediction_b, \u001b[38;5;28minput\u001b[39m, reference)\n\u001b[0;32m--> 342\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_output(result)\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:181\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     emit_warning()\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain/chains/base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    387\u001b[0m }\n\u001b[0;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain/chains/base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain/chains/base.py:158\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    153\u001b[0m     inputs,\n\u001b[1;32m    154\u001b[0m     run_id,\n\u001b[1;32m    155\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[1;32m    156\u001b[0m )\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    167\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/tutorials/tutorials/.venv/lib/python3.12/site-packages/langchain/chains/base.py:290\u001b[0m, in \u001b[0;36mChain._validate_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    288\u001b[0m missing_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_keys)\u001b[38;5;241m.\u001b[39mdifference(inputs)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_keys:\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing some input keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Missing some input keys: {'output_b', 'output_a'}"
     ]
    }
   ],
   "source": [
    "eval_chain.evaluate_string_pairs(\n",
    "    prediction=\"there are three dogs\",\n",
    " prediction_b=\"4\",\n",
    "    input=inputs,\n",
    " reference=\"four\",\n",
    "output_a=\"kk\",\n",
    "output_b=\"jjj\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ab502c-b990-43f4-a0dc-7b02723a2a7b",
   "metadata": {},
   "source": [
    "# Tool\n",
    "The tool abstraction in LangChain associates a Python function with a schema that defines the function's name, description and expected arguments.\n",
    "\n",
    "Tools can be passed to chat models that support tool calling allowing the model to request the execution of a specific function with specific inputs.\n",
    "\n",
    "Key concepts\n",
    "- Tools are a way to encapsulate a function and its schema in a way that can be passed to a chat model.\n",
    "- Create tools using the @tool decorator, which simplifies the process of tool creation, supporting the following:\n",
    "- - Automatically infer the tool's name, description and expected arguments, while also supporting customization.\n",
    "- - Defining tools that return artifacts (e.g. images, dataframes, etc.)\n",
    "- - Hiding input arguments from the schema (and hence from the model) using injected tool arguments.\n",
    " \n",
    "The tool interface is defined in the BaseTool class which is a subclass of the Runnable Interface.\n",
    "\n",
    "Parameters for BaseTool:\n",
    "- tool_input\n",
    "- verbose\n",
    "- start_color\n",
    "- color\n",
    "- callbacks\n",
    "- tags\n",
    "- metadata\n",
    "- run_name\n",
    "- run_id\n",
    "\n",
    "Key attributes to the tool's schema\n",
    "- name: name of the tool\n",
    "- description: a description of what the tool does\n",
    "- args: property that returns the JSON echmea for the tool's arguments\n",
    "\n",
    "Key methods\n",
    "- inboke: invokes the tool with the given arguments\n",
    "- ainvoke: invokes the tool with the given argument asynchronously\n",
    "\n",
    "Create tools using the @tool decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d9a7190-d869-4792-9abd-9f249e10d0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b:int) -> int:\n",
    "    \"\"\"Multiply two numbers\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5eef4582-2c40-47f3-abaf-a93b4af78740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.invoke({\"a\": 2, \"b\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a6c0070-c3ec-4277-a280-5e4d651b0605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "Multiply two numbers\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "print(multiply.name) # multiply\n",
    "print(multiply.description) # Multiply two numbers.\n",
    "print(multiply.args) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3b5eb2-e7e3-455d-9fae-c72e33d87307",
   "metadata": {},
   "source": [
    "Tools, has parameter \"response_format\"\n",
    "\n",
    "response_format: The tool response format. If \"content\" then the output of the tool is interpreted as the contents of a ToolMessage. If \"content_and_artifact\" then the output is expected to be a two-tuple corresponding to the (content, artifact) of a ToolMessage. Defaults to \"content\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fafb2150-6650-45de-b9b3-195c8b78c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List, Tuple\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def generate_random_ints(min: int, max: int, size: int) -> Tuple[str, List[int]]:\n",
    "    \"\"\"Generate size random ints in the range [min, max].\"\"\"\n",
    "    array = [random.randint(min, max) for _ in range(size)]\n",
    "    content = f\"Successfully generated array of {size} random ints in [{min}, {max}].\"\n",
    "    return content, array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7395127-6ddb-4667-a749-f52e42006eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Successfully generated array of 10 random ints in [0, 9].'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_random_ints.invoke({\"min\": 0, \"max\": 9, \"size\": 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980045e2-a719-4df5-ab8c-78ff825156fd",
   "metadata": {},
   "source": [
    "In order to get back both the content and the artifacft, we need to invoke our model with a ToolCall (which is just aa dictionary with \"name\", \"args\", \"id\" and \"type\" keys), which has additional info needed to generate a ToolMessage like the tool call ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "074e4519-1336-4edf-a297-ad5cf411cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = generate_random_ints.invoke(\n",
    "    {\n",
    "        \"name\": \"generate_random_ints\",\n",
    "        \"args\": {\"min\": 0, \"max\": 9, \"size\": 10},\n",
    "        \"id\": \"123\",  # required\n",
    "        \"type\": \"tool_call\",  # required\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afc37511-38ac-4cd3-bdab-23e45bc88f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 9, 2, 8, 3, 9, 5, 0, 9]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f438d740-2e3f-4c32-a3e3-fa918a62283d",
   "metadata": {},
   "source": [
    "Tool calling with llm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b7b08a8-68ad-4813-9794-e4ecf0eff6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"qwen2.5-coder:14b\", model_provider=\"ollama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fbe025d-b260-49ba-a1a8-51e5c9b48c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'generate_random_ints',\n",
       "  'args': {'max': 24, 'min': 1, 'size': 6},\n",
       "  'id': '0fd71454-4578-48d4-b8dc-e65f081d3d3a',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools = llm.bind_tools([generate_random_ints])\n",
    "\n",
    "ai_msg = llm_with_tools.invoke(\"generate 6 positive ints less than 25\")\n",
    "ai_msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c8c8e33-5ca9-48eb-9502-9c901f87de40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='Successfully generated array of 6 random ints in [1, 24].', name='generate_random_ints', tool_call_id='0d648ac0-0a93-425f-98a1-38e85c08b44c', artifact=[24, 15, 7, 20, 13, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_random_ints.invoke(ai_msg.tool_calls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9016b316-ca65-4418-8559-070d589fafcd",
   "metadata": {},
   "source": [
    "Tool call using a chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f748b0e2-85d9-4843-bcd6-a38072628317",
   "metadata": {},
   "source": [
    "# LangChain Expression Language (LCEL)\n",
    "LCEL takes declarative approach to building new Runnables from existing Runnables.\n",
    "\n",
    "This means you describe what should happen, rather than how it should happen, allowing Langchain to optimize the run-time execution of the chains.\n",
    "\n",
    "a chain is runnable, and it implements the full runnable interface\n",
    "\n",
    "\n",
    "the pipe operator in langchain | , means that the operands a run in sequence\n",
    "\n",
    "a | b, a then b, and the result of a is the input of b\n",
    "\n",
    " In LangChain, the pipe operator (|) is overloaded for runnables so that when you write a | b, it creates a sequence where:\n",
    "\n",
    "- a is executed first.\n",
    "- The output of a is passed as the input to b.\n",
    "This operator essentially composes two runnables into a pipeline, enabling you to build complex workflows by chaining simple components together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce3f2b46-2d17-4fe2-b519-b60b0fc75c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolMessage(content='Successfully generated array of 1 random ints in [1, 5].', name='generate_random_ints', tool_call_id='7569e5cb-de1a-4087-8bc1-3ed3ad5e9912', artifact=[4])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import attrgetter\n",
    "\n",
    "\n",
    "chain.invoke(\"give me a random number between 1 and 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a828394d-1959-4a74-82de-fcc20702e2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from operator import attrgetter\n",
    "\n",
    "import langsmith\n",
    "from langchain_core.tracers.context import tracing_v2_enabled\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "langsmith_client = langsmith.Client(\n",
    " api_key=os.environ.get(\"LANGSMITH_API_KEY\"),\n",
    " api_url='https://api.smith.langchain.com'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4415bdf2-58fe-4587-a52f-632b67018fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "chain = llm_with_tools | attrgetter(\"tool_calls\") | generate_random_ints.map()\n",
    "\n",
    "with tracing_v2_enabled(client=langsmith_client, project_name=\"chaining\"):\n",
    "    chain.invoke(\"give me a random number between 1 and 5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8588b0c0-ed16-4d19-9397-608398e87cf5",
   "metadata": {},
   "source": [
    "### How to chain runnables\n",
    "One point of LCEL is that any 2 runnables can be chained together into sequences. the output of the previous runnabls `.invoke()` call is passed as input to the next runnable. this can be done using the pipe operator `|` or more explicit `.pipe()` mehod.\n",
    "\n",
    "### | operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0bcc960-b335-4734-bde1-a4b800254865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"qwen2.5-coder:14b\", model_provider=\"ollama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b26d47e-c86c-4eaf-bc49-1eaa33296f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "with tracing_v2_enabled(client=langsmith_client, project_name=\"pipe\"):\n",
    "    chain.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d55ce81-6100-4522-886b-b5daf3f4e276",
   "metadata": {},
   "source": [
    "#### Coercion\n",
    "Combine this chain with more runnables to create another chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8c8df55-ced9-4046-bb56-e9ccdba4055e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, that is indeed a funny joke! It plays on the stereotypes of bears being slow and cheetahs being fast, with a clever punchline that suggests the bear doesn't want to play poker because there are too many \"cheetahs\" (cheaters). The humor comes from the unexpected comparison and the wordplay.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "analysis_prompt = ChatPromptTemplate.from_template(\"is this a funny joke? {joke}\")\n",
    "\n",
    "composed_chain = {\"joke\": chain} | analysis_prompt | model | StrOutputParser()\n",
    "\n",
    "with tracing_v2_enabled(client=langsmith_client, project_name=\"coercion\"):\n",
    "    result = composed_chain.invoke({\"topic\": \"bears\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "549a0a99-fb72-41b5-98f3-31dd7134d59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translate {input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "with tracing_v2_enabled(client=langsmith_client, project_name=\"chaining\"):\n",
    "    result = chain.invoke(\n",
    "        {\n",
    "            \"input_language\": \"English\",\n",
    "            \"output_language\": \"German\",\n",
    "            \"input\": \"I love programming.\",\n",
    "        }\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7209220-a320-4f03-a11d-c67204c81105",
   "metadata": {},
   "source": [
    "### Tool calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2850c3c3-493b-45a9-9aeb-d692e30a5542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'validate_user', 'args': {'addresses': ['123 Fake St, Boston, MA', '234 Pretend Blvd, Houston, TX'], 'user_id': 123}, 'id': 'e464de9c-437b-439c-84f2-80929ad871e3', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "@tool\n",
    "def validate_user(user_id: int, addresses: List[str]) -> bool:\n",
    "    \"\"\" Validate user using historical addresses.\n",
    "\n",
    "    Args:\n",
    "        user_id (int): the user ID.\n",
    "        addresses list[str]): Previous addresses as a list of strings.\n",
    "    \"\"\"\n",
    "    return True\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"qwen2.5-coder:14b\",\n",
    "    temperature=0,\n",
    ").bind_tools([validate_user])\n",
    "\n",
    "with tracing_v2_enabled(client=langsmith_client, project_name=\"chaining\"):\n",
    "    result = llm.invoke(\n",
    "        \"Could you validate user 123? They previously lived at \"\n",
    "        \"123 Fake St in boston MA and 234 Pretend Blvd in \"\n",
    "        \"Houston Tx.\"\n",
    "    )\n",
    "print(result.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334e406e-e871-4f54-a280-7fe6c710af93",
   "metadata": {},
   "source": [
    "# Agents\n",
    "Agents are systems that use LLMs as reasoning engines to determine which actions to take and the inputs necessary to perform the action. After executing actions, the reqults can be fed back into the LLM to determine whether more actions are needed, or whether it is okay to finish. this is often achieved via tool-calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9b88a68-b2ed-4a29-9959-208b8043b828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/yi/Documents/tutorials/tutorials/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m28 packages\u001b[0m \u001b[2min 567ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 105ms\u001b[0m\u001b[0m                                             \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 13ms\u001b[0m\u001b[0m=2.0.16                         \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlanggraph\u001b[0m\u001b[2m==0.2.74\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlanggraph-checkpoint\u001b[0m\u001b[2m==2.0.16\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlanggraph-sdk\u001b[0m\u001b[2m==0.1.53\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! uv pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4b687fb-3e8f-4a5b-9033-3efc32956fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
    "  os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter API key for tavily: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7468957c-dc93-44bd-b05d-707eea4948e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Create the agent\n",
    "memory = MemorySaver()\n",
    "model = ChatOllama(model=\"qwen2.5-coder:14b\")\n",
    "search = TavilySearchResults(max_results=2)\n",
    "tools = [search]\n",
    "agent_executor = create_react_agent(model, tools, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7ee3915-1d13-4e7c-b0d2-be43c3ce20ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi im bob! and i live in sf\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Bob! It's nice to meet you. How can I assist you today? If you have any questions or need information, feel free to let me know.\n"
     ]
    }
   ],
   "source": [
    "# Use the agent\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "with tracing_v2_enabled(client=langsmith_client, project_name=\"agent\"):\n",
    "    for step in agent_executor.stream(\n",
    "        {\"messages\": [HumanMessage(content=\"hi im bob! and i live in sf\")]},\n",
    "        config,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d645d623-a46b-4745-98ac-83b1eada2824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "whats the weather where I live?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (cf3935f6-06d7-4530-a8eb-75ef67ab9540)\n",
      " Call ID: cf3935f6-06d7-4530-a8eb-75ef67ab9540\n",
      "  Args:\n",
      "    query: current weather in San Francisco\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.775, 'lon': -122.4183, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1740102873, 'localtime': '2025-02-20 17:54'}, 'current': {'last_updated_epoch': 1740102300, 'last_updated': '2025-02-20 17:45', 'temp_c': 15.2, 'temp_f': 59.4, 'is_day': 1, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/day/116.png', 'code': 1003}, 'wind_mph': 6.0, 'wind_kph': 9.7, 'wind_degree': 284, 'wind_dir': 'WNW', 'pressure_mb': 1020.0, 'pressure_in': 30.11, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 67, 'cloud': 75, 'feelslike_c': 15.2, 'feelslike_f': 59.4, 'windchill_c': 11.8, 'windchill_f': 53.2, 'heatindex_c': 12.4, 'heatindex_f': 54.4, 'dewpoint_c': 10.8, 'dewpoint_f': 51.4, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 0.1, 'gust_mph': 9.3, 'gust_kph': 14.9}}\"}, {\"url\": \"https://world-weather.info/forecast/usa/san_francisco/february-2025/\", \"content\": \"Weather in San Francisco in February 2025 (California) - Detailed Weather Forecast for a Month Weather World Weather in San Francisco Weather in San Francisco in February 2025 San Francisco Weather Forecast for February 2025, is based on previous years' statistical data. +59°+50° +59°+52° +59°+50° +61°+52° +59°+50° +61°+50° +61°+52° +63°+52° +61°+52° +61°+50° +61°+50° +61°+50° +59°+50° +59°+50° +61°+50° +61°+52° +59°+50° +59°+48° +57°+48° +59°+50° +59°+48° +59°+50° +57°+46° +61°+50° +61°+50° +59°+50° +59°+48° +59°+50° Extended weather forecast in San Francisco HourlyWeek10-Day14-Day30-DayYear Weather in large and nearby cities Weather in Washington, D.C.+41° Sacramento+55° Pleasanton+55° Redwood City+55° San Leandro+55° San Mateo+54° San Rafael+52° San Ramon+52° South San Francisco+54° Vallejo+50° Palo Alto+55° Pacifica+55° Berkeley+54° Castro Valley+55° Concord+52° Daly City+54° Noverd+52° Sign Hill+54° world's temperature today day day Temperature units\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for providing that information. Based on the data from WeatherAPI.com, here is a summary of the current weather in San Francisco:\n",
      "\n",
      "- **Location**: San Francisco, California, United States of America\n",
      "- **Local Time**: February 20, 2025, at 17:54 (Pacific Standard Time)\n",
      "- **Temperature**: 15.2°C or 59.4°F\n",
      "- **Condition**: Partly cloudy\n",
      "- **Wind Speed**: 6.0 mph or 9.7 kph from the WNW direction\n",
      "- **Pressure**: 1020.0 mb or 30.11 inHg\n",
      "- **Precipitation**: 0.0 mm or 0.0 inches\n",
      "- **Humidity**: 67%\n",
      "- **Cloud Cover**: 75%\n",
      "\n",
      "If you need more detailed information or forecasts, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "with tracing_v2_enabled(client=langsmith_client, project_name=\"agent\"):\n",
    "    for step in agent_executor.stream(\n",
    "        {\"messages\": [HumanMessage(content=\"whats the weather where I live?\")]},\n",
    "        config,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        step[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
